{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":0,"renderable":0},{"_id":"source/README.md","path":"README.md","modified":0,"renderable":0},{"_id":"themes/vexo/source/css/style.styl","path":"css/style.styl","modified":0,"renderable":1},{"_id":"themes/vexo/source/js/qrious.js","path":"js/qrious.js","modified":0,"renderable":1},{"_id":"themes/vexo/source/js/script.js","path":"js/script.js","modified":0,"renderable":1},{"_id":"themes/vexo/source/css/plugins/gitment.css","path":"css/plugins/gitment.css","modified":0,"renderable":1},{"_id":"themes/vexo/source/css/images/catalog.png","path":"css/images/catalog.png","modified":0,"renderable":1},{"_id":"themes/vexo/source/css/images/logo.png","path":"css/images/logo.png","modified":0,"renderable":1},{"_id":"themes/vexo/source/css/images/escheres.png","path":"css/images/escheres.png","modified":0,"renderable":1},{"_id":"themes/vexo/source/css/images/menu.png","path":"css/images/menu.png","modified":0,"renderable":1},{"_id":"themes/vexo/source/css/images/top.png","path":"css/images/top.png","modified":0,"renderable":1},{"_id":"themes/vexo/source/fonts/SourceSansPro.ttf","path":"fonts/SourceSansPro.ttf","modified":0,"renderable":1},{"_id":"themes/vexo/source/js/gitment.js","path":"js/gitment.js","modified":0,"renderable":1},{"_id":"themes/vexo/source/css/images/alipay.jpg","path":"css/images/alipay.jpg","modified":0,"renderable":1},{"_id":"themes/vexo/source/css/images/wechat.jpg","path":"css/images/wechat.jpg","modified":0,"renderable":1}],"Cache":[{"_id":"source/CNAME","hash":"4cb7e1877db76baec11d5f4626a5149cb3d00d50","modified":1551196193080},{"_id":"source/README.md","hash":"77310ef78fbb283913944ba7be7a7c2a136379d9","modified":1551196193081},{"_id":"themes/vexo/.gitignore_bak","hash":"37fb9fd49e7f944716efd3284a6bf55adb6dd0c2","modified":1548075761000},{"_id":"themes/vexo/.travis.yml","hash":"06f7f18e111549c653969bcedfc3e4044d380007","modified":1548075780000},{"_id":"themes/vexo/_config.yml","hash":"d5ca0d6f968ab586f868bb74f44226a83ebc3f47","modified":1547569431000},{"_id":"themes/vexo/LICENSE","hash":"3e135cd69c0e02c0a49dd43d571f600223cc61d1","modified":1547564672000},{"_id":"themes/vexo/lint.sh","hash":"f580302e4aa9ccfb95a253851da6501d145613fe","modified":1547564672000},{"_id":"themes/vexo/package.json","hash":"015402ca4413815f683bfcdd5e6c3bc16ae6e2dd","modified":1590761203478},{"_id":"source/about/index.md","hash":"68c8af0453deca5f6b03eb18ee6f89fb0c1f1f75","modified":1547564680210},{"_id":"source/project/index.md","hash":"b8f5482c157514bd2df4ce8a4e4d01a957497924","modified":1547564680211},{"_id":"source/tags/index.md","hash":"80a15f1b5daff22b04849109e976bc91a410b83e","modified":1547564680212},{"_id":"themes/vexo/.git_bak/FETCH_HEAD","hash":"a78e9b85d791242f87199d3e037409c68389d53f","modified":1547564748000},{"_id":"themes/vexo/.git_bak/HEAD","hash":"acbaef275e46a7f14c1ef456fff2c8bbe8c84724","modified":1547564672000},{"_id":"themes/vexo/.git_bak/ORIG_HEAD","hash":"2f39b97d250b608ce685b10e4ca209c05b3ec6db","modified":1547564748000},{"_id":"themes/vexo/.git_bak/config","hash":"9cf891bec062e2138910d9c40051c4d656da1345","modified":1547564672000},{"_id":"themes/vexo/.git_bak/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1547564669000},{"_id":"themes/vexo/.git_bak/index","hash":"1c784381aaef83a1a6b9046296419b07fe467585","modified":1547569473000},{"_id":"themes/vexo/.git_bak/packed-refs","hash":"86b780921ebffae7fa7964fece82eb23051e6699","modified":1547564672000},{"_id":"source/_posts/Git与Gerrit使用小结.md","hash":"92367fe2bdb94a3d4ba3c8bb2d0d601ab62569cf","modified":1590685179245},{"_id":"source/_posts/Docker基础知识--Cgroup.md","hash":"a931a93a08a88d56ae07531c66297953f368a47b","modified":1590685055910},{"_id":"source/_posts/Docker基础原理--namespace（pid与network）.md","hash":"6f8fab986351ff3bf1a8cf9e75334dea844e8064","modified":1590685056007},{"_id":"source/_posts/Go语言的sync模块.md","hash":"42ee15cf7db4485fb330f5f03f5d0e374a3a99c3","modified":1590685056066},{"_id":"source/_posts/usb接口键盘转PS2接口.md","hash":"346d6b74cdaaaa7dfc7b2051046ee1dda66cb87e","modified":1590685056123},{"_id":"source/_posts/RPC调用.md","hash":"8bf5a2013bd0b8dfaf57e4bcb255ffba441743d8","modified":1590685056083},{"_id":"source/_posts/搭建hexo博客，Travis持续集成.md","hash":"6c67c2bc9d488b83b17805864bcf86b0ee675070","modified":1590685179252},{"_id":"source/_posts/Kafka - - 快速入门指南.md","hash":"0149ee3042ac592b5288d1ce902e1e265c96941f","modified":1590685056320},{"_id":"source/_posts/python协程gevent.md","hash":"592f2691a2bf0a7c92b12dc22f36055569305eeb","modified":1590685055821},{"_id":"source/_posts/技术系分.md","hash":"621207dcc9f691491e0cafcd1f32cbe0b9fcb815","modified":1590685056357},{"_id":"source/_posts/测试语雀-Travis-Hexo.md","hash":"2a194cd2fd2b5150d1bc608ca2095fa204791d48","modified":1590685056350},{"_id":"themes/vexo/layout/about.ejs","hash":"76ba7418788eb2bb9ba46844f4d750734847d0b4","modified":1547564672000},{"_id":"themes/vexo/layout/archive.ejs","hash":"cb12abb19cb70e90d410a6233933eedb3f2c033a","modified":1547564672000},{"_id":"themes/vexo/layout/index.ejs","hash":"9f12f5928d68d4d68175b825e18f89f3b0dfdb69","modified":1547564672000},{"_id":"themes/vexo/layout/layout.ejs","hash":"a7b8f1debdca12d667ecd1bcc3d4bc6e13a23d7b","modified":1547564672000},{"_id":"themes/vexo/layout/page.ejs","hash":"5aa03c58ed0174c86a5c5fc8410108bfcbe0c0d3","modified":1547564672000},{"_id":"themes/vexo/layout/project.ejs","hash":"666be5c72bac8165e0946428642b36dd3232983e","modified":1547564672000},{"_id":"themes/vexo/layout/tags.ejs","hash":"5b326e2bd3292b3015d0666b796544d7126acfda","modified":1547564672000},{"_id":"themes/vexo/.git_bak/hooks/applypatch-msg.sample","hash":"4de88eb95a5e93fd27e78b5fb3b5231a8d8917dd","modified":1547564669000},{"_id":"themes/vexo/.git_bak/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1547564669000},{"_id":"themes/vexo/.git_bak/hooks/fsmonitor-watchman.sample","hash":"f7c0aa40cb0d620ff0bca3efe3521ec79e5d7156","modified":1547564669000},{"_id":"themes/vexo/.git_bak/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1547564669000},{"_id":"themes/vexo/.git_bak/hooks/pre-applypatch.sample","hash":"f208287c1a92525de9f5462e905a9d31de1e2d75","modified":1547564669000},{"_id":"themes/vexo/.git_bak/hooks/pre-commit.sample","hash":"36aed8976dcc08b5076844f0ec645b18bc37758f","modified":1547564669000},{"_id":"themes/vexo/.git_bak/hooks/pre-push.sample","hash":"5c8518bfd1d1d3d2c1a7194994c0a16d8a313a41","modified":1547564669000},{"_id":"themes/vexo/.git_bak/hooks/pre-receive.sample","hash":"705a17d259e7896f0082fe2e9f2c0c3b127be5ac","modified":1547564669000},{"_id":"themes/vexo/.git_bak/hooks/prepare-commit-msg.sample","hash":"2584806ba147152ae005cb675aa4f01d5d068456","modified":1547564669000},{"_id":"themes/vexo/.git_bak/hooks/pre-rebase.sample","hash":"288efdc0027db4cfd8b7c47c4aeddba09b6ded12","modified":1547564669000},{"_id":"themes/vexo/.git_bak/hooks/update.sample","hash":"e729cd61b27c128951d139de8e7c63d1a3758dde","modified":1547564669000},{"_id":"themes/vexo/.git_bak/info/exclude","hash":"c879df015d97615050afa7b9641e3352a1e701ac","modified":1547564669000},{"_id":"themes/vexo/.git_bak/logs/HEAD","hash":"440a98c9a5f266c6a3881c179a244ea975d5fcf8","modified":1547564672000},{"_id":"source/_posts/yuque/Docker基础原理--namespace（pid与network）.md","hash":"df4f42a9e5a5c74fdaa8f5fa6e3e0d7af1d7d332","modified":1590685179247},{"_id":"source/_posts/yuque/Docker基础知识--Cgroup.md","hash":"33b282afc402846a2fa83d324328e3f22d25ba55","modified":1590685179248},{"_id":"source/_posts/yuque/Go语言的sync模块.md","hash":"bb3315423df7bfd9f2b1a8c26a107cae593a3354","modified":1590685179249},{"_id":"source/_posts/yuque/Kafka - - 快速入门指南.md","hash":"adc1535e984df61a1a4dd7ff0d816010eb680a73","modified":1590685179250},{"_id":"source/_posts/yuque/RPC调用.md","hash":"d78f6895ac74e28c6cde35f82848dbaef8179718","modified":1590685179250},{"_id":"source/_posts/yuque/usb接口键盘转PS2接口.md","hash":"b2806cb779508f1f9eee8bd8567ecdcdd597fdfb","modified":1590685179251},{"_id":"source/_posts/yuque/测试语雀-Travis-Hexo.md","hash":"411aaca97374cb9d9ad149919d25a6732465e229","modified":1590685179251},{"_id":"themes/vexo/_source/about/index.md","hash":"68c8af0453deca5f6b03eb18ee6f89fb0c1f1f75","modified":1547564672000},{"_id":"themes/vexo/_source/project/index.md","hash":"b8f5482c157514bd2df4ce8a4e4d01a957497924","modified":1547564672000},{"_id":"themes/vexo/_source/tags/index.md","hash":"80a15f1b5daff22b04849109e976bc91a410b83e","modified":1547564672000},{"_id":"themes/vexo/layout/_partial/archive.ejs","hash":"9abbf14034d581569c0b6c992fe22035cb5306b3","modified":1547564672000},{"_id":"themes/vexo/layout/_partial/catalog.ejs","hash":"0352ce39c28074dcfc3bd6416680195eeb384fd1","modified":1547564672000},{"_id":"themes/vexo/layout/_partial/footer.ejs","hash":"6032a4dcc6224ad916b7898d54e91552c17396ce","modified":1547564672000},{"_id":"themes/vexo/layout/_partial/head.ejs","hash":"90334bd53e232d7b2cc5ae743b377fc5336bcd6b","modified":1547564672000},{"_id":"themes/vexo/layout/_partial/header.ejs","hash":"e544f516b23bc609cc6367190f380c879b935c21","modified":1547564672000},{"_id":"themes/vexo/layout/_partial/nav.ejs","hash":"3d8ddc1f6e135a240d40edd157cf37f5d0a12df6","modified":1547564672000},{"_id":"themes/vexo/layout/_partial/pager.ejs","hash":"3a1b9680fbfa3baa76933c7c17216996381ad241","modified":1547564672000},{"_id":"themes/vexo/layout/_partial/tag.ejs","hash":"5d2a2c3f8ca7000945ab426a0c6939421974b224","modified":1547564672000},{"_id":"themes/vexo/layout/_partial/top.ejs","hash":"f09dea486246a580213005b21d4b38810dd16fb3","modified":1547564672000},{"_id":"themes/vexo/layout/_third-party/mathjax.ejs","hash":"aa58f0cfe22e7151c1a0521bbfa5cbd76f6dcd9d","modified":1547564672000},{"_id":"themes/vexo/source/css/_config.styl","hash":"104a0769d5360ae10434f8d73557a4e9e9fb5080","modified":1547568770000},{"_id":"themes/vexo/source/css/style.styl","hash":"c09ad049c647cc089eaf00aa59e5d5d2a7f782d4","modified":1547564672000},{"_id":"themes/vexo/source/js/qrious.js","hash":"a9271e81e2ac6a692b1c133811afa33f0f3d7dc5","modified":1547564672000},{"_id":"themes/vexo/source/js/script.js","hash":"19c6ac9c1d8220fa9ab2ec461c17eaae3bc962d7","modified":1547564672000},{"_id":"themes/vexo/.git_bak/objects/pack/pack-c95f499206cb0ec5460fd9b25fbefe7917a23659.idx","hash":"144b50e4e0e718bf75c0e3582dd20a3e5a493d10","modified":1547564672000},{"_id":"themes/vexo/.git_bak/refs/heads/master","hash":"2f39b97d250b608ce685b10e4ca209c05b3ec6db","modified":1547564672000},{"_id":"themes/vexo/source/css/_partial/about.styl","hash":"8a428687f74f33426bf0c7de3fdd1f7654c26587","modified":1547564672000},{"_id":"themes/vexo/source/css/_partial/archive.styl","hash":"e80ddf26f2af3523632afeabd57f81592537985a","modified":1547564672000},{"_id":"themes/vexo/source/css/_partial/catalog.styl","hash":"cbf3f59d3c3162700eb9cbd4cf72c8470c170f81","modified":1547564672000},{"_id":"themes/vexo/source/css/_partial/footer.styl","hash":"970b6fd3d05834926c69724934b798dd5a1472e6","modified":1547564672000},{"_id":"themes/vexo/source/css/_partial/header.styl","hash":"def3a6938d925c585a7da6256a6f2e90f3b7d61e","modified":1547564672000},{"_id":"themes/vexo/source/css/_partial/markdown.styl","hash":"3ec22606f9548681389158384dc29ddf59c8ceea","modified":1547564672000},{"_id":"themes/vexo/source/css/_partial/nav.styl","hash":"e92c010c5cd460e75c67083df8cdd0bf4d25cde4","modified":1547564672000},{"_id":"themes/vexo/source/css/_partial/pager.styl","hash":"888384c67429c7568aa38b5ebe5acae3cc4de367","modified":1547564672000},{"_id":"themes/vexo/source/css/_partial/project.styl","hash":"e9b6faadf4852bce3a4141cba0a102a7afb81e9f","modified":1547564672000},{"_id":"themes/vexo/source/css/_partial/tags.styl","hash":"5198a7f7c221341138ae5c65185e86b6e13e8e26","modified":1547564672000},{"_id":"themes/vexo/source/css/plugins/gitment.css","hash":"541ff18d7f3542b5663dc6aad06d43e135332b71","modified":1547564672000},{"_id":"themes/vexo/source/css/images/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1548075999555},{"_id":"themes/vexo/source/css/images/catalog.png","hash":"541d20dd600fc2c9230329ceb6885d86e6c151dd","modified":1547564672000},{"_id":"themes/vexo/source/css/images/logo.png","hash":"718c6e48956249121cf3cca1a22a99f8372a3f0d","modified":1547564672000},{"_id":"themes/vexo/source/css/images/escheres.png","hash":"55deece3236dcc2fb44c28dec3e8bacbb7b46542","modified":1547564672000},{"_id":"themes/vexo/source/css/images/menu.png","hash":"bdaa35eb1ed119caeb934e15a05b9f4a5396d957","modified":1547564672000},{"_id":"themes/vexo/source/css/images/top.png","hash":"611a257907474ca02828319f81b006c1d818bb84","modified":1547564672000},{"_id":"themes/vexo/source/fonts/SourceSansPro.ttf","hash":"1e9f0372c269da205fdbac8cf27cb9cf59f6ad45","modified":1547564672000},{"_id":"themes/vexo/source/js/gitment.js","hash":"376446d9c5930576016f97dd63e5e6616c94d8d4","modified":1547564672000},{"_id":"themes/vexo/source/css/images/alipay.jpg","hash":"9c200abdcbb97ee8d78287c994ce909f40540b9a","modified":1547568964000},{"_id":"themes/vexo/source/css/images/wechat.jpg","hash":"d91fcac17b7549eb2649e37d642a1d7b68ff5760","modified":1547568986000},{"_id":"themes/vexo/.git_bak/logs/refs/heads/master","hash":"440a98c9a5f266c6a3881c179a244ea975d5fcf8","modified":1547564672000},{"_id":"themes/vexo/.git_bak/refs/remotes/origin/HEAD","hash":"d9427cda09aba1cdde5c69c2b13c905bddb0bc51","modified":1547564672000},{"_id":"themes/vexo/.git_bak/logs/refs/remotes/origin/HEAD","hash":"440a98c9a5f266c6a3881c179a244ea975d5fcf8","modified":1547564672000},{"_id":"themes/vexo/.git_bak/objects/pack/pack-c95f499206cb0ec5460fd9b25fbefe7917a23659.pack","hash":"f909722216ecfff3adbb2cbb0b2c7fc3f1843311","modified":1547564672000},{"_id":"public/about/index.html","hash":"2984ea81ad3d4602a656523dacad4a7ad9b85fce","modified":1590761732101},{"_id":"public/project/index.html","hash":"30b313b2253c23734e656125bb7122d94a7b9e6f","modified":1590761732101},{"_id":"public/tags/index.html","hash":"5d42ea9f7b575fabc7066049cdd90338ebfb7d77","modified":1590761732215},{"_id":"public/2019/01/15/Git与Gerrit使用小结/index.html","hash":"e07c6896eac844246f228dfb2b97425c80880502","modified":1590761732215},{"_id":"public/archives/index.html","hash":"eadbda7f90101f319307511ddfd86d8d6ab4587f","modified":1590761732219},{"_id":"public/archives/2019/index.html","hash":"bd7626804d6615d98da09cb0847e96424c9be02c","modified":1590761732220},{"_id":"public/archives/2019/01/index.html","hash":"14556a10671c67745b1d3c3626ff5f422cb9c8cc","modified":1590761732220},{"_id":"public/index.html","hash":"8b12649b36e29e382bec9d6ea72cd44f10d5ebd2","modified":1590761732220},{"_id":"public/2020/05/26/python协程gevent/index.html","hash":"cd0ece00113e81fe7ef6571e03f0f4c15d2be686","modified":1590761732260},{"_id":"public/2020/01/08/Docker基础知识--Cgroup/index.html","hash":"10d26b47b578a12aa32588d2d739ee03fd598d52","modified":1590761732260},{"_id":"public/2020/01/08/yuque/Docker基础知识--Cgroup/index.html","hash":"af2ee549f9942683c35fcf392b1545d0ceb083b8","modified":1590761732286},{"_id":"public/2019/06/03/RPC调用/index.html","hash":"341a3750869d58429f1f40df2df9e57b68ec4013","modified":1590761732288},{"_id":"public/2019/06/03/yuque/RPC调用/index.html","hash":"e867c4f5d82217569cf2a6826736b6f68df4d700","modified":1590761732289},{"_id":"public/2019/03/03/usb接口键盘转PS2接口/index.html","hash":"a9c7e37a2711627389f747b810f625b1f93335c9","modified":1590761732289},{"_id":"public/2019/03/03/yuque/usb接口键盘转PS2接口/index.html","hash":"9bd9401a19f6a540bf4d655fa6b6c162080dc19d","modified":1590761732289},{"_id":"public/2019/01/29/测试语雀-Travis-Hexo/index.html","hash":"e877b78dec282d3999bded488ba53935deff2681","modified":1590761732289},{"_id":"public/2019/01/29/yuque/测试语雀-Travis-Hexo/index.html","hash":"d5262be5b6a64ee84a9e0fecdaa90dc56e5cf47f","modified":1590761732289},{"_id":"public/2019/01/21/技术系分/index.html","hash":"968484bdde3ae710d0da632efba8f5e81edb3ed6","modified":1590761732289},{"_id":"public/2019/01/04/搭建hexo博客，Travis持续集成/index.html","hash":"e4d8599d72a0a34576b3fa3041be2cf83d2c080a","modified":1590761732289},{"_id":"public/archives/page/2/index.html","hash":"fab4dc3fa19d17901d4147d6239056364eb5f59a","modified":1590761732289},{"_id":"public/archives/2019/page/2/index.html","hash":"aee2c3ca70938a7d0ea69c3d3d4ff439be525261","modified":1590761732289},{"_id":"public/archives/2019/03/index.html","hash":"2cec090b7f88a08a3266c12974fea7976262753f","modified":1590761732289},{"_id":"public/archives/2019/02/index.html","hash":"7d03c2a53b8cb136faf46cd8f34efe8fb08dc602","modified":1590761732289},{"_id":"public/archives/2019/09/index.html","hash":"3cff46b83a2c60607326f234ce90c3d2e6a83018","modified":1590761732290},{"_id":"public/archives/2020/index.html","hash":"f80c4f759efaf904f134c42df5317c496420a3aa","modified":1590761732290},{"_id":"public/archives/2020/01/index.html","hash":"4e91e6802afa13f2b51411bf53553408b120ba29","modified":1590761732290},{"_id":"public/archives/2020/05/index.html","hash":"54ee38e34f6854f89ecfc95b3bdb219b28148fd0","modified":1590761732290},{"_id":"public/page/2/index.html","hash":"a52aff45ba723e69e3340a807b3b7f20ea659660","modified":1590761732290},{"_id":"public/archives/2019/06/index.html","hash":"9064b979eaf178aa53bc4517eab3c5acd55e5b97","modified":1590761732290},{"_id":"public/archives/2019/12/index.html","hash":"2297f5df11bee92c3f6c2c311e554acab757a735","modified":1590761732290},{"_id":"public/tags/docker/index.html","hash":"668276c1536cfed5c366b21d60d9578f78156f80","modified":1590761732290},{"_id":"public/tags/Cgroup/index.html","hash":"2e366c58fe85a8fb384f6edd13fecd05698c5c31","modified":1590761732290},{"_id":"public/tags/namespace/index.html","hash":"a974c452b8946b9697c5104268d559f502251a34","modified":1590761732291},{"_id":"public/2019/12/18/Docker基础原理--namespace（pid与network）/index.html","hash":"bb8470ba53f4da922927d78754ce1fe746c843bc","modified":1590761732291},{"_id":"public/2019/12/18/yuque/Docker基础原理--namespace（pid与network）/index.html","hash":"7584ec007d84deba4015a7dc404d8be849966893","modified":1590761732291},{"_id":"public/2019/09/04/Go语言的sync模块/index.html","hash":"c4d8bccaa338c26b78123c8dc418a987157872ed","modified":1590761732292},{"_id":"public/2019/09/04/yuque/Go语言的sync模块/index.html","hash":"352603b9f1897513930c270a63303f77f8dcc1b9","modified":1590761732293},{"_id":"public/2019/02/01/Kafka - - 快速入门指南/index.html","hash":"72ac865454bae43916100fff497ffac872283402","modified":1590761732293},{"_id":"public/2019/02/01/yuque/Kafka - - 快速入门指南/index.html","hash":"b74e80613a4206cff5f3a6761d32a52178fc4d78","modified":1590761732293},{"_id":"public/tags/硬件/index.html","hash":"3dd4c21b7e98bc4c1ead6fa16759a23d852996ef","modified":1590761732299},{"_id":"public/tags/HTTP/index.html","hash":"ab11d25a3669061780608bf4e4a518c8676cd1d6","modified":1590761732299},{"_id":"public/tags/rpc/index.html","hash":"79169aed55580baf7b68fa45dd698e49b5b531fe","modified":1590761732299},{"_id":"public/tags/Arduino/index.html","hash":"b4bc322517ebca1c19b49cc405333584340fc735","modified":1590761732300},{"_id":"public/tags/珠峰翻译计划/index.html","hash":"b125c5cc43394ff3e8102337019903738a5cea68","modified":1590761732300},{"_id":"public/tags/Kafka/index.html","hash":"92807dcf5eb7932bbb1d4ddeac2fd470384c5145","modified":1590761732300},{"_id":"public/css/images/catalog.png","hash":"541d20dd600fc2c9230329ceb6885d86e6c151dd","modified":1590761732300},{"_id":"public/css/images/logo.png","hash":"718c6e48956249121cf3cca1a22a99f8372a3f0d","modified":1590761732300},{"_id":"public/css/images/escheres.png","hash":"55deece3236dcc2fb44c28dec3e8bacbb7b46542","modified":1590761732300},{"_id":"public/css/images/menu.png","hash":"bdaa35eb1ed119caeb934e15a05b9f4a5396d957","modified":1590761732300},{"_id":"public/css/images/top.png","hash":"611a257907474ca02828319f81b006c1d818bb84","modified":1590761732300},{"_id":"public/CNAME","hash":"4cb7e1877db76baec11d5f4626a5149cb3d00d50","modified":1590761732300},{"_id":"public/README.md","hash":"77310ef78fbb283913944ba7be7a7c2a136379d9","modified":1590761732300},{"_id":"public/css/images/alipay.jpg","hash":"9c200abdcbb97ee8d78287c994ce909f40540b9a","modified":1590761732671},{"_id":"public/css/images/wechat.jpg","hash":"d91fcac17b7549eb2649e37d642a1d7b68ff5760","modified":1590761732673},{"_id":"public/js/script.js","hash":"19c6ac9c1d8220fa9ab2ec461c17eaae3bc962d7","modified":1590761732680},{"_id":"public/css/style.css","hash":"8181bfc076fa2e5866e12f1d2a597f9fac7b3c7f","modified":1590761732680},{"_id":"public/js/qrious.js","hash":"a9271e81e2ac6a692b1c133811afa33f0f3d7dc5","modified":1590761732680},{"_id":"public/css/plugins/gitment.css","hash":"541ff18d7f3542b5663dc6aad06d43e135332b71","modified":1590761732681},{"_id":"public/js/gitment.js","hash":"376446d9c5930576016f97dd63e5e6616c94d8d4","modified":1590761732681},{"_id":"public/fonts/SourceSansPro.ttf","hash":"1e9f0372c269da205fdbac8cf27cb9cf59f6ad45","modified":1590761732681}],"Category":[],"Data":[],"Page":[{"title":"About","layout":"about","_content":"","source":"about/index.md","raw":"---\ntitle: About\nlayout: about\n---","date":"2020-01-15T14:41:04.369Z","updated":"2019-01-15T15:04:40.210Z","path":"about/index.html","comments":1,"_id":"ckasagnhd0000x39695gm5lqn","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"Project","layout":"project","_content":"","source":"project/index.md","raw":"---\ntitle: Project\nlayout: project\n---\n","date":"2020-01-15T14:41:04.371Z","updated":"2019-01-15T15:04:40.211Z","path":"project/index.html","comments":1,"_id":"ckasagnhj0002x3968h6rrw4y","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"Tags","layout":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: Tags\nlayout: tags\n---\n","date":"2020-01-15T14:41:04.375Z","updated":"2019-01-15T15:04:40.212Z","path":"tags/index.html","comments":1,"_id":"ckasagnhm0004x396vyeshjgu","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"Git与Gerrit使用小结","date":"2019-01-15T06:22:16.000Z","_content":"\n[TOC]\n\n### 切换分支报错，提示需要删除差异文件\n\ngit clean  -d  -fx \"\"\n注： \n\n1. x ：表示删除忽略文件已经对git来说不识别的文件 \n2. d: 删除未被添加到git的路径中的文件 \n3. f: 强制执行\n\n### git status提示.idea未同步。\n\nSince you are locally ignoring files that are in the repository, you need to tell git that you are ignoring them。\n​    git update-index --assume-unchanged <files to forget>\n\n### 修改代码第一次提交\n\ngit checkout master                                               // 切换到master分支\ngit pull -r 或者 git fetch -p && git reset --hard origin/master   // 拉取最新代码，不建议使用git pull\ngit checkout -b branchname                                        // 新建分支branchname\n\n### 修改代码\n\ngit add files 或 git add -A 或 git add -u 或 git add .            // 添加修改文件到暂存区     \ngit commit -m \"commit msg\"                                        // 本地提交，注意每次commit都会生成一个change-ID，即一个评审\n\ngit review                                                        // 提交到master分支\n或\ngit push origin HEAD:refs/for/master                              // 推荐使用git review\n或\ngit review r5_bugfix                                              // 提交到指定分支。r5_bugfix为分支名\n\n##git add -A 提交所有变化\n##git add -u 提交被修改（modified）和被删除（deleteed）文件，不包括新文件（new）\n##git add . （git version 1.x）提交新文件（new）和被修改（modified）文件，不包括被删除（deleteed）文件\n\n（git version 2.x）提交所有变化\n\n### 添加评审人\n\n2.2.1 使用Gerrit添加评审人\n登录http://gerrit.zte.com.cn/，my --> changes 选择提交的评审单，在右侧的Reviewers 后添加评审人，等待评审结果\n2.2.2 在提交评审的同时，设置评审人\ngit review --reviewers xxx@zte.com.cn\n\n评审未通过，开发人员需要在本地修改代码，作为补丁提交到gerrit上\n\n！！提醒：注意要使用commit --amend功能来修订你的提交，而非新增一个commit，新增commit会新生成一个评审单\n场景一：如果本地目录已经是上次提交的代码，则可以直接修改代码，执行下面的命令提交补丁即可\n\ngit add files 或 git add -A 或 git add -u 或 git add .  \ngit commit --amend\ngit review \n场景二：如果本地目录不是上次提交的代码（比如：给以前提交的代码或者别人提交的代码打补丁），需要先获取指定的Change No对应的代码，然后修改代码，提交补丁\n\ngit review -d xx   // 重新下载之前提交过的patchset代码，并切换到新分支\n修改代码\ngit add\ngit commit --amend\ngit review\n\n以前整理的几个Gerrit使用场景：\n\n开发1，建立分支a; 开发2，建立分支b\n\n在开发过程中，a在开发到中间时，需要基于分支b的修改进行继续开发，这样就需要b提交一个review。\n\n然后a基于这个review进行开发，操作流程如下：\n\nbrach_b_id： git review -l进行查看。\n\n开发1在本地，git reiew -d brach_b_id ,然后 执行 git cherry-pick a，然后 git branch -D a ,最后 git checout -b a。\n\n这样操作完成后，本地的a 就变成了基于 b的某个review的 branch了。\n\ngit进一步使用场景：上面场景中，如果，a的开发过程中，b又有修改，并且a需要基于b的新修改进行后续开发。\n\n那么操作流程基本与上面一样：\n\ngit review -d b_1_id\n\ngit cherry-pick a\n\ngit brach -D a\n\ngit checkout -d a\n\n\n\n不过此时更好理解的时另外一种操作：\n\ngit review -d b_1_id\n\ngit checkout a\n\ngit rebase -i  b_1_id\n\n此时，会出现编辑界面，需要编辑本地变更的段，来应用(base)到b_1_id上。\n\n此时，可以选择仅应用，a的变更，至于上个场景中已经base的b_id的变更，就可以丢弃了。\n","source":"_posts/Git与Gerrit使用小结.md","raw":"---\ntitle: Git与Gerrit使用小结\ndate: 2019-01-15 14:22:16\ntags:\n---\n\n[TOC]\n\n### 切换分支报错，提示需要删除差异文件\n\ngit clean  -d  -fx \"\"\n注： \n\n1. x ：表示删除忽略文件已经对git来说不识别的文件 \n2. d: 删除未被添加到git的路径中的文件 \n3. f: 强制执行\n\n### git status提示.idea未同步。\n\nSince you are locally ignoring files that are in the repository, you need to tell git that you are ignoring them。\n​    git update-index --assume-unchanged <files to forget>\n\n### 修改代码第一次提交\n\ngit checkout master                                               // 切换到master分支\ngit pull -r 或者 git fetch -p && git reset --hard origin/master   // 拉取最新代码，不建议使用git pull\ngit checkout -b branchname                                        // 新建分支branchname\n\n### 修改代码\n\ngit add files 或 git add -A 或 git add -u 或 git add .            // 添加修改文件到暂存区     \ngit commit -m \"commit msg\"                                        // 本地提交，注意每次commit都会生成一个change-ID，即一个评审\n\ngit review                                                        // 提交到master分支\n或\ngit push origin HEAD:refs/for/master                              // 推荐使用git review\n或\ngit review r5_bugfix                                              // 提交到指定分支。r5_bugfix为分支名\n\n##git add -A 提交所有变化\n##git add -u 提交被修改（modified）和被删除（deleteed）文件，不包括新文件（new）\n##git add . （git version 1.x）提交新文件（new）和被修改（modified）文件，不包括被删除（deleteed）文件\n\n（git version 2.x）提交所有变化\n\n### 添加评审人\n\n2.2.1 使用Gerrit添加评审人\n登录http://gerrit.zte.com.cn/，my --> changes 选择提交的评审单，在右侧的Reviewers 后添加评审人，等待评审结果\n2.2.2 在提交评审的同时，设置评审人\ngit review --reviewers xxx@zte.com.cn\n\n评审未通过，开发人员需要在本地修改代码，作为补丁提交到gerrit上\n\n！！提醒：注意要使用commit --amend功能来修订你的提交，而非新增一个commit，新增commit会新生成一个评审单\n场景一：如果本地目录已经是上次提交的代码，则可以直接修改代码，执行下面的命令提交补丁即可\n\ngit add files 或 git add -A 或 git add -u 或 git add .  \ngit commit --amend\ngit review \n场景二：如果本地目录不是上次提交的代码（比如：给以前提交的代码或者别人提交的代码打补丁），需要先获取指定的Change No对应的代码，然后修改代码，提交补丁\n\ngit review -d xx   // 重新下载之前提交过的patchset代码，并切换到新分支\n修改代码\ngit add\ngit commit --amend\ngit review\n\n以前整理的几个Gerrit使用场景：\n\n开发1，建立分支a; 开发2，建立分支b\n\n在开发过程中，a在开发到中间时，需要基于分支b的修改进行继续开发，这样就需要b提交一个review。\n\n然后a基于这个review进行开发，操作流程如下：\n\nbrach_b_id： git review -l进行查看。\n\n开发1在本地，git reiew -d brach_b_id ,然后 执行 git cherry-pick a，然后 git branch -D a ,最后 git checout -b a。\n\n这样操作完成后，本地的a 就变成了基于 b的某个review的 branch了。\n\ngit进一步使用场景：上面场景中，如果，a的开发过程中，b又有修改，并且a需要基于b的新修改进行后续开发。\n\n那么操作流程基本与上面一样：\n\ngit review -d b_1_id\n\ngit cherry-pick a\n\ngit brach -D a\n\ngit checkout -d a\n\n\n\n不过此时更好理解的时另外一种操作：\n\ngit review -d b_1_id\n\ngit checkout a\n\ngit rebase -i  b_1_id\n\n此时，会出现编辑界面，需要编辑本地变更的段，来应用(base)到b_1_id上。\n\n此时，可以选择仅应用，a的变更，至于上个场景中已经base的b_id的变更，就可以丢弃了。\n","slug":"Git与Gerrit使用小结","published":1,"updated":"2020-05-28T16:59:39.245Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckasagnhf0001x39632hn7czk","content":"<p>[TOC]</p>\n<h3 id=\"切换分支报错，提示需要删除差异文件\"><a href=\"#切换分支报错，提示需要删除差异文件\" class=\"headerlink\" title=\"切换分支报错，提示需要删除差异文件\"></a>切换分支报错，提示需要删除差异文件</h3><p>git clean  -d  -fx “”<br>注： </p>\n<ol>\n<li>x ：表示删除忽略文件已经对git来说不识别的文件 </li>\n<li>d: 删除未被添加到git的路径中的文件 </li>\n<li>f: 强制执行</li>\n</ol>\n<h3 id=\"git-status提示-idea未同步。\"><a href=\"#git-status提示-idea未同步。\" class=\"headerlink\" title=\"git status提示.idea未同步。\"></a>git status提示.idea未同步。</h3><p>Since you are locally ignoring files that are in the repository, you need to tell git that you are ignoring them。<br>​    git update-index –assume-unchanged <files to=\"\" forget=\"\"></files></p>\n<h3 id=\"修改代码第一次提交\"><a href=\"#修改代码第一次提交\" class=\"headerlink\" title=\"修改代码第一次提交\"></a>修改代码第一次提交</h3><p>git checkout master                                               // 切换到master分支<br>git pull -r 或者 git fetch -p &amp;&amp; git reset –hard origin/master   // 拉取最新代码，不建议使用git pull<br>git checkout -b branchname                                        // 新建分支branchname</p>\n<h3 id=\"修改代码\"><a href=\"#修改代码\" class=\"headerlink\" title=\"修改代码\"></a>修改代码</h3><p>git add files 或 git add -A 或 git add -u 或 git add .            // 添加修改文件到暂存区<br>git commit -m “commit msg”                                        // 本地提交，注意每次commit都会生成一个change-ID，即一个评审</p>\n<p>git review                                                        // 提交到master分支<br>或<br>git push origin HEAD:refs/for/master                              // 推荐使用git review<br>或<br>git review r5_bugfix                                              // 提交到指定分支。r5_bugfix为分支名</p>\n<p>##git add -A 提交所有变化</p>\n<p>##git add -u 提交被修改（modified）和被删除（deleteed）文件，不包括新文件（new）</p>\n<p>##git add . （git version 1.x）提交新文件（new）和被修改（modified）文件，不包括被删除（deleteed）文件</p>\n<p>（git version 2.x）提交所有变化</p>\n<h3 id=\"添加评审人\"><a href=\"#添加评审人\" class=\"headerlink\" title=\"添加评审人\"></a>添加评审人</h3><p>2.2.1 使用Gerrit添加评审人<br>登录<a href=\"http://gerrit.zte.com.cn/，my\" target=\"_blank\" rel=\"noopener\">http://gerrit.zte.com.cn/，my</a> –&gt; changes 选择提交的评审单，在右侧的Reviewers 后添加评审人，等待评审结果<br>2.2.2 在提交评审的同时，设置评审人<br>git review –reviewers <a href=\"mailto:xxx@zte.com.cn\" target=\"_blank\" rel=\"noopener\">xxx@zte.com.cn</a></p>\n<p>评审未通过，开发人员需要在本地修改代码，作为补丁提交到gerrit上</p>\n<p>！！提醒：注意要使用commit –amend功能来修订你的提交，而非新增一个commit，新增commit会新生成一个评审单<br>场景一：如果本地目录已经是上次提交的代码，则可以直接修改代码，执行下面的命令提交补丁即可</p>\n<p>git add files 或 git add -A 或 git add -u 或 git add .<br>git commit –amend<br>git review<br>场景二：如果本地目录不是上次提交的代码（比如：给以前提交的代码或者别人提交的代码打补丁），需要先获取指定的Change No对应的代码，然后修改代码，提交补丁</p>\n<p>git review -d xx   // 重新下载之前提交过的patchset代码，并切换到新分支<br>修改代码<br>git add<br>git commit –amend<br>git review</p>\n<p>以前整理的几个Gerrit使用场景：</p>\n<p>开发1，建立分支a; 开发2，建立分支b</p>\n<p>在开发过程中，a在开发到中间时，需要基于分支b的修改进行继续开发，这样就需要b提交一个review。</p>\n<p>然后a基于这个review进行开发，操作流程如下：</p>\n<p>brach_b_id： git review -l进行查看。</p>\n<p>开发1在本地，git reiew -d brach_b_id ,然后 执行 git cherry-pick a，然后 git branch -D a ,最后 git checout -b a。</p>\n<p>这样操作完成后，本地的a 就变成了基于 b的某个review的 branch了。</p>\n<p>git进一步使用场景：上面场景中，如果，a的开发过程中，b又有修改，并且a需要基于b的新修改进行后续开发。</p>\n<p>那么操作流程基本与上面一样：</p>\n<p>git review -d b_1_id</p>\n<p>git cherry-pick a</p>\n<p>git brach -D a</p>\n<p>git checkout -d a</p>\n<p>不过此时更好理解的时另外一种操作：</p>\n<p>git review -d b_1_id</p>\n<p>git checkout a</p>\n<p>git rebase -i  b_1_id</p>\n<p>此时，会出现编辑界面，需要编辑本地变更的段，来应用(base)到b_1_id上。</p>\n<p>此时，可以选择仅应用，a的变更，至于上个场景中已经base的b_id的变更，就可以丢弃了。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>[TOC]</p>\n<h3 id=\"切换分支报错，提示需要删除差异文件\"><a href=\"#切换分支报错，提示需要删除差异文件\" class=\"headerlink\" title=\"切换分支报错，提示需要删除差异文件\"></a>切换分支报错，提示需要删除差异文件</h3><p>git clean  -d  -fx “”<br>注： </p>\n<ol>\n<li>x ：表示删除忽略文件已经对git来说不识别的文件 </li>\n<li>d: 删除未被添加到git的路径中的文件 </li>\n<li>f: 强制执行</li>\n</ol>\n<h3 id=\"git-status提示-idea未同步。\"><a href=\"#git-status提示-idea未同步。\" class=\"headerlink\" title=\"git status提示.idea未同步。\"></a>git status提示.idea未同步。</h3><p>Since you are locally ignoring files that are in the repository, you need to tell git that you are ignoring them。<br>​    git update-index –assume-unchanged <files to=\"\" forget=\"\"></files></p>\n<h3 id=\"修改代码第一次提交\"><a href=\"#修改代码第一次提交\" class=\"headerlink\" title=\"修改代码第一次提交\"></a>修改代码第一次提交</h3><p>git checkout master                                               // 切换到master分支<br>git pull -r 或者 git fetch -p &amp;&amp; git reset –hard origin/master   // 拉取最新代码，不建议使用git pull<br>git checkout -b branchname                                        // 新建分支branchname</p>\n<h3 id=\"修改代码\"><a href=\"#修改代码\" class=\"headerlink\" title=\"修改代码\"></a>修改代码</h3><p>git add files 或 git add -A 或 git add -u 或 git add .            // 添加修改文件到暂存区<br>git commit -m “commit msg”                                        // 本地提交，注意每次commit都会生成一个change-ID，即一个评审</p>\n<p>git review                                                        // 提交到master分支<br>或<br>git push origin HEAD:refs/for/master                              // 推荐使用git review<br>或<br>git review r5_bugfix                                              // 提交到指定分支。r5_bugfix为分支名</p>\n<p>##git add -A 提交所有变化</p>\n<p>##git add -u 提交被修改（modified）和被删除（deleteed）文件，不包括新文件（new）</p>\n<p>##git add . （git version 1.x）提交新文件（new）和被修改（modified）文件，不包括被删除（deleteed）文件</p>\n<p>（git version 2.x）提交所有变化</p>\n<h3 id=\"添加评审人\"><a href=\"#添加评审人\" class=\"headerlink\" title=\"添加评审人\"></a>添加评审人</h3><p>2.2.1 使用Gerrit添加评审人<br>登录<a href=\"http://gerrit.zte.com.cn/，my\" target=\"_blank\" rel=\"noopener\">http://gerrit.zte.com.cn/，my</a> –&gt; changes 选择提交的评审单，在右侧的Reviewers 后添加评审人，等待评审结果<br>2.2.2 在提交评审的同时，设置评审人<br>git review –reviewers <a href=\"mailto:xxx@zte.com.cn\" target=\"_blank\" rel=\"noopener\">xxx@zte.com.cn</a></p>\n<p>评审未通过，开发人员需要在本地修改代码，作为补丁提交到gerrit上</p>\n<p>！！提醒：注意要使用commit –amend功能来修订你的提交，而非新增一个commit，新增commit会新生成一个评审单<br>场景一：如果本地目录已经是上次提交的代码，则可以直接修改代码，执行下面的命令提交补丁即可</p>\n<p>git add files 或 git add -A 或 git add -u 或 git add .<br>git commit –amend<br>git review<br>场景二：如果本地目录不是上次提交的代码（比如：给以前提交的代码或者别人提交的代码打补丁），需要先获取指定的Change No对应的代码，然后修改代码，提交补丁</p>\n<p>git review -d xx   // 重新下载之前提交过的patchset代码，并切换到新分支<br>修改代码<br>git add<br>git commit –amend<br>git review</p>\n<p>以前整理的几个Gerrit使用场景：</p>\n<p>开发1，建立分支a; 开发2，建立分支b</p>\n<p>在开发过程中，a在开发到中间时，需要基于分支b的修改进行继续开发，这样就需要b提交一个review。</p>\n<p>然后a基于这个review进行开发，操作流程如下：</p>\n<p>brach_b_id： git review -l进行查看。</p>\n<p>开发1在本地，git reiew -d brach_b_id ,然后 执行 git cherry-pick a，然后 git branch -D a ,最后 git checout -b a。</p>\n<p>这样操作完成后，本地的a 就变成了基于 b的某个review的 branch了。</p>\n<p>git进一步使用场景：上面场景中，如果，a的开发过程中，b又有修改，并且a需要基于b的新修改进行后续开发。</p>\n<p>那么操作流程基本与上面一样：</p>\n<p>git review -d b_1_id</p>\n<p>git cherry-pick a</p>\n<p>git brach -D a</p>\n<p>git checkout -d a</p>\n<p>不过此时更好理解的时另外一种操作：</p>\n<p>git review -d b_1_id</p>\n<p>git checkout a</p>\n<p>git rebase -i  b_1_id</p>\n<p>此时，会出现编辑界面，需要编辑本地变更的段，来应用(base)到b_1_id上。</p>\n<p>此时，可以选择仅应用，a的变更，至于上个场景中已经base的b_id的变更，就可以丢弃了。</p>\n"},{"title":"Docker基础知识--Cgroup","urlname":"czpxfz","date":"2020-01-08T14:24:05.000Z","_content":"\n## 前言\n\n上篇中，已经讨论了 Docker 作为虚拟化技术，所采用的基础技术 namespace，以此来进行资源隔离。同时，我们也想到了另外一个问题，在资源隔离后，实际上仍然是占用 host 的资源，如何保证资源（CPU、内存和 IO）被有效的控制，为此 Docker 引入另外一项关键技术---Control group ( `Cgroup`)。\n\n## 何为 Cgroup\n\n在 Linux 系统中，内核本身的调度和管理并不对进程和线程进行区分，只会根据`clone`创建时传入的值不同，来区分进程和线程。\nCgroup 全称为 `control grup` ，由 06 年合入 linux 内核，就是把任务放在一个组里进行控制。我们给出官方的定义：\ncgroup 是 Linux 内核提供的一种机制，这种机制可以根据需要把一系列的系统任务和对应的子任务整合（或者分割）到资源划分等级的不同组内。从而对系统的资源，提供了一个完整的控制框架。\n\n## Cgroup 的四个特点\n\n1. cgroup 的 API 以仿文件系统的方式实现，用户态的进程可以通过管理文件的方式完成组织管理\n1. cgroup 的组织管理，最小颗粒度为线程级别，此外用户有权限创建和销毁 cgroup，从而实现资源再分配\n1. 所有的资源管理的功能都以**子系统**的方式实现，保证 API 接口的统一性\n1. 所有子系统的资源组与父任务相同\n\n所有我们，可以认为，cgroup 是附加在程序上的钩子（hook），通过程序运行时，对资源进行调度触发钩子达到资源监控和控制。\n\n## Cgroup 原理\n\n在介绍 Cgroup 原理之前，我们先熟悉两个概念：组织结构与基本规则、子系统。\n\n### Cgroup 的组织结构\n\n传统的 Unix 体系中，首先启动 init 的进程作为 root 进程，再由 init 进程扩展创建子系统作为子节点，而每个子节点又重复此方式，往复循序。而 Cgroup 也创建类似树状结构，子节点继承自父节点。\n与传统 init 方式不同，cgroup 运行多个父节点，即 cgroup 子节点对应的父节点可以有多个。在 Docker 中每个子系统独自构成一个层级，便于管理。\n\n#### Cgroup 的组织规则\n\n1. 同一个层级可以附加多个子系统\n1. 一个子系统可以附加到多个层级，但前提是，关联的层级仅能与此子系统相连，即当且仅当目标层级只有唯一一个子系统时。\n1. 系统每次创建一个新的层级，该系统上所有任务默认加入这个新建层级的初始化层级，即 `root cgroup` 。任务在同一层级，仅能有一份。\n1. 任务在 `fork/clone`  自身时，创建的子任务默认与原任务在同一层级（cgroup）中，但子任务运行被移动到不同个的 cgroup 中。\n\n### 子系统介绍\n\nblkio --  这个子系统为块设备设定输入/输出限制，比如物理设备（磁盘，固态硬盘，USB  等等）。\ncpu --  这个子系统使用调度程序提供对  CPU  的  cgroup  任务访问。\ncpuacct --  这个子系统自动生成  cgroup  中任务所使用的  CPU  报告。\ncpuset --  这个子系统为  cgroup  中的任务分配独立  CPU（在多核系统）和内存节点。\ndevices --  这个子系统可允许或者拒绝  cgroup  中的任务访问设备。\nfreezer --  这个子系统挂起或者恢复  cgroup  中的任务。\nmemory --  这个子系统设定  cgroup  中任务使用的内存限制，并自动生成由那些任务使用的内存资源报告。\nnet_cls --  这个子系统使用等级识别符（classid）标记网络数据包，可允许  Linux  流量控制程序（tc）识别从具体  cgroup  中生成的数据包。\nns --  名称空间子系统。\n","source":"_posts/Docker基础知识--Cgroup.md","raw":"---\ntitle: Docker基础知识--Cgroup\nurlname: czpxfz\ndate: 2020-01-08 22:24:05 +0800\ntags: [docker,Cgroup]\ncategories: []\n---\n\n## 前言\n\n上篇中，已经讨论了 Docker 作为虚拟化技术，所采用的基础技术 namespace，以此来进行资源隔离。同时，我们也想到了另外一个问题，在资源隔离后，实际上仍然是占用 host 的资源，如何保证资源（CPU、内存和 IO）被有效的控制，为此 Docker 引入另外一项关键技术---Control group ( `Cgroup`)。\n\n## 何为 Cgroup\n\n在 Linux 系统中，内核本身的调度和管理并不对进程和线程进行区分，只会根据`clone`创建时传入的值不同，来区分进程和线程。\nCgroup 全称为 `control grup` ，由 06 年合入 linux 内核，就是把任务放在一个组里进行控制。我们给出官方的定义：\ncgroup 是 Linux 内核提供的一种机制，这种机制可以根据需要把一系列的系统任务和对应的子任务整合（或者分割）到资源划分等级的不同组内。从而对系统的资源，提供了一个完整的控制框架。\n\n## Cgroup 的四个特点\n\n1. cgroup 的 API 以仿文件系统的方式实现，用户态的进程可以通过管理文件的方式完成组织管理\n1. cgroup 的组织管理，最小颗粒度为线程级别，此外用户有权限创建和销毁 cgroup，从而实现资源再分配\n1. 所有的资源管理的功能都以**子系统**的方式实现，保证 API 接口的统一性\n1. 所有子系统的资源组与父任务相同\n\n所有我们，可以认为，cgroup 是附加在程序上的钩子（hook），通过程序运行时，对资源进行调度触发钩子达到资源监控和控制。\n\n## Cgroup 原理\n\n在介绍 Cgroup 原理之前，我们先熟悉两个概念：组织结构与基本规则、子系统。\n\n### Cgroup 的组织结构\n\n传统的 Unix 体系中，首先启动 init 的进程作为 root 进程，再由 init 进程扩展创建子系统作为子节点，而每个子节点又重复此方式，往复循序。而 Cgroup 也创建类似树状结构，子节点继承自父节点。\n与传统 init 方式不同，cgroup 运行多个父节点，即 cgroup 子节点对应的父节点可以有多个。在 Docker 中每个子系统独自构成一个层级，便于管理。\n\n#### Cgroup 的组织规则\n\n1. 同一个层级可以附加多个子系统\n1. 一个子系统可以附加到多个层级，但前提是，关联的层级仅能与此子系统相连，即当且仅当目标层级只有唯一一个子系统时。\n1. 系统每次创建一个新的层级，该系统上所有任务默认加入这个新建层级的初始化层级，即 `root cgroup` 。任务在同一层级，仅能有一份。\n1. 任务在 `fork/clone`  自身时，创建的子任务默认与原任务在同一层级（cgroup）中，但子任务运行被移动到不同个的 cgroup 中。\n\n### 子系统介绍\n\nblkio --  这个子系统为块设备设定输入/输出限制，比如物理设备（磁盘，固态硬盘，USB  等等）。\ncpu --  这个子系统使用调度程序提供对  CPU  的  cgroup  任务访问。\ncpuacct --  这个子系统自动生成  cgroup  中任务所使用的  CPU  报告。\ncpuset --  这个子系统为  cgroup  中的任务分配独立  CPU（在多核系统）和内存节点。\ndevices --  这个子系统可允许或者拒绝  cgroup  中的任务访问设备。\nfreezer --  这个子系统挂起或者恢复  cgroup  中的任务。\nmemory --  这个子系统设定  cgroup  中任务使用的内存限制，并自动生成由那些任务使用的内存资源报告。\nnet_cls --  这个子系统使用等级识别符（classid）标记网络数据包，可允许  Linux  流量控制程序（tc）识别从具体  cgroup  中生成的数据包。\nns --  名称空间子系统。\n","slug":"Docker基础知识--Cgroup","published":1,"updated":"2020-05-28T16:57:35.910Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckasagnhk0003x396ywp46e4f","content":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>上篇中，已经讨论了 Docker 作为虚拟化技术，所采用的基础技术 namespace，以此来进行资源隔离。同时，我们也想到了另外一个问题，在资源隔离后，实际上仍然是占用 host 的资源，如何保证资源（CPU、内存和 IO）被有效的控制，为此 Docker 引入另外一项关键技术—Control group ( <code>Cgroup</code>)。</p>\n<h2 id=\"何为-Cgroup\"><a href=\"#何为-Cgroup\" class=\"headerlink\" title=\"何为 Cgroup\"></a>何为 Cgroup</h2><p>在 Linux 系统中，内核本身的调度和管理并不对进程和线程进行区分，只会根据<code>clone</code>创建时传入的值不同，来区分进程和线程。<br>Cgroup 全称为 <code>control grup</code> ，由 06 年合入 linux 内核，就是把任务放在一个组里进行控制。我们给出官方的定义：<br>cgroup 是 Linux 内核提供的一种机制，这种机制可以根据需要把一系列的系统任务和对应的子任务整合（或者分割）到资源划分等级的不同组内。从而对系统的资源，提供了一个完整的控制框架。</p>\n<h2 id=\"Cgroup-的四个特点\"><a href=\"#Cgroup-的四个特点\" class=\"headerlink\" title=\"Cgroup 的四个特点\"></a>Cgroup 的四个特点</h2><ol>\n<li>cgroup 的 API 以仿文件系统的方式实现，用户态的进程可以通过管理文件的方式完成组织管理</li>\n<li>cgroup 的组织管理，最小颗粒度为线程级别，此外用户有权限创建和销毁 cgroup，从而实现资源再分配</li>\n<li>所有的资源管理的功能都以<strong>子系统</strong>的方式实现，保证 API 接口的统一性</li>\n<li>所有子系统的资源组与父任务相同</li>\n</ol>\n<p>所有我们，可以认为，cgroup 是附加在程序上的钩子（hook），通过程序运行时，对资源进行调度触发钩子达到资源监控和控制。</p>\n<h2 id=\"Cgroup-原理\"><a href=\"#Cgroup-原理\" class=\"headerlink\" title=\"Cgroup 原理\"></a>Cgroup 原理</h2><p>在介绍 Cgroup 原理之前，我们先熟悉两个概念：组织结构与基本规则、子系统。</p>\n<h3 id=\"Cgroup-的组织结构\"><a href=\"#Cgroup-的组织结构\" class=\"headerlink\" title=\"Cgroup 的组织结构\"></a>Cgroup 的组织结构</h3><p>传统的 Unix 体系中，首先启动 init 的进程作为 root 进程，再由 init 进程扩展创建子系统作为子节点，而每个子节点又重复此方式，往复循序。而 Cgroup 也创建类似树状结构，子节点继承自父节点。<br>与传统 init 方式不同，cgroup 运行多个父节点，即 cgroup 子节点对应的父节点可以有多个。在 Docker 中每个子系统独自构成一个层级，便于管理。</p>\n<h4 id=\"Cgroup-的组织规则\"><a href=\"#Cgroup-的组织规则\" class=\"headerlink\" title=\"Cgroup 的组织规则\"></a>Cgroup 的组织规则</h4><ol>\n<li>同一个层级可以附加多个子系统</li>\n<li>一个子系统可以附加到多个层级，但前提是，关联的层级仅能与此子系统相连，即当且仅当目标层级只有唯一一个子系统时。</li>\n<li>系统每次创建一个新的层级，该系统上所有任务默认加入这个新建层级的初始化层级，即 <code>root cgroup</code> 。任务在同一层级，仅能有一份。</li>\n<li>任务在 <code>fork/clone</code>  自身时，创建的子任务默认与原任务在同一层级（cgroup）中，但子任务运行被移动到不同个的 cgroup 中。</li>\n</ol>\n<h3 id=\"子系统介绍\"><a href=\"#子系统介绍\" class=\"headerlink\" title=\"子系统介绍\"></a>子系统介绍</h3><p>blkio –  这个子系统为块设备设定输入/输出限制，比如物理设备（磁盘，固态硬盘，USB  等等）。<br>cpu –  这个子系统使用调度程序提供对  CPU  的  cgroup  任务访问。<br>cpuacct –  这个子系统自动生成  cgroup  中任务所使用的  CPU  报告。<br>cpuset –  这个子系统为  cgroup  中的任务分配独立  CPU（在多核系统）和内存节点。<br>devices –  这个子系统可允许或者拒绝  cgroup  中的任务访问设备。<br>freezer –  这个子系统挂起或者恢复  cgroup  中的任务。<br>memory –  这个子系统设定  cgroup  中任务使用的内存限制，并自动生成由那些任务使用的内存资源报告。<br>net_cls –  这个子系统使用等级识别符（classid）标记网络数据包，可允许  Linux  流量控制程序（tc）识别从具体  cgroup  中生成的数据包。<br>ns –  名称空间子系统。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>上篇中，已经讨论了 Docker 作为虚拟化技术，所采用的基础技术 namespace，以此来进行资源隔离。同时，我们也想到了另外一个问题，在资源隔离后，实际上仍然是占用 host 的资源，如何保证资源（CPU、内存和 IO）被有效的控制，为此 Docker 引入另外一项关键技术—Control group ( <code>Cgroup</code>)。</p>\n<h2 id=\"何为-Cgroup\"><a href=\"#何为-Cgroup\" class=\"headerlink\" title=\"何为 Cgroup\"></a>何为 Cgroup</h2><p>在 Linux 系统中，内核本身的调度和管理并不对进程和线程进行区分，只会根据<code>clone</code>创建时传入的值不同，来区分进程和线程。<br>Cgroup 全称为 <code>control grup</code> ，由 06 年合入 linux 内核，就是把任务放在一个组里进行控制。我们给出官方的定义：<br>cgroup 是 Linux 内核提供的一种机制，这种机制可以根据需要把一系列的系统任务和对应的子任务整合（或者分割）到资源划分等级的不同组内。从而对系统的资源，提供了一个完整的控制框架。</p>\n<h2 id=\"Cgroup-的四个特点\"><a href=\"#Cgroup-的四个特点\" class=\"headerlink\" title=\"Cgroup 的四个特点\"></a>Cgroup 的四个特点</h2><ol>\n<li>cgroup 的 API 以仿文件系统的方式实现，用户态的进程可以通过管理文件的方式完成组织管理</li>\n<li>cgroup 的组织管理，最小颗粒度为线程级别，此外用户有权限创建和销毁 cgroup，从而实现资源再分配</li>\n<li>所有的资源管理的功能都以<strong>子系统</strong>的方式实现，保证 API 接口的统一性</li>\n<li>所有子系统的资源组与父任务相同</li>\n</ol>\n<p>所有我们，可以认为，cgroup 是附加在程序上的钩子（hook），通过程序运行时，对资源进行调度触发钩子达到资源监控和控制。</p>\n<h2 id=\"Cgroup-原理\"><a href=\"#Cgroup-原理\" class=\"headerlink\" title=\"Cgroup 原理\"></a>Cgroup 原理</h2><p>在介绍 Cgroup 原理之前，我们先熟悉两个概念：组织结构与基本规则、子系统。</p>\n<h3 id=\"Cgroup-的组织结构\"><a href=\"#Cgroup-的组织结构\" class=\"headerlink\" title=\"Cgroup 的组织结构\"></a>Cgroup 的组织结构</h3><p>传统的 Unix 体系中，首先启动 init 的进程作为 root 进程，再由 init 进程扩展创建子系统作为子节点，而每个子节点又重复此方式，往复循序。而 Cgroup 也创建类似树状结构，子节点继承自父节点。<br>与传统 init 方式不同，cgroup 运行多个父节点，即 cgroup 子节点对应的父节点可以有多个。在 Docker 中每个子系统独自构成一个层级，便于管理。</p>\n<h4 id=\"Cgroup-的组织规则\"><a href=\"#Cgroup-的组织规则\" class=\"headerlink\" title=\"Cgroup 的组织规则\"></a>Cgroup 的组织规则</h4><ol>\n<li>同一个层级可以附加多个子系统</li>\n<li>一个子系统可以附加到多个层级，但前提是，关联的层级仅能与此子系统相连，即当且仅当目标层级只有唯一一个子系统时。</li>\n<li>系统每次创建一个新的层级，该系统上所有任务默认加入这个新建层级的初始化层级，即 <code>root cgroup</code> 。任务在同一层级，仅能有一份。</li>\n<li>任务在 <code>fork/clone</code>  自身时，创建的子任务默认与原任务在同一层级（cgroup）中，但子任务运行被移动到不同个的 cgroup 中。</li>\n</ol>\n<h3 id=\"子系统介绍\"><a href=\"#子系统介绍\" class=\"headerlink\" title=\"子系统介绍\"></a>子系统介绍</h3><p>blkio –  这个子系统为块设备设定输入/输出限制，比如物理设备（磁盘，固态硬盘，USB  等等）。<br>cpu –  这个子系统使用调度程序提供对  CPU  的  cgroup  任务访问。<br>cpuacct –  这个子系统自动生成  cgroup  中任务所使用的  CPU  报告。<br>cpuset –  这个子系统为  cgroup  中的任务分配独立  CPU（在多核系统）和内存节点。<br>devices –  这个子系统可允许或者拒绝  cgroup  中的任务访问设备。<br>freezer –  这个子系统挂起或者恢复  cgroup  中的任务。<br>memory –  这个子系统设定  cgroup  中任务使用的内存限制，并自动生成由那些任务使用的内存资源报告。<br>net_cls –  这个子系统使用等级识别符（classid）标记网络数据包，可允许  Linux  流量控制程序（tc）识别从具体  cgroup  中生成的数据包。<br>ns –  名称空间子系统。</p>\n"},{"title":"Docker基础原理--namespace（pid与network）","urlname":"st1f9c","date":"2019-12-18T13:10:11.000Z","_content":"\n## 前言\n\n在计算机系统中为了标识不同的作用域，而引入 namespace（命名空间）的概念。namespace 作用在内核级别的隔离，可以有效阻止不同进程间的通信。在日常的 Linux 系统中，通常服务在启动后的进程，彼此之间不会特意进行隔离，例如 Web 服务器中，Nginx、MySQL 和 rides，三个服务之间亦可访问任意主机中的文件。如果任一服务不慎被攻破，会被入侵其他的服务。因而 namespace 的引入，可以有效防止不同服务或进程间的相互干扰。\nDocker 使用 Linux 的 namespace 技术，对实现的容器，做了多种层次的隔离。Docker 所使用的七种 namespace 如下：`CLONE_NEWCGROUP`、`CLONE_NEWIPC`、`CLONE_NEWNET`、`CLONE_NEWNS`、`CLONE_NEWPID`、`CLONE_NEWUSER`  和  `CLONE_NEWUTS`。通过在进程中添加如上属性，便能保证与宿主机的对应资源进行有效隔离。\n\n## 进程\n\n在分时操作系统中，进程作为程序的基本执行单元，也是资源（CPU、内存）分配的基本单位。当服务、程序启动后，操作系统为其开辟一个进程，并为它分配资源，除等待 CPU 资源，其他资源以及就绪，此时进入到**就绪态。**当时间片分割的进程，在高优先级调度队列被调度后，进程开始运行。\n进程的三种状态：就绪态、运行态和阻断状态。\nLinux 的进程，可以通过`ps -elf`命令进行查看，下图为 Centos 系统的截图：\n\n```bash\nps -ef\nUID        PID  PPID  C STIME TTY          TIME CMD\nroot         1     0  0 9月24 ?       00:01:32 /usr/lib/systemd/systemd --switched-root --system --deserialize 22\nroot         2     0  0 9月24 ?       00:00:00 [kthreadd]\nroot         3     2  0 9月24 ?       00:00:00 [rcu_gp]\nroot         4     2  0 9月24 ?       00:00:00 [rcu_par_gp]\n```\n\n当前机器中，运行着很多进程，但都以一个 1 号进程开始，即 pid=1 的进程 init。此进程作为所以后续进程的父进程。例如 pid=39 的进程，其父进程（PPID=1）。\n\n- pid=0 号进程 idle，其前身是系统创建的第一个进程，也是唯一一个没有通过 fork 或者 kernel_thread 产生的进程。完成加载系统后，演变为进程调度、交换\n- pid=1 号进程 init，负责执行内核的初始化工作和系统配置。\n- pid=2 的 kthreadd 进程，始终运行在内核空间, 负责所有内核线程的调度和管理。\n\n## Docker 容器内进程 PID\n\n以 RabbitMQ 容器为例，通过如下命令进入 rabbitmq 容器后，使用 ps -ef 命令，再次查看容器内的进程，可以与上面的系统进程进行比较。\n\n```bash\n[root@li1559-144 ~]# docker exec -it 28b6862b34a9 bash\nroot@28b6862b34a9:/# ps -ef\nUID        PID  PPID  C STIME TTY          TIME CMD\nrabbitmq     1     0  0 16:07 ?        00:00:00 /bin/sh /opt/rabbitmq/sbin/rabbitmq-server\nrabbitmq   138     1  0 16:07 ?        00:00:00 /usr/local/lib/erlang/erts-10.4.4/bin/epmd -daemon\n```\n\n当前容器内，PID=1 的进程为 rabbitmq-server，与 Linux 的宿主机的 PID=1 的 init 进程不同。此时，容器内的进程以及与宿主机完全隔离。\n宿主机与 rabbitmq 容器之间的进程对应关系，如下所示（摘自@Draveness）：\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1576771885943-5e1c23b8-82e6-43ee-bb68-1f9ef836e98d.png#align=left&display=inline&height=260&name=image.png&originHeight=520&originWidth=1200&size=83888&status=done&style=none&width=600)\n因此容器内的进程，对宿主机的进程一无所知。实现了内核级的隔离。\n\nDocker 在使用上述隔离技术，进行资源的隔离。当我们每次运行 `docker run`  或者 `docker start`  时，都会调用以下代码块（moby:[https://github.com/moby](https://github.com/moby)），创建资源隔离的容器：\n\n```go\nfunc (daemon *Daemon) createSpec(c *container.Container) (retSpec *specs.Spec, err error) {\n\tvar (\n\t\topts []coci.SpecOpts\n\t\ts    = oci.DefaultSpec()\n\t)\n\topts = append(opts,\n\t\tWithCommonOptions(daemon, c),\n\t\tWithCgroups(daemon, c),\t//添加Cgroups，进行资源限制\n\t\tWithResources(c),\n\t\tWithSysctls(c),\n\t\tWithDevices(daemon, c),\n\t\tWithUser(c),\n\t\tWithRlimits(daemon, c),\n\t\tWithNamespaces(daemon, c),\t//添加namespace，进行资源隔离\n\t\tWithCapabilities(c),\n\t\tWithSeccomp(daemon, c),\n\t\tWithMounts(daemon, c),\t\t//添加挂载点\n\t\tWithLibnetwork(daemon, c),\n\t\tWithApparmor(c),\n\t\tWithSelinux(c),\n\t\tWithOOMScore(&c.HostConfig.OomScoreAdj),\n\t)\n```\n\n在 `WithNamespaces(daemon, c)`  函数中，会设置 `user` `network` `ipc` `pid`  `uts`  以及 `cgroup` ，需要主要的是 moby 项目中，`CLONE_NEWNS`即文件系统被单独在 `WithMounts(daemon, c)`  函数中设置。\n\n```go\nfunc WithNamespaces(daemon *Daemon, c *container.Container) coci.SpecOpts {\n\treturn func(ctx context.Context, _ coci.Client, _ *containers.Container, s *coci.Spec) error {\n\t\tuserNS := false\n\t\t// user\n        // network\n        // ipc\n        //pid\n        if c.HostConfig.PidMode.IsContainer() {\n\t\t\tns := specs.LinuxNamespace{Type: \"pid\"}\n\t\t\tpc, err := daemon.getPidContainer(c)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tns.Path = fmt.Sprintf(\"/proc/%d/ns/pid\", pc.State.GetPID())\n\t\t\tsetNamespace(s, ns)\n\t\t\tif userNS {\n\t\t\t\t// to share a PID namespace, they must also share a user namespace\n\t\t\t\tnsUser := specs.LinuxNamespace{Type: \"user\"}\n\t\t\t\tnsUser.Path = fmt.Sprintf(\"/proc/%d/ns/user\", pc.State.GetPID())\n\t\t\t\tsetNamespace(s, nsUser)\n\t\t\t}\n\t\t} else if c.HostConfig.PidMode.IsHost() {\n\t\t\toci.RemoveNamespace(s, specs.LinuxNamespaceType(\"pid\"))\n\t\t} else {\n\t\t\tns := specs.LinuxNamespace{Type: \"pid\"}\n\t\t\tsetNamespace(s, ns)\n\t\t}\n        // uts\n        //cgroup\n        return nil\n\t}\n}\n```\n\n## Docker 容器内网络 Network\n\nLinux 的 namespace 主要隔离的对象有：网络设备、IPv4 和 IPv6 协议栈、路由表、防火墙、/proc/net 目录、/sys/class/net 目录、套接字（socket）等。Linux 中，物理网络设备默认放置在 root namespace 中。\nDocker 中为实现网络的独立，又能与宿主机进行通信，为此创建 veth pair。将其中的一段放置在容器内通常，通常命名为 eth0，另外一段挂载为物理网络设备上所在的 namespace 中。实际中，docker 在 docker daemon 启动后会创建 docker0 网桥，docker 容器的网络对另一端通常绑定在 docker0 网桥。\n现行的 docker 项目中，自 docker>1.9 之后，已经将网络单独剥离为 `libnetwork`  库，自此网络模式也被抽象为同样接口。docker 现有的网络模式有五种： `bridge驱动` 、 `host驱动` 、 `overlay驱动` 、 `remote驱动` 、 `null驱动` 。\n接下来，我们手动创建 `veth pair` ，用于模仿 docker 网桥模式。docker0（lxcbr0）网桥作为二层交换网桥，之所以在上面配置 IP，可以认为内部有一个可以用于配置 IP 信息的网卡接口。Docker 在桥接模式下，docker0 网桥用于连接容器上的默认网关而存在，并且可以保证在必要时候与宿主机进行网络隔离。\n\n```bash\n## 首先，我们先增加一个网桥lxcbr0，模仿docker0\nbrctl addbr lxcbr0\nbrctl stp lxcbr0 off\nifconfig lxcbr0 192.168.10.1/24 up #为网桥设置IP地址\n\n## 接下来，我们要创建一个network namespace - ns1\n\n# 增加一个namesapce 命令为 ns1 （使用ip netns add命令）\nip netns add ns1\n\n# 激活namespace中的loopback，即127.0.0.1（使用ip netns exec ns1来操作ns1中的命令）\nip netns exec ns1   ip link set dev lo up\n\n## 然后，我们需要增加一对虚拟网卡\n\n# 增加一个pair虚拟网卡，注意其中的veth类型，其中一个网卡要按进容器中\nip link add veth-ns1 type veth peer name lxcbr0.1\n\n# 把 veth-ns1 按到namespace ns1中，这样容器中就会有一个新的网卡了\nip link set veth-ns1 netns ns1\n\n# 把容器里的 veth-ns1改名为 eth0 （容器外会冲突，容器内就不会了）\nip netns exec ns1  ip link set dev veth-ns1 name eth0\n\n# 为容器中的网卡分配一个IP地址，并激活它\nip netns exec ns1 ifconfig eth0 192.168.10.11/24 up\n\n\n# 上面我们把veth-ns1这个网卡按到了容器中，然后我们要把lxcbr0.1添加上网桥上\nbrctl addif lxcbr0 lxcbr0.1\n\n# 为容器增加一个路由规则，让容器可以访问外面的网络\nip netns exec ns1     ip route add default via 192.168.10.1\n\n# 在/etc/netns下创建network namespce名称为ns1的目录，\n# 然后为这个namespace设置resolv.conf，这样，容器内就可以访问域名了\nmkdir -p /etc/netns/ns1\necho \"nameserver 8.8.8.8\" > /etc/netns/ns1/resolv.conf\n\n## 引自：https://coolshell.cn/articles/17029.html\n```\n\n详细的 Linux 的 `ip`  命令，可以参见：[https://wangchujiang.com/linux-command/c/ip.html](https://wangchujiang.com/linux-command/c/ip.html)\n","source":"_posts/Docker基础原理--namespace（pid与network）.md","raw":"---\ntitle: Docker基础原理--namespace（pid与network）\nurlname: st1f9c\ndate: 2019-12-18 21:10:11 +0800\ntags: [docker,namespace]\ncategories: []\n---\n\n## 前言\n\n在计算机系统中为了标识不同的作用域，而引入 namespace（命名空间）的概念。namespace 作用在内核级别的隔离，可以有效阻止不同进程间的通信。在日常的 Linux 系统中，通常服务在启动后的进程，彼此之间不会特意进行隔离，例如 Web 服务器中，Nginx、MySQL 和 rides，三个服务之间亦可访问任意主机中的文件。如果任一服务不慎被攻破，会被入侵其他的服务。因而 namespace 的引入，可以有效防止不同服务或进程间的相互干扰。\nDocker 使用 Linux 的 namespace 技术，对实现的容器，做了多种层次的隔离。Docker 所使用的七种 namespace 如下：`CLONE_NEWCGROUP`、`CLONE_NEWIPC`、`CLONE_NEWNET`、`CLONE_NEWNS`、`CLONE_NEWPID`、`CLONE_NEWUSER`  和  `CLONE_NEWUTS`。通过在进程中添加如上属性，便能保证与宿主机的对应资源进行有效隔离。\n\n## 进程\n\n在分时操作系统中，进程作为程序的基本执行单元，也是资源（CPU、内存）分配的基本单位。当服务、程序启动后，操作系统为其开辟一个进程，并为它分配资源，除等待 CPU 资源，其他资源以及就绪，此时进入到**就绪态。**当时间片分割的进程，在高优先级调度队列被调度后，进程开始运行。\n进程的三种状态：就绪态、运行态和阻断状态。\nLinux 的进程，可以通过`ps -elf`命令进行查看，下图为 Centos 系统的截图：\n\n```bash\nps -ef\nUID        PID  PPID  C STIME TTY          TIME CMD\nroot         1     0  0 9月24 ?       00:01:32 /usr/lib/systemd/systemd --switched-root --system --deserialize 22\nroot         2     0  0 9月24 ?       00:00:00 [kthreadd]\nroot         3     2  0 9月24 ?       00:00:00 [rcu_gp]\nroot         4     2  0 9月24 ?       00:00:00 [rcu_par_gp]\n```\n\n当前机器中，运行着很多进程，但都以一个 1 号进程开始，即 pid=1 的进程 init。此进程作为所以后续进程的父进程。例如 pid=39 的进程，其父进程（PPID=1）。\n\n- pid=0 号进程 idle，其前身是系统创建的第一个进程，也是唯一一个没有通过 fork 或者 kernel_thread 产生的进程。完成加载系统后，演变为进程调度、交换\n- pid=1 号进程 init，负责执行内核的初始化工作和系统配置。\n- pid=2 的 kthreadd 进程，始终运行在内核空间, 负责所有内核线程的调度和管理。\n\n## Docker 容器内进程 PID\n\n以 RabbitMQ 容器为例，通过如下命令进入 rabbitmq 容器后，使用 ps -ef 命令，再次查看容器内的进程，可以与上面的系统进程进行比较。\n\n```bash\n[root@li1559-144 ~]# docker exec -it 28b6862b34a9 bash\nroot@28b6862b34a9:/# ps -ef\nUID        PID  PPID  C STIME TTY          TIME CMD\nrabbitmq     1     0  0 16:07 ?        00:00:00 /bin/sh /opt/rabbitmq/sbin/rabbitmq-server\nrabbitmq   138     1  0 16:07 ?        00:00:00 /usr/local/lib/erlang/erts-10.4.4/bin/epmd -daemon\n```\n\n当前容器内，PID=1 的进程为 rabbitmq-server，与 Linux 的宿主机的 PID=1 的 init 进程不同。此时，容器内的进程以及与宿主机完全隔离。\n宿主机与 rabbitmq 容器之间的进程对应关系，如下所示（摘自@Draveness）：\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1576771885943-5e1c23b8-82e6-43ee-bb68-1f9ef836e98d.png#align=left&display=inline&height=260&name=image.png&originHeight=520&originWidth=1200&size=83888&status=done&style=none&width=600)\n因此容器内的进程，对宿主机的进程一无所知。实现了内核级的隔离。\n\nDocker 在使用上述隔离技术，进行资源的隔离。当我们每次运行 `docker run`  或者 `docker start`  时，都会调用以下代码块（moby:[https://github.com/moby](https://github.com/moby)），创建资源隔离的容器：\n\n```go\nfunc (daemon *Daemon) createSpec(c *container.Container) (retSpec *specs.Spec, err error) {\n\tvar (\n\t\topts []coci.SpecOpts\n\t\ts    = oci.DefaultSpec()\n\t)\n\topts = append(opts,\n\t\tWithCommonOptions(daemon, c),\n\t\tWithCgroups(daemon, c),\t//添加Cgroups，进行资源限制\n\t\tWithResources(c),\n\t\tWithSysctls(c),\n\t\tWithDevices(daemon, c),\n\t\tWithUser(c),\n\t\tWithRlimits(daemon, c),\n\t\tWithNamespaces(daemon, c),\t//添加namespace，进行资源隔离\n\t\tWithCapabilities(c),\n\t\tWithSeccomp(daemon, c),\n\t\tWithMounts(daemon, c),\t\t//添加挂载点\n\t\tWithLibnetwork(daemon, c),\n\t\tWithApparmor(c),\n\t\tWithSelinux(c),\n\t\tWithOOMScore(&c.HostConfig.OomScoreAdj),\n\t)\n```\n\n在 `WithNamespaces(daemon, c)`  函数中，会设置 `user` `network` `ipc` `pid`  `uts`  以及 `cgroup` ，需要主要的是 moby 项目中，`CLONE_NEWNS`即文件系统被单独在 `WithMounts(daemon, c)`  函数中设置。\n\n```go\nfunc WithNamespaces(daemon *Daemon, c *container.Container) coci.SpecOpts {\n\treturn func(ctx context.Context, _ coci.Client, _ *containers.Container, s *coci.Spec) error {\n\t\tuserNS := false\n\t\t// user\n        // network\n        // ipc\n        //pid\n        if c.HostConfig.PidMode.IsContainer() {\n\t\t\tns := specs.LinuxNamespace{Type: \"pid\"}\n\t\t\tpc, err := daemon.getPidContainer(c)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tns.Path = fmt.Sprintf(\"/proc/%d/ns/pid\", pc.State.GetPID())\n\t\t\tsetNamespace(s, ns)\n\t\t\tif userNS {\n\t\t\t\t// to share a PID namespace, they must also share a user namespace\n\t\t\t\tnsUser := specs.LinuxNamespace{Type: \"user\"}\n\t\t\t\tnsUser.Path = fmt.Sprintf(\"/proc/%d/ns/user\", pc.State.GetPID())\n\t\t\t\tsetNamespace(s, nsUser)\n\t\t\t}\n\t\t} else if c.HostConfig.PidMode.IsHost() {\n\t\t\toci.RemoveNamespace(s, specs.LinuxNamespaceType(\"pid\"))\n\t\t} else {\n\t\t\tns := specs.LinuxNamespace{Type: \"pid\"}\n\t\t\tsetNamespace(s, ns)\n\t\t}\n        // uts\n        //cgroup\n        return nil\n\t}\n}\n```\n\n## Docker 容器内网络 Network\n\nLinux 的 namespace 主要隔离的对象有：网络设备、IPv4 和 IPv6 协议栈、路由表、防火墙、/proc/net 目录、/sys/class/net 目录、套接字（socket）等。Linux 中，物理网络设备默认放置在 root namespace 中。\nDocker 中为实现网络的独立，又能与宿主机进行通信，为此创建 veth pair。将其中的一段放置在容器内通常，通常命名为 eth0，另外一段挂载为物理网络设备上所在的 namespace 中。实际中，docker 在 docker daemon 启动后会创建 docker0 网桥，docker 容器的网络对另一端通常绑定在 docker0 网桥。\n现行的 docker 项目中，自 docker>1.9 之后，已经将网络单独剥离为 `libnetwork`  库，自此网络模式也被抽象为同样接口。docker 现有的网络模式有五种： `bridge驱动` 、 `host驱动` 、 `overlay驱动` 、 `remote驱动` 、 `null驱动` 。\n接下来，我们手动创建 `veth pair` ，用于模仿 docker 网桥模式。docker0（lxcbr0）网桥作为二层交换网桥，之所以在上面配置 IP，可以认为内部有一个可以用于配置 IP 信息的网卡接口。Docker 在桥接模式下，docker0 网桥用于连接容器上的默认网关而存在，并且可以保证在必要时候与宿主机进行网络隔离。\n\n```bash\n## 首先，我们先增加一个网桥lxcbr0，模仿docker0\nbrctl addbr lxcbr0\nbrctl stp lxcbr0 off\nifconfig lxcbr0 192.168.10.1/24 up #为网桥设置IP地址\n\n## 接下来，我们要创建一个network namespace - ns1\n\n# 增加一个namesapce 命令为 ns1 （使用ip netns add命令）\nip netns add ns1\n\n# 激活namespace中的loopback，即127.0.0.1（使用ip netns exec ns1来操作ns1中的命令）\nip netns exec ns1   ip link set dev lo up\n\n## 然后，我们需要增加一对虚拟网卡\n\n# 增加一个pair虚拟网卡，注意其中的veth类型，其中一个网卡要按进容器中\nip link add veth-ns1 type veth peer name lxcbr0.1\n\n# 把 veth-ns1 按到namespace ns1中，这样容器中就会有一个新的网卡了\nip link set veth-ns1 netns ns1\n\n# 把容器里的 veth-ns1改名为 eth0 （容器外会冲突，容器内就不会了）\nip netns exec ns1  ip link set dev veth-ns1 name eth0\n\n# 为容器中的网卡分配一个IP地址，并激活它\nip netns exec ns1 ifconfig eth0 192.168.10.11/24 up\n\n\n# 上面我们把veth-ns1这个网卡按到了容器中，然后我们要把lxcbr0.1添加上网桥上\nbrctl addif lxcbr0 lxcbr0.1\n\n# 为容器增加一个路由规则，让容器可以访问外面的网络\nip netns exec ns1     ip route add default via 192.168.10.1\n\n# 在/etc/netns下创建network namespce名称为ns1的目录，\n# 然后为这个namespace设置resolv.conf，这样，容器内就可以访问域名了\nmkdir -p /etc/netns/ns1\necho \"nameserver 8.8.8.8\" > /etc/netns/ns1/resolv.conf\n\n## 引自：https://coolshell.cn/articles/17029.html\n```\n\n详细的 Linux 的 `ip`  命令，可以参见：[https://wangchujiang.com/linux-command/c/ip.html](https://wangchujiang.com/linux-command/c/ip.html)\n","slug":"Docker基础原理--namespace（pid与network）","published":1,"updated":"2020-05-28T16:57:36.007Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckasagnhn0005x3963ahl1dt6","content":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>在计算机系统中为了标识不同的作用域，而引入 namespace（命名空间）的概念。namespace 作用在内核级别的隔离，可以有效阻止不同进程间的通信。在日常的 Linux 系统中，通常服务在启动后的进程，彼此之间不会特意进行隔离，例如 Web 服务器中，Nginx、MySQL 和 rides，三个服务之间亦可访问任意主机中的文件。如果任一服务不慎被攻破，会被入侵其他的服务。因而 namespace 的引入，可以有效防止不同服务或进程间的相互干扰。<br>Docker 使用 Linux 的 namespace 技术，对实现的容器，做了多种层次的隔离。Docker 所使用的七种 namespace 如下：<code>CLONE_NEWCGROUP</code>、<code>CLONE_NEWIPC</code>、<code>CLONE_NEWNET</code>、<code>CLONE_NEWNS</code>、<code>CLONE_NEWPID</code>、<code>CLONE_NEWUSER</code>  和  <code>CLONE_NEWUTS</code>。通过在进程中添加如上属性，便能保证与宿主机的对应资源进行有效隔离。</p>\n<h2 id=\"进程\"><a href=\"#进程\" class=\"headerlink\" title=\"进程\"></a>进程</h2><p>在分时操作系统中，进程作为程序的基本执行单元，也是资源（CPU、内存）分配的基本单位。当服务、程序启动后，操作系统为其开辟一个进程，并为它分配资源，除等待 CPU 资源，其他资源以及就绪，此时进入到<strong>就绪态。</strong>当时间片分割的进程，在高优先级调度队列被调度后，进程开始运行。<br>进程的三种状态：就绪态、运行态和阻断状态。<br>Linux 的进程，可以通过<code>ps -elf</code>命令进行查看，下图为 Centos 系统的截图：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ps -ef</span><br><span class=\"line\">UID        PID  PPID  C STIME TTY          TIME CMD</span><br><span class=\"line\">root         1     0  0 9月24 ?       00:01:32 /usr/lib/systemd/systemd --switched-root --system --deserialize 22</span><br><span class=\"line\">root         2     0  0 9月24 ?       00:00:00 [kthreadd]</span><br><span class=\"line\">root         3     2  0 9月24 ?       00:00:00 [rcu_gp]</span><br><span class=\"line\">root         4     2  0 9月24 ?       00:00:00 [rcu_par_gp]</span><br></pre></td></tr></table></figure>\n<p>当前机器中，运行着很多进程，但都以一个 1 号进程开始，即 pid=1 的进程 init。此进程作为所以后续进程的父进程。例如 pid=39 的进程，其父进程（PPID=1）。</p>\n<ul>\n<li>pid=0 号进程 idle，其前身是系统创建的第一个进程，也是唯一一个没有通过 fork 或者 kernel_thread 产生的进程。完成加载系统后，演变为进程调度、交换</li>\n<li>pid=1 号进程 init，负责执行内核的初始化工作和系统配置。</li>\n<li>pid=2 的 kthreadd 进程，始终运行在内核空间, 负责所有内核线程的调度和管理。</li>\n</ul>\n<h2 id=\"Docker-容器内进程-PID\"><a href=\"#Docker-容器内进程-PID\" class=\"headerlink\" title=\"Docker 容器内进程 PID\"></a>Docker 容器内进程 PID</h2><p>以 RabbitMQ 容器为例，通过如下命令进入 rabbitmq 容器后，使用 ps -ef 命令，再次查看容器内的进程，可以与上面的系统进程进行比较。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@li1559-144 ~]<span class=\"comment\"># docker exec -it 28b6862b34a9 bash</span></span><br><span class=\"line\">root@28b6862b34a9:/<span class=\"comment\"># ps -ef</span></span><br><span class=\"line\">UID        PID  PPID  C STIME TTY          TIME CMD</span><br><span class=\"line\">rabbitmq     1     0  0 16:07 ?        00:00:00 /bin/sh /opt/rabbitmq/sbin/rabbitmq-server</span><br><span class=\"line\">rabbitmq   138     1  0 16:07 ?        00:00:00 /usr/<span class=\"built_in\">local</span>/lib/erlang/erts-10.4.4/bin/epmd -daemon</span><br></pre></td></tr></table></figure>\n<p>当前容器内，PID=1 的进程为 rabbitmq-server，与 Linux 的宿主机的 PID=1 的 init 进程不同。此时，容器内的进程以及与宿主机完全隔离。<br>宿主机与 rabbitmq 容器之间的进程对应关系，如下所示（摘自@Draveness）：<br><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1576771885943-5e1c23b8-82e6-43ee-bb68-1f9ef836e98d.png#align=left&amp;display=inline&amp;height=260&amp;name=image.png&amp;originHeight=520&amp;originWidth=1200&amp;size=83888&amp;status=done&amp;style=none&amp;width=600\" alt=\"image.png\"><br>因此容器内的进程，对宿主机的进程一无所知。实现了内核级的隔离。</p>\n<p>Docker 在使用上述隔离技术，进行资源的隔离。当我们每次运行 <code>docker run</code>  或者 <code>docker start</code>  时，都会调用以下代码块（moby:<a href=\"https://github.com/moby\" target=\"_blank\" rel=\"noopener\">https://github.com/moby</a>），创建资源隔离的容器：</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(daemon *Daemon)</span> <span class=\"title\">createSpec</span><span class=\"params\">(c *container.Container)</span> <span class=\"params\">(retSpec *specs.Spec, err error)</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">var</span> (</span><br><span class=\"line\">\t\topts []coci.SpecOpts</span><br><span class=\"line\">\t\ts    = oci.DefaultSpec()</span><br><span class=\"line\">\t)</span><br><span class=\"line\">\topts = <span class=\"built_in\">append</span>(opts,</span><br><span class=\"line\">\t\tWithCommonOptions(daemon, c),</span><br><span class=\"line\">\t\tWithCgroups(daemon, c),\t<span class=\"comment\">//添加Cgroups，进行资源限制</span></span><br><span class=\"line\">\t\tWithResources(c),</span><br><span class=\"line\">\t\tWithSysctls(c),</span><br><span class=\"line\">\t\tWithDevices(daemon, c),</span><br><span class=\"line\">\t\tWithUser(c),</span><br><span class=\"line\">\t\tWithRlimits(daemon, c),</span><br><span class=\"line\">\t\tWithNamespaces(daemon, c),\t<span class=\"comment\">//添加namespace，进行资源隔离</span></span><br><span class=\"line\">\t\tWithCapabilities(c),</span><br><span class=\"line\">\t\tWithSeccomp(daemon, c),</span><br><span class=\"line\">\t\tWithMounts(daemon, c),\t\t<span class=\"comment\">//添加挂载点</span></span><br><span class=\"line\">\t\tWithLibnetwork(daemon, c),</span><br><span class=\"line\">\t\tWithApparmor(c),</span><br><span class=\"line\">\t\tWithSelinux(c),</span><br><span class=\"line\">\t\tWithOOMScore(&amp;c.HostConfig.OomScoreAdj),</span><br><span class=\"line\">\t)</span><br></pre></td></tr></table></figure>\n<p>在 <code>WithNamespaces(daemon, c)</code>  函数中，会设置 <code>user</code> <code>network</code> <code>ipc</code> <code>pid</code>  <code>uts</code>  以及 <code>cgroup</code> ，需要主要的是 moby 项目中，<code>CLONE_NEWNS</code>即文件系统被单独在 <code>WithMounts(daemon, c)</code>  函数中设置。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">WithNamespaces</span><span class=\"params\">(daemon *Daemon, c *container.Container)</span> <span class=\"title\">coci</span>.<span class=\"title\">SpecOpts</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">(ctx context.Context, _ coci.Client, _ *containers.Container, s *coci.Spec)</span> <span class=\"title\">error</span></span> &#123;</span><br><span class=\"line\">\t\tuserNS := <span class=\"literal\">false</span></span><br><span class=\"line\">\t\t<span class=\"comment\">// user</span></span><br><span class=\"line\">        <span class=\"comment\">// network</span></span><br><span class=\"line\">        <span class=\"comment\">// ipc</span></span><br><span class=\"line\">        <span class=\"comment\">//pid</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> c.HostConfig.PidMode.IsContainer() &#123;</span><br><span class=\"line\">\t\t\tns := specs.LinuxNamespace&#123;Type: <span class=\"string\">\"pid\"</span>&#125;</span><br><span class=\"line\">\t\t\tpc, err := daemon.getPidContainer(c)</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">return</span> err</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t\tns.Path = fmt.Sprintf(<span class=\"string\">\"/proc/%d/ns/pid\"</span>, pc.State.GetPID())</span><br><span class=\"line\">\t\t\tsetNamespace(s, ns)</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> userNS &#123;</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">// to share a PID namespace, they must also share a user namespace</span></span><br><span class=\"line\">\t\t\t\tnsUser := specs.LinuxNamespace&#123;Type: <span class=\"string\">\"user\"</span>&#125;</span><br><span class=\"line\">\t\t\t\tnsUser.Path = fmt.Sprintf(<span class=\"string\">\"/proc/%d/ns/user\"</span>, pc.State.GetPID())</span><br><span class=\"line\">\t\t\t\tsetNamespace(s, nsUser)</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> c.HostConfig.PidMode.IsHost() &#123;</span><br><span class=\"line\">\t\t\toci.RemoveNamespace(s, specs.LinuxNamespaceType(<span class=\"string\">\"pid\"</span>))</span><br><span class=\"line\">\t\t&#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">\t\t\tns := specs.LinuxNamespace&#123;Type: <span class=\"string\">\"pid\"</span>&#125;</span><br><span class=\"line\">\t\t\tsetNamespace(s, ns)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">        <span class=\"comment\">// uts</span></span><br><span class=\"line\">        <span class=\"comment\">//cgroup</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">nil</span></span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"Docker-容器内网络-Network\"><a href=\"#Docker-容器内网络-Network\" class=\"headerlink\" title=\"Docker 容器内网络 Network\"></a>Docker 容器内网络 Network</h2><p>Linux 的 namespace 主要隔离的对象有：网络设备、IPv4 和 IPv6 协议栈、路由表、防火墙、/proc/net 目录、/sys/class/net 目录、套接字（socket）等。Linux 中，物理网络设备默认放置在 root namespace 中。<br>Docker 中为实现网络的独立，又能与宿主机进行通信，为此创建 veth pair。将其中的一段放置在容器内通常，通常命名为 eth0，另外一段挂载为物理网络设备上所在的 namespace 中。实际中，docker 在 docker daemon 启动后会创建 docker0 网桥，docker 容器的网络对另一端通常绑定在 docker0 网桥。<br>现行的 docker 项目中，自 docker&gt;1.9 之后，已经将网络单独剥离为 <code>libnetwork</code>  库，自此网络模式也被抽象为同样接口。docker 现有的网络模式有五种： <code>bridge驱动</code> 、 <code>host驱动</code> 、 <code>overlay驱动</code> 、 <code>remote驱动</code> 、 <code>null驱动</code> 。<br>接下来，我们手动创建 <code>veth pair</code> ，用于模仿 docker 网桥模式。docker0（lxcbr0）网桥作为二层交换网桥，之所以在上面配置 IP，可以认为内部有一个可以用于配置 IP 信息的网卡接口。Docker 在桥接模式下，docker0 网桥用于连接容器上的默认网关而存在，并且可以保证在必要时候与宿主机进行网络隔离。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 首先，我们先增加一个网桥lxcbr0，模仿docker0</span></span><br><span class=\"line\">brctl addbr lxcbr0</span><br><span class=\"line\">brctl stp lxcbr0 off</span><br><span class=\"line\">ifconfig lxcbr0 192.168.10.1/24 up <span class=\"comment\">#为网桥设置IP地址</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 接下来，我们要创建一个network namespace - ns1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 增加一个namesapce 命令为 ns1 （使用ip netns add命令）</span></span><br><span class=\"line\">ip netns add ns1</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 激活namespace中的loopback，即127.0.0.1（使用ip netns exec ns1来操作ns1中的命令）</span></span><br><span class=\"line\">ip netns <span class=\"built_in\">exec</span> ns1   ip link <span class=\"built_in\">set</span> dev lo up</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 然后，我们需要增加一对虚拟网卡</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 增加一个pair虚拟网卡，注意其中的veth类型，其中一个网卡要按进容器中</span></span><br><span class=\"line\">ip link add veth-ns1 <span class=\"built_in\">type</span> veth peer name lxcbr0.1</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 把 veth-ns1 按到namespace ns1中，这样容器中就会有一个新的网卡了</span></span><br><span class=\"line\">ip link <span class=\"built_in\">set</span> veth-ns1 netns ns1</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 把容器里的 veth-ns1改名为 eth0 （容器外会冲突，容器内就不会了）</span></span><br><span class=\"line\">ip netns <span class=\"built_in\">exec</span> ns1  ip link <span class=\"built_in\">set</span> dev veth-ns1 name eth0</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 为容器中的网卡分配一个IP地址，并激活它</span></span><br><span class=\"line\">ip netns <span class=\"built_in\">exec</span> ns1 ifconfig eth0 192.168.10.11/24 up</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 上面我们把veth-ns1这个网卡按到了容器中，然后我们要把lxcbr0.1添加上网桥上</span></span><br><span class=\"line\">brctl addif lxcbr0 lxcbr0.1</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 为容器增加一个路由规则，让容器可以访问外面的网络</span></span><br><span class=\"line\">ip netns <span class=\"built_in\">exec</span> ns1     ip route add default via 192.168.10.1</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 在/etc/netns下创建network namespce名称为ns1的目录，</span></span><br><span class=\"line\"><span class=\"comment\"># 然后为这个namespace设置resolv.conf，这样，容器内就可以访问域名了</span></span><br><span class=\"line\">mkdir -p /etc/netns/ns1</span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">\"nameserver 8.8.8.8\"</span> &gt; /etc/netns/ns1/resolv.conf</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 引自：https://coolshell.cn/articles/17029.html</span></span><br></pre></td></tr></table></figure>\n<p>详细的 Linux 的 <code>ip</code>  命令，可以参见：<a href=\"https://wangchujiang.com/linux-command/c/ip.html\" target=\"_blank\" rel=\"noopener\">https://wangchujiang.com/linux-command/c/ip.html</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>在计算机系统中为了标识不同的作用域，而引入 namespace（命名空间）的概念。namespace 作用在内核级别的隔离，可以有效阻止不同进程间的通信。在日常的 Linux 系统中，通常服务在启动后的进程，彼此之间不会特意进行隔离，例如 Web 服务器中，Nginx、MySQL 和 rides，三个服务之间亦可访问任意主机中的文件。如果任一服务不慎被攻破，会被入侵其他的服务。因而 namespace 的引入，可以有效防止不同服务或进程间的相互干扰。<br>Docker 使用 Linux 的 namespace 技术，对实现的容器，做了多种层次的隔离。Docker 所使用的七种 namespace 如下：<code>CLONE_NEWCGROUP</code>、<code>CLONE_NEWIPC</code>、<code>CLONE_NEWNET</code>、<code>CLONE_NEWNS</code>、<code>CLONE_NEWPID</code>、<code>CLONE_NEWUSER</code>  和  <code>CLONE_NEWUTS</code>。通过在进程中添加如上属性，便能保证与宿主机的对应资源进行有效隔离。</p>\n<h2 id=\"进程\"><a href=\"#进程\" class=\"headerlink\" title=\"进程\"></a>进程</h2><p>在分时操作系统中，进程作为程序的基本执行单元，也是资源（CPU、内存）分配的基本单位。当服务、程序启动后，操作系统为其开辟一个进程，并为它分配资源，除等待 CPU 资源，其他资源以及就绪，此时进入到<strong>就绪态。</strong>当时间片分割的进程，在高优先级调度队列被调度后，进程开始运行。<br>进程的三种状态：就绪态、运行态和阻断状态。<br>Linux 的进程，可以通过<code>ps -elf</code>命令进行查看，下图为 Centos 系统的截图：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ps -ef</span><br><span class=\"line\">UID        PID  PPID  C STIME TTY          TIME CMD</span><br><span class=\"line\">root         1     0  0 9月24 ?       00:01:32 /usr/lib/systemd/systemd --switched-root --system --deserialize 22</span><br><span class=\"line\">root         2     0  0 9月24 ?       00:00:00 [kthreadd]</span><br><span class=\"line\">root         3     2  0 9月24 ?       00:00:00 [rcu_gp]</span><br><span class=\"line\">root         4     2  0 9月24 ?       00:00:00 [rcu_par_gp]</span><br></pre></td></tr></table></figure>\n<p>当前机器中，运行着很多进程，但都以一个 1 号进程开始，即 pid=1 的进程 init。此进程作为所以后续进程的父进程。例如 pid=39 的进程，其父进程（PPID=1）。</p>\n<ul>\n<li>pid=0 号进程 idle，其前身是系统创建的第一个进程，也是唯一一个没有通过 fork 或者 kernel_thread 产生的进程。完成加载系统后，演变为进程调度、交换</li>\n<li>pid=1 号进程 init，负责执行内核的初始化工作和系统配置。</li>\n<li>pid=2 的 kthreadd 进程，始终运行在内核空间, 负责所有内核线程的调度和管理。</li>\n</ul>\n<h2 id=\"Docker-容器内进程-PID\"><a href=\"#Docker-容器内进程-PID\" class=\"headerlink\" title=\"Docker 容器内进程 PID\"></a>Docker 容器内进程 PID</h2><p>以 RabbitMQ 容器为例，通过如下命令进入 rabbitmq 容器后，使用 ps -ef 命令，再次查看容器内的进程，可以与上面的系统进程进行比较。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@li1559-144 ~]<span class=\"comment\"># docker exec -it 28b6862b34a9 bash</span></span><br><span class=\"line\">root@28b6862b34a9:/<span class=\"comment\"># ps -ef</span></span><br><span class=\"line\">UID        PID  PPID  C STIME TTY          TIME CMD</span><br><span class=\"line\">rabbitmq     1     0  0 16:07 ?        00:00:00 /bin/sh /opt/rabbitmq/sbin/rabbitmq-server</span><br><span class=\"line\">rabbitmq   138     1  0 16:07 ?        00:00:00 /usr/<span class=\"built_in\">local</span>/lib/erlang/erts-10.4.4/bin/epmd -daemon</span><br></pre></td></tr></table></figure>\n<p>当前容器内，PID=1 的进程为 rabbitmq-server，与 Linux 的宿主机的 PID=1 的 init 进程不同。此时，容器内的进程以及与宿主机完全隔离。<br>宿主机与 rabbitmq 容器之间的进程对应关系，如下所示（摘自@Draveness）：<br><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1576771885943-5e1c23b8-82e6-43ee-bb68-1f9ef836e98d.png#align=left&amp;display=inline&amp;height=260&amp;name=image.png&amp;originHeight=520&amp;originWidth=1200&amp;size=83888&amp;status=done&amp;style=none&amp;width=600\" alt=\"image.png\"><br>因此容器内的进程，对宿主机的进程一无所知。实现了内核级的隔离。</p>\n<p>Docker 在使用上述隔离技术，进行资源的隔离。当我们每次运行 <code>docker run</code>  或者 <code>docker start</code>  时，都会调用以下代码块（moby:<a href=\"https://github.com/moby\" target=\"_blank\" rel=\"noopener\">https://github.com/moby</a>），创建资源隔离的容器：</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(daemon *Daemon)</span> <span class=\"title\">createSpec</span><span class=\"params\">(c *container.Container)</span> <span class=\"params\">(retSpec *specs.Spec, err error)</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">var</span> (</span><br><span class=\"line\">\t\topts []coci.SpecOpts</span><br><span class=\"line\">\t\ts    = oci.DefaultSpec()</span><br><span class=\"line\">\t)</span><br><span class=\"line\">\topts = <span class=\"built_in\">append</span>(opts,</span><br><span class=\"line\">\t\tWithCommonOptions(daemon, c),</span><br><span class=\"line\">\t\tWithCgroups(daemon, c),\t<span class=\"comment\">//添加Cgroups，进行资源限制</span></span><br><span class=\"line\">\t\tWithResources(c),</span><br><span class=\"line\">\t\tWithSysctls(c),</span><br><span class=\"line\">\t\tWithDevices(daemon, c),</span><br><span class=\"line\">\t\tWithUser(c),</span><br><span class=\"line\">\t\tWithRlimits(daemon, c),</span><br><span class=\"line\">\t\tWithNamespaces(daemon, c),\t<span class=\"comment\">//添加namespace，进行资源隔离</span></span><br><span class=\"line\">\t\tWithCapabilities(c),</span><br><span class=\"line\">\t\tWithSeccomp(daemon, c),</span><br><span class=\"line\">\t\tWithMounts(daemon, c),\t\t<span class=\"comment\">//添加挂载点</span></span><br><span class=\"line\">\t\tWithLibnetwork(daemon, c),</span><br><span class=\"line\">\t\tWithApparmor(c),</span><br><span class=\"line\">\t\tWithSelinux(c),</span><br><span class=\"line\">\t\tWithOOMScore(&amp;c.HostConfig.OomScoreAdj),</span><br><span class=\"line\">\t)</span><br></pre></td></tr></table></figure>\n<p>在 <code>WithNamespaces(daemon, c)</code>  函数中，会设置 <code>user</code> <code>network</code> <code>ipc</code> <code>pid</code>  <code>uts</code>  以及 <code>cgroup</code> ，需要主要的是 moby 项目中，<code>CLONE_NEWNS</code>即文件系统被单独在 <code>WithMounts(daemon, c)</code>  函数中设置。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">WithNamespaces</span><span class=\"params\">(daemon *Daemon, c *container.Container)</span> <span class=\"title\">coci</span>.<span class=\"title\">SpecOpts</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">(ctx context.Context, _ coci.Client, _ *containers.Container, s *coci.Spec)</span> <span class=\"title\">error</span></span> &#123;</span><br><span class=\"line\">\t\tuserNS := <span class=\"literal\">false</span></span><br><span class=\"line\">\t\t<span class=\"comment\">// user</span></span><br><span class=\"line\">        <span class=\"comment\">// network</span></span><br><span class=\"line\">        <span class=\"comment\">// ipc</span></span><br><span class=\"line\">        <span class=\"comment\">//pid</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> c.HostConfig.PidMode.IsContainer() &#123;</span><br><span class=\"line\">\t\t\tns := specs.LinuxNamespace&#123;Type: <span class=\"string\">\"pid\"</span>&#125;</span><br><span class=\"line\">\t\t\tpc, err := daemon.getPidContainer(c)</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">return</span> err</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t\tns.Path = fmt.Sprintf(<span class=\"string\">\"/proc/%d/ns/pid\"</span>, pc.State.GetPID())</span><br><span class=\"line\">\t\t\tsetNamespace(s, ns)</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> userNS &#123;</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">// to share a PID namespace, they must also share a user namespace</span></span><br><span class=\"line\">\t\t\t\tnsUser := specs.LinuxNamespace&#123;Type: <span class=\"string\">\"user\"</span>&#125;</span><br><span class=\"line\">\t\t\t\tnsUser.Path = fmt.Sprintf(<span class=\"string\">\"/proc/%d/ns/user\"</span>, pc.State.GetPID())</span><br><span class=\"line\">\t\t\t\tsetNamespace(s, nsUser)</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> c.HostConfig.PidMode.IsHost() &#123;</span><br><span class=\"line\">\t\t\toci.RemoveNamespace(s, specs.LinuxNamespaceType(<span class=\"string\">\"pid\"</span>))</span><br><span class=\"line\">\t\t&#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">\t\t\tns := specs.LinuxNamespace&#123;Type: <span class=\"string\">\"pid\"</span>&#125;</span><br><span class=\"line\">\t\t\tsetNamespace(s, ns)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">        <span class=\"comment\">// uts</span></span><br><span class=\"line\">        <span class=\"comment\">//cgroup</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">nil</span></span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"Docker-容器内网络-Network\"><a href=\"#Docker-容器内网络-Network\" class=\"headerlink\" title=\"Docker 容器内网络 Network\"></a>Docker 容器内网络 Network</h2><p>Linux 的 namespace 主要隔离的对象有：网络设备、IPv4 和 IPv6 协议栈、路由表、防火墙、/proc/net 目录、/sys/class/net 目录、套接字（socket）等。Linux 中，物理网络设备默认放置在 root namespace 中。<br>Docker 中为实现网络的独立，又能与宿主机进行通信，为此创建 veth pair。将其中的一段放置在容器内通常，通常命名为 eth0，另外一段挂载为物理网络设备上所在的 namespace 中。实际中，docker 在 docker daemon 启动后会创建 docker0 网桥，docker 容器的网络对另一端通常绑定在 docker0 网桥。<br>现行的 docker 项目中，自 docker&gt;1.9 之后，已经将网络单独剥离为 <code>libnetwork</code>  库，自此网络模式也被抽象为同样接口。docker 现有的网络模式有五种： <code>bridge驱动</code> 、 <code>host驱动</code> 、 <code>overlay驱动</code> 、 <code>remote驱动</code> 、 <code>null驱动</code> 。<br>接下来，我们手动创建 <code>veth pair</code> ，用于模仿 docker 网桥模式。docker0（lxcbr0）网桥作为二层交换网桥，之所以在上面配置 IP，可以认为内部有一个可以用于配置 IP 信息的网卡接口。Docker 在桥接模式下，docker0 网桥用于连接容器上的默认网关而存在，并且可以保证在必要时候与宿主机进行网络隔离。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 首先，我们先增加一个网桥lxcbr0，模仿docker0</span></span><br><span class=\"line\">brctl addbr lxcbr0</span><br><span class=\"line\">brctl stp lxcbr0 off</span><br><span class=\"line\">ifconfig lxcbr0 192.168.10.1/24 up <span class=\"comment\">#为网桥设置IP地址</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 接下来，我们要创建一个network namespace - ns1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 增加一个namesapce 命令为 ns1 （使用ip netns add命令）</span></span><br><span class=\"line\">ip netns add ns1</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 激活namespace中的loopback，即127.0.0.1（使用ip netns exec ns1来操作ns1中的命令）</span></span><br><span class=\"line\">ip netns <span class=\"built_in\">exec</span> ns1   ip link <span class=\"built_in\">set</span> dev lo up</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 然后，我们需要增加一对虚拟网卡</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 增加一个pair虚拟网卡，注意其中的veth类型，其中一个网卡要按进容器中</span></span><br><span class=\"line\">ip link add veth-ns1 <span class=\"built_in\">type</span> veth peer name lxcbr0.1</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 把 veth-ns1 按到namespace ns1中，这样容器中就会有一个新的网卡了</span></span><br><span class=\"line\">ip link <span class=\"built_in\">set</span> veth-ns1 netns ns1</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 把容器里的 veth-ns1改名为 eth0 （容器外会冲突，容器内就不会了）</span></span><br><span class=\"line\">ip netns <span class=\"built_in\">exec</span> ns1  ip link <span class=\"built_in\">set</span> dev veth-ns1 name eth0</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 为容器中的网卡分配一个IP地址，并激活它</span></span><br><span class=\"line\">ip netns <span class=\"built_in\">exec</span> ns1 ifconfig eth0 192.168.10.11/24 up</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 上面我们把veth-ns1这个网卡按到了容器中，然后我们要把lxcbr0.1添加上网桥上</span></span><br><span class=\"line\">brctl addif lxcbr0 lxcbr0.1</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 为容器增加一个路由规则，让容器可以访问外面的网络</span></span><br><span class=\"line\">ip netns <span class=\"built_in\">exec</span> ns1     ip route add default via 192.168.10.1</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 在/etc/netns下创建network namespce名称为ns1的目录，</span></span><br><span class=\"line\"><span class=\"comment\"># 然后为这个namespace设置resolv.conf，这样，容器内就可以访问域名了</span></span><br><span class=\"line\">mkdir -p /etc/netns/ns1</span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">\"nameserver 8.8.8.8\"</span> &gt; /etc/netns/ns1/resolv.conf</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 引自：https://coolshell.cn/articles/17029.html</span></span><br></pre></td></tr></table></figure>\n<p>详细的 Linux 的 <code>ip</code>  命令，可以参见：<a href=\"https://wangchujiang.com/linux-command/c/ip.html\" target=\"_blank\" rel=\"noopener\">https://wangchujiang.com/linux-command/c/ip.html</a></p>\n"},{"title":"Go语言的sync模块","urlname":"idoio8","date":"2019-09-03T16:11:27.000Z","_content":"\n在程序进行并发操作时，当不同线程使用同一变量时，由于无法判断是否有其他线程在进行写操作，即线程之间出现竞争（资源竞争），因此引入锁机制。\nGo 语言使用 sync 模块保证线程在操作变量的互斥性。当变量被一个线程操作时，先使用 sync 将变量上锁，退出操作时，解锁。\nsync 模块提供基础的同步原语，例如互斥锁（mutual exclusion locks）。除了**Once**和**WaitGroup**类型，大部分的 sync 模块的方法使用在低级库。更高级别的同步方式是使用通道（channel）和通信（communication）。\n本文主要介绍 sync 包内，一些锁的概念及使用方式。\n\n## sync 包基础\n\nsync 包围绕 sync.Locker 进行，其中 interface 为：\n\n```go\ntype Locker interface {\n        Lock()\n        Unlock()\n}\n```\n\n## 基本锁 Mutex\n\nsync.Mutex 是互斥锁，相当于在变量入口处确保只有一个线程能够操作变量。\n假如 num 是一个需要锁处理的存储在共享内存中的变量。通过 Mutex 处理加锁与解锁。具体例子如下：\n\n```go\nimport \"sync\"\n\ntype num struct {\n\tmutex sync.Mutex\n    nu int\n}\n\n//flash num\nfunc update(num *num) {\n    num.mutex.Lock()\n    //update num\n    num.nu = // new value\n    num.mutex.Unlock()  //任何 goroutine 都可用开锁\n}\n```\n\n## 单写多读锁 RWMutex\n\n顾名思义，允许多个线程进行读取，但仅允许单个线程进行写操作。通过 Rlock() 允许同一时间多个线程读操作；如果使用 Lock() ，则 RWMutex 变成 Mutex。\nRWMutex 的方法有：\n\n```go\n    func (rw *RWMutex) Lock()\n    func (rw *RWMutex) RLock()\n    func (rw *RWMutex) RLocker() Locker\n    func (rw *RWMutex) RUnlock()\n    func (rw *RWMutex) Unlock()\n```\n\n对应的策略有：\n\n- **允许存在多个读锁，但只能有一把写锁**；\n\n- **当写锁未被释放时或此时有正被等待的写锁，读锁不可用**；\n\n- **只有当全部读锁结束，写锁才可用**；\n\n## sync.Once\n\nsync.Once 可以保证被调用的 func，只调用一次。\nOnce 数据结构为：\n\n```go\ntype Once struct {\n\tm Mutex\n\tdone uint32\n}\n\nfunc (o *Once) Do(f func()) {\n\tif atomic.LoadUint32(&o.done) == 1 {\n\t\treturn\n\t}\n\t// Slow-path.\n\to.m.Lock()\n\tdefer o.m.Unlock()\n\tif o.done == 0 {\n\t\tdefer atomic.StoreUint32(&o.done, 1)\n\t\tf()\n\t}\n}\n```\n\n由 once.Do 可以看出，当*once.Do(f)*被调用多次时，只有第一次会调用功能函数 f。其核心思想是，使用原子计数记录被执行的次数。其中的锁机制，仍旧使用**Mutex.**\n\n官方给出的一个示例，及对应的执行结果如下：\n\n```go\n//官方例子\npackage main\n\nimport (\n\t\"fmt\"\n\t\"sync\"\n)\n\nfunc main() {\n\tvar once sync.Once\n\tonceBody := func() {\n\t\tfmt.Println(\"Only once\")\n\t}\n\tdone := make(chan bool)\n\tfor i := 0; i < 10; i++ {\n\t\tgo func() {\n\t\t\tonce.Do(onceBody)\n\t\t\tdone <- true\n\t\t}()\n\t}\n\tfor i := 0; i < 10; i++ {\n\t\t<-done\n\t}\n}\n\n// 打印输出为：\nOnly once\n\n```\n\n## sync.WaitGroup\n\n> A WaitGroup waits for a collection of goroutines to finish. The main goroutine calls Add to set the number of goroutines to wait for. Then each of the goroutines runs and calls Done when finished. At the same time, Wait can be used to block until all goroutines have finished.\n\nWaitGroup 可以保证集合内所有 goroutines 协程完成后，主进程再执行其他动作。避免协程未执行完，主进程就退出或执行其他影响协程的动作。\n\n### WaitGroup 操作方式\n\n执行协程前使用 func (*WaitGroup) Add 添加等待计数器。协程完成一次，执行 func (*WaitGroup) Done，在 waitgroup 计数器中减少一个，直至计数器为零，释放锁。\n\n### 使用举例\n\n```go\npackage main\n\nimport (\n\t\"sync\"\n)\n\ntype httpPkg struct{}\n\nfunc (httpPkg) Get(url string) {}\n\nvar http httpPkg\n\nfunc main() {\n\tvar wg sync.WaitGroup\n\tvar urls = []string{\n\t\t\"http://www.golang.org/\",\n\t\t\"http://www.google.com/\",\n\t\t\"http://www.somestupidname.com/\",\n\t}\n\tfor _, url := range urls {\n\t\t// Increment the WaitGroup counter.\n\t\twg.Add(1)\n\t\t// Launch a goroutine to fetch the URL.\n\t\tgo func(url string) {\n\t\t\t// Decrement the counter when the goroutine completes.\n\t\t\tdefer wg.Done()\n\t\t\t// Fetch the URL.\n\t\t\thttp.Get(url)\n\t\t}(url)\n\t}\n\t// Wait for all HTTP fetches to complete.\n\twg.Wait()\n}\n```\n","source":"_posts/Go语言的sync模块.md","raw":"---\ntitle: Go语言的sync模块\nurlname: idoio8\ndate: 2019-09-04 00:11:27 +0800\ntags: []\ncategories: []\n---\n\n在程序进行并发操作时，当不同线程使用同一变量时，由于无法判断是否有其他线程在进行写操作，即线程之间出现竞争（资源竞争），因此引入锁机制。\nGo 语言使用 sync 模块保证线程在操作变量的互斥性。当变量被一个线程操作时，先使用 sync 将变量上锁，退出操作时，解锁。\nsync 模块提供基础的同步原语，例如互斥锁（mutual exclusion locks）。除了**Once**和**WaitGroup**类型，大部分的 sync 模块的方法使用在低级库。更高级别的同步方式是使用通道（channel）和通信（communication）。\n本文主要介绍 sync 包内，一些锁的概念及使用方式。\n\n## sync 包基础\n\nsync 包围绕 sync.Locker 进行，其中 interface 为：\n\n```go\ntype Locker interface {\n        Lock()\n        Unlock()\n}\n```\n\n## 基本锁 Mutex\n\nsync.Mutex 是互斥锁，相当于在变量入口处确保只有一个线程能够操作变量。\n假如 num 是一个需要锁处理的存储在共享内存中的变量。通过 Mutex 处理加锁与解锁。具体例子如下：\n\n```go\nimport \"sync\"\n\ntype num struct {\n\tmutex sync.Mutex\n    nu int\n}\n\n//flash num\nfunc update(num *num) {\n    num.mutex.Lock()\n    //update num\n    num.nu = // new value\n    num.mutex.Unlock()  //任何 goroutine 都可用开锁\n}\n```\n\n## 单写多读锁 RWMutex\n\n顾名思义，允许多个线程进行读取，但仅允许单个线程进行写操作。通过 Rlock() 允许同一时间多个线程读操作；如果使用 Lock() ，则 RWMutex 变成 Mutex。\nRWMutex 的方法有：\n\n```go\n    func (rw *RWMutex) Lock()\n    func (rw *RWMutex) RLock()\n    func (rw *RWMutex) RLocker() Locker\n    func (rw *RWMutex) RUnlock()\n    func (rw *RWMutex) Unlock()\n```\n\n对应的策略有：\n\n- **允许存在多个读锁，但只能有一把写锁**；\n\n- **当写锁未被释放时或此时有正被等待的写锁，读锁不可用**；\n\n- **只有当全部读锁结束，写锁才可用**；\n\n## sync.Once\n\nsync.Once 可以保证被调用的 func，只调用一次。\nOnce 数据结构为：\n\n```go\ntype Once struct {\n\tm Mutex\n\tdone uint32\n}\n\nfunc (o *Once) Do(f func()) {\n\tif atomic.LoadUint32(&o.done) == 1 {\n\t\treturn\n\t}\n\t// Slow-path.\n\to.m.Lock()\n\tdefer o.m.Unlock()\n\tif o.done == 0 {\n\t\tdefer atomic.StoreUint32(&o.done, 1)\n\t\tf()\n\t}\n}\n```\n\n由 once.Do 可以看出，当*once.Do(f)*被调用多次时，只有第一次会调用功能函数 f。其核心思想是，使用原子计数记录被执行的次数。其中的锁机制，仍旧使用**Mutex.**\n\n官方给出的一个示例，及对应的执行结果如下：\n\n```go\n//官方例子\npackage main\n\nimport (\n\t\"fmt\"\n\t\"sync\"\n)\n\nfunc main() {\n\tvar once sync.Once\n\tonceBody := func() {\n\t\tfmt.Println(\"Only once\")\n\t}\n\tdone := make(chan bool)\n\tfor i := 0; i < 10; i++ {\n\t\tgo func() {\n\t\t\tonce.Do(onceBody)\n\t\t\tdone <- true\n\t\t}()\n\t}\n\tfor i := 0; i < 10; i++ {\n\t\t<-done\n\t}\n}\n\n// 打印输出为：\nOnly once\n\n```\n\n## sync.WaitGroup\n\n> A WaitGroup waits for a collection of goroutines to finish. The main goroutine calls Add to set the number of goroutines to wait for. Then each of the goroutines runs and calls Done when finished. At the same time, Wait can be used to block until all goroutines have finished.\n\nWaitGroup 可以保证集合内所有 goroutines 协程完成后，主进程再执行其他动作。避免协程未执行完，主进程就退出或执行其他影响协程的动作。\n\n### WaitGroup 操作方式\n\n执行协程前使用 func (*WaitGroup) Add 添加等待计数器。协程完成一次，执行 func (*WaitGroup) Done，在 waitgroup 计数器中减少一个，直至计数器为零，释放锁。\n\n### 使用举例\n\n```go\npackage main\n\nimport (\n\t\"sync\"\n)\n\ntype httpPkg struct{}\n\nfunc (httpPkg) Get(url string) {}\n\nvar http httpPkg\n\nfunc main() {\n\tvar wg sync.WaitGroup\n\tvar urls = []string{\n\t\t\"http://www.golang.org/\",\n\t\t\"http://www.google.com/\",\n\t\t\"http://www.somestupidname.com/\",\n\t}\n\tfor _, url := range urls {\n\t\t// Increment the WaitGroup counter.\n\t\twg.Add(1)\n\t\t// Launch a goroutine to fetch the URL.\n\t\tgo func(url string) {\n\t\t\t// Decrement the counter when the goroutine completes.\n\t\t\tdefer wg.Done()\n\t\t\t// Fetch the URL.\n\t\t\thttp.Get(url)\n\t\t}(url)\n\t}\n\t// Wait for all HTTP fetches to complete.\n\twg.Wait()\n}\n```\n","slug":"Go语言的sync模块","published":1,"updated":"2020-05-28T16:57:36.066Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckasagnhr0007x3965dqywz7c","content":"<p>在程序进行并发操作时，当不同线程使用同一变量时，由于无法判断是否有其他线程在进行写操作，即线程之间出现竞争（资源竞争），因此引入锁机制。<br>Go 语言使用 sync 模块保证线程在操作变量的互斥性。当变量被一个线程操作时，先使用 sync 将变量上锁，退出操作时，解锁。<br>sync 模块提供基础的同步原语，例如互斥锁（mutual exclusion locks）。除了<strong>Once</strong>和<strong>WaitGroup</strong>类型，大部分的 sync 模块的方法使用在低级库。更高级别的同步方式是使用通道（channel）和通信（communication）。<br>本文主要介绍 sync 包内，一些锁的概念及使用方式。</p>\n<h2 id=\"sync-包基础\"><a href=\"#sync-包基础\" class=\"headerlink\" title=\"sync 包基础\"></a>sync 包基础</h2><p>sync 包围绕 sync.Locker 进行，其中 interface 为：</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">type</span> Locker <span class=\"keyword\">interface</span> &#123;</span><br><span class=\"line\">        Lock()</span><br><span class=\"line\">        Unlock()</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"基本锁-Mutex\"><a href=\"#基本锁-Mutex\" class=\"headerlink\" title=\"基本锁 Mutex\"></a>基本锁 Mutex</h2><p>sync.Mutex 是互斥锁，相当于在变量入口处确保只有一个线程能够操作变量。<br>假如 num 是一个需要锁处理的存储在共享内存中的变量。通过 Mutex 处理加锁与解锁。具体例子如下：</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> <span class=\"string\">\"sync\"</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">type</span> num <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">\tmutex sync.Mutex</span><br><span class=\"line\">    nu <span class=\"keyword\">int</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//flash num</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">update</span><span class=\"params\">(num *num)</span></span> &#123;</span><br><span class=\"line\">    num.mutex.Lock()</span><br><span class=\"line\">    <span class=\"comment\">//update num</span></span><br><span class=\"line\">    num.nu = <span class=\"comment\">// new value</span></span><br><span class=\"line\">    num.mutex.Unlock()  <span class=\"comment\">//任何 goroutine 都可用开锁</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"单写多读锁-RWMutex\"><a href=\"#单写多读锁-RWMutex\" class=\"headerlink\" title=\"单写多读锁 RWMutex\"></a>单写多读锁 RWMutex</h2><p>顾名思义，允许多个线程进行读取，但仅允许单个线程进行写操作。通过 Rlock() 允许同一时间多个线程读操作；如果使用 Lock() ，则 RWMutex 变成 Mutex。<br>RWMutex 的方法有：</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(rw *RWMutex)</span> <span class=\"title\">Lock</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">func</span> <span class=\"params\">(rw *RWMutex)</span> <span class=\"title\">RLock</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">func</span> <span class=\"params\">(rw *RWMutex)</span> <span class=\"title\">RLocker</span><span class=\"params\">()</span> <span class=\"title\">Locker</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">func</span> <span class=\"params\">(rw *RWMutex)</span> <span class=\"title\">RUnlock</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">func</span> <span class=\"params\">(rw *RWMutex)</span> <span class=\"title\">Unlock</span><span class=\"params\">()</span></span></span><br></pre></td></tr></table></figure>\n<p>对应的策略有：</p>\n<ul>\n<li><p><strong>允许存在多个读锁，但只能有一把写锁</strong>；</p>\n</li>\n<li><p><strong>当写锁未被释放时或此时有正被等待的写锁，读锁不可用</strong>；</p>\n</li>\n<li><p><strong>只有当全部读锁结束，写锁才可用</strong>；</p>\n</li>\n</ul>\n<h2 id=\"sync-Once\"><a href=\"#sync-Once\" class=\"headerlink\" title=\"sync.Once\"></a>sync.Once</h2><p>sync.Once 可以保证被调用的 func，只调用一次。<br>Once 数据结构为：</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">type</span> Once <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">\tm Mutex</span><br><span class=\"line\">\tdone <span class=\"keyword\">uint32</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(o *Once)</span> <span class=\"title\">Do</span><span class=\"params\">(f <span class=\"keyword\">func</span>()</span>)</span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> atomic.LoadUint32(&amp;o.done) == <span class=\"number\">1</span> &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span></span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"comment\">// Slow-path.</span></span><br><span class=\"line\">\to.m.Lock()</span><br><span class=\"line\">\t<span class=\"keyword\">defer</span> o.m.Unlock()</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> o.done == <span class=\"number\">0</span> &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">defer</span> atomic.StoreUint32(&amp;o.done, <span class=\"number\">1</span>)</span><br><span class=\"line\">\t\tf()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>由 once.Do 可以看出，当<em>once.Do(f)</em>被调用多次时，只有第一次会调用功能函数 f。其核心思想是，使用原子计数记录被执行的次数。其中的锁机制，仍旧使用<strong>Mutex.</strong></p>\n<p>官方给出的一个示例，及对应的执行结果如下：</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//官方例子</span></span><br><span class=\"line\"><span class=\"keyword\">package</span> main</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> (</span><br><span class=\"line\">\t<span class=\"string\">\"fmt\"</span></span><br><span class=\"line\">\t<span class=\"string\">\"sync\"</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">var</span> once sync.Once</span><br><span class=\"line\">\tonceBody := <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t\tfmt.Println(<span class=\"string\">\"Only once\"</span>)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tdone := <span class=\"built_in\">make</span>(<span class=\"keyword\">chan</span> <span class=\"keyword\">bool</span>)</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i := <span class=\"number\">0</span>; i &lt; <span class=\"number\">10</span>; i++ &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">go</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t\t\tonce.Do(onceBody)</span><br><span class=\"line\">\t\t\tdone &lt;- <span class=\"literal\">true</span></span><br><span class=\"line\">\t\t&#125;()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i := <span class=\"number\">0</span>; i &lt; <span class=\"number\">10</span>; i++ &#123;</span><br><span class=\"line\">\t\t&lt;-done</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 打印输出为：</span></span><br><span class=\"line\">Only once</span><br></pre></td></tr></table></figure>\n<h2 id=\"sync-WaitGroup\"><a href=\"#sync-WaitGroup\" class=\"headerlink\" title=\"sync.WaitGroup\"></a>sync.WaitGroup</h2><blockquote>\n<p>A WaitGroup waits for a collection of goroutines to finish. The main goroutine calls Add to set the number of goroutines to wait for. Then each of the goroutines runs and calls Done when finished. At the same time, Wait can be used to block until all goroutines have finished.</p>\n</blockquote>\n<p>WaitGroup 可以保证集合内所有 goroutines 协程完成后，主进程再执行其他动作。避免协程未执行完，主进程就退出或执行其他影响协程的动作。</p>\n<h3 id=\"WaitGroup-操作方式\"><a href=\"#WaitGroup-操作方式\" class=\"headerlink\" title=\"WaitGroup 操作方式\"></a>WaitGroup 操作方式</h3><p>执行协程前使用 func (<em>WaitGroup) Add 添加等待计数器。协程完成一次，执行 func (</em>WaitGroup) Done，在 waitgroup 计数器中减少一个，直至计数器为零，释放锁。</p>\n<h3 id=\"使用举例\"><a href=\"#使用举例\" class=\"headerlink\" title=\"使用举例\"></a>使用举例</h3><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> main</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> (</span><br><span class=\"line\">\t<span class=\"string\">\"sync\"</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">type</span> httpPkg <span class=\"keyword\">struct</span>&#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(httpPkg)</span> <span class=\"title\">Get</span><span class=\"params\">(url <span class=\"keyword\">string</span>)</span></span> &#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> http httpPkg</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">var</span> wg sync.WaitGroup</span><br><span class=\"line\">\t<span class=\"keyword\">var</span> urls = []<span class=\"keyword\">string</span>&#123;</span><br><span class=\"line\">\t\t<span class=\"string\">\"http://www.golang.org/\"</span>,</span><br><span class=\"line\">\t\t<span class=\"string\">\"http://www.google.com/\"</span>,</span><br><span class=\"line\">\t\t<span class=\"string\">\"http://www.somestupidname.com/\"</span>,</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> _, url := <span class=\"keyword\">range</span> urls &#123;</span><br><span class=\"line\">\t\t<span class=\"comment\">// Increment the WaitGroup counter.</span></span><br><span class=\"line\">\t\twg.Add(<span class=\"number\">1</span>)</span><br><span class=\"line\">\t\t<span class=\"comment\">// Launch a goroutine to fetch the URL.</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">go</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">(url <span class=\"keyword\">string</span>)</span></span> &#123;</span><br><span class=\"line\">\t\t\t<span class=\"comment\">// Decrement the counter when the goroutine completes.</span></span><br><span class=\"line\">\t\t\t<span class=\"keyword\">defer</span> wg.Done()</span><br><span class=\"line\">\t\t\t<span class=\"comment\">// Fetch the URL.</span></span><br><span class=\"line\">\t\t\thttp.Get(url)</span><br><span class=\"line\">\t\t&#125;(url)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"comment\">// Wait for all HTTP fetches to complete.</span></span><br><span class=\"line\">\twg.Wait()</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<p>在程序进行并发操作时，当不同线程使用同一变量时，由于无法判断是否有其他线程在进行写操作，即线程之间出现竞争（资源竞争），因此引入锁机制。<br>Go 语言使用 sync 模块保证线程在操作变量的互斥性。当变量被一个线程操作时，先使用 sync 将变量上锁，退出操作时，解锁。<br>sync 模块提供基础的同步原语，例如互斥锁（mutual exclusion locks）。除了<strong>Once</strong>和<strong>WaitGroup</strong>类型，大部分的 sync 模块的方法使用在低级库。更高级别的同步方式是使用通道（channel）和通信（communication）。<br>本文主要介绍 sync 包内，一些锁的概念及使用方式。</p>\n<h2 id=\"sync-包基础\"><a href=\"#sync-包基础\" class=\"headerlink\" title=\"sync 包基础\"></a>sync 包基础</h2><p>sync 包围绕 sync.Locker 进行，其中 interface 为：</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">type</span> Locker <span class=\"keyword\">interface</span> &#123;</span><br><span class=\"line\">        Lock()</span><br><span class=\"line\">        Unlock()</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"基本锁-Mutex\"><a href=\"#基本锁-Mutex\" class=\"headerlink\" title=\"基本锁 Mutex\"></a>基本锁 Mutex</h2><p>sync.Mutex 是互斥锁，相当于在变量入口处确保只有一个线程能够操作变量。<br>假如 num 是一个需要锁处理的存储在共享内存中的变量。通过 Mutex 处理加锁与解锁。具体例子如下：</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> <span class=\"string\">\"sync\"</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">type</span> num <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">\tmutex sync.Mutex</span><br><span class=\"line\">    nu <span class=\"keyword\">int</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//flash num</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">update</span><span class=\"params\">(num *num)</span></span> &#123;</span><br><span class=\"line\">    num.mutex.Lock()</span><br><span class=\"line\">    <span class=\"comment\">//update num</span></span><br><span class=\"line\">    num.nu = <span class=\"comment\">// new value</span></span><br><span class=\"line\">    num.mutex.Unlock()  <span class=\"comment\">//任何 goroutine 都可用开锁</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"单写多读锁-RWMutex\"><a href=\"#单写多读锁-RWMutex\" class=\"headerlink\" title=\"单写多读锁 RWMutex\"></a>单写多读锁 RWMutex</h2><p>顾名思义，允许多个线程进行读取，但仅允许单个线程进行写操作。通过 Rlock() 允许同一时间多个线程读操作；如果使用 Lock() ，则 RWMutex 变成 Mutex。<br>RWMutex 的方法有：</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(rw *RWMutex)</span> <span class=\"title\">Lock</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">func</span> <span class=\"params\">(rw *RWMutex)</span> <span class=\"title\">RLock</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">func</span> <span class=\"params\">(rw *RWMutex)</span> <span class=\"title\">RLocker</span><span class=\"params\">()</span> <span class=\"title\">Locker</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">func</span> <span class=\"params\">(rw *RWMutex)</span> <span class=\"title\">RUnlock</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">func</span> <span class=\"params\">(rw *RWMutex)</span> <span class=\"title\">Unlock</span><span class=\"params\">()</span></span></span><br></pre></td></tr></table></figure>\n<p>对应的策略有：</p>\n<ul>\n<li><p><strong>允许存在多个读锁，但只能有一把写锁</strong>；</p>\n</li>\n<li><p><strong>当写锁未被释放时或此时有正被等待的写锁，读锁不可用</strong>；</p>\n</li>\n<li><p><strong>只有当全部读锁结束，写锁才可用</strong>；</p>\n</li>\n</ul>\n<h2 id=\"sync-Once\"><a href=\"#sync-Once\" class=\"headerlink\" title=\"sync.Once\"></a>sync.Once</h2><p>sync.Once 可以保证被调用的 func，只调用一次。<br>Once 数据结构为：</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">type</span> Once <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">\tm Mutex</span><br><span class=\"line\">\tdone <span class=\"keyword\">uint32</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(o *Once)</span> <span class=\"title\">Do</span><span class=\"params\">(f <span class=\"keyword\">func</span>()</span>)</span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> atomic.LoadUint32(&amp;o.done) == <span class=\"number\">1</span> &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span></span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"comment\">// Slow-path.</span></span><br><span class=\"line\">\to.m.Lock()</span><br><span class=\"line\">\t<span class=\"keyword\">defer</span> o.m.Unlock()</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> o.done == <span class=\"number\">0</span> &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">defer</span> atomic.StoreUint32(&amp;o.done, <span class=\"number\">1</span>)</span><br><span class=\"line\">\t\tf()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>由 once.Do 可以看出，当<em>once.Do(f)</em>被调用多次时，只有第一次会调用功能函数 f。其核心思想是，使用原子计数记录被执行的次数。其中的锁机制，仍旧使用<strong>Mutex.</strong></p>\n<p>官方给出的一个示例，及对应的执行结果如下：</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//官方例子</span></span><br><span class=\"line\"><span class=\"keyword\">package</span> main</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> (</span><br><span class=\"line\">\t<span class=\"string\">\"fmt\"</span></span><br><span class=\"line\">\t<span class=\"string\">\"sync\"</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">var</span> once sync.Once</span><br><span class=\"line\">\tonceBody := <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t\tfmt.Println(<span class=\"string\">\"Only once\"</span>)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tdone := <span class=\"built_in\">make</span>(<span class=\"keyword\">chan</span> <span class=\"keyword\">bool</span>)</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i := <span class=\"number\">0</span>; i &lt; <span class=\"number\">10</span>; i++ &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">go</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t\t\tonce.Do(onceBody)</span><br><span class=\"line\">\t\t\tdone &lt;- <span class=\"literal\">true</span></span><br><span class=\"line\">\t\t&#125;()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i := <span class=\"number\">0</span>; i &lt; <span class=\"number\">10</span>; i++ &#123;</span><br><span class=\"line\">\t\t&lt;-done</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 打印输出为：</span></span><br><span class=\"line\">Only once</span><br></pre></td></tr></table></figure>\n<h2 id=\"sync-WaitGroup\"><a href=\"#sync-WaitGroup\" class=\"headerlink\" title=\"sync.WaitGroup\"></a>sync.WaitGroup</h2><blockquote>\n<p>A WaitGroup waits for a collection of goroutines to finish. The main goroutine calls Add to set the number of goroutines to wait for. Then each of the goroutines runs and calls Done when finished. At the same time, Wait can be used to block until all goroutines have finished.</p>\n</blockquote>\n<p>WaitGroup 可以保证集合内所有 goroutines 协程完成后，主进程再执行其他动作。避免协程未执行完，主进程就退出或执行其他影响协程的动作。</p>\n<h3 id=\"WaitGroup-操作方式\"><a href=\"#WaitGroup-操作方式\" class=\"headerlink\" title=\"WaitGroup 操作方式\"></a>WaitGroup 操作方式</h3><p>执行协程前使用 func (<em>WaitGroup) Add 添加等待计数器。协程完成一次，执行 func (</em>WaitGroup) Done，在 waitgroup 计数器中减少一个，直至计数器为零，释放锁。</p>\n<h3 id=\"使用举例\"><a href=\"#使用举例\" class=\"headerlink\" title=\"使用举例\"></a>使用举例</h3><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> main</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> (</span><br><span class=\"line\">\t<span class=\"string\">\"sync\"</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">type</span> httpPkg <span class=\"keyword\">struct</span>&#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(httpPkg)</span> <span class=\"title\">Get</span><span class=\"params\">(url <span class=\"keyword\">string</span>)</span></span> &#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> http httpPkg</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">var</span> wg sync.WaitGroup</span><br><span class=\"line\">\t<span class=\"keyword\">var</span> urls = []<span class=\"keyword\">string</span>&#123;</span><br><span class=\"line\">\t\t<span class=\"string\">\"http://www.golang.org/\"</span>,</span><br><span class=\"line\">\t\t<span class=\"string\">\"http://www.google.com/\"</span>,</span><br><span class=\"line\">\t\t<span class=\"string\">\"http://www.somestupidname.com/\"</span>,</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> _, url := <span class=\"keyword\">range</span> urls &#123;</span><br><span class=\"line\">\t\t<span class=\"comment\">// Increment the WaitGroup counter.</span></span><br><span class=\"line\">\t\twg.Add(<span class=\"number\">1</span>)</span><br><span class=\"line\">\t\t<span class=\"comment\">// Launch a goroutine to fetch the URL.</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">go</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">(url <span class=\"keyword\">string</span>)</span></span> &#123;</span><br><span class=\"line\">\t\t\t<span class=\"comment\">// Decrement the counter when the goroutine completes.</span></span><br><span class=\"line\">\t\t\t<span class=\"keyword\">defer</span> wg.Done()</span><br><span class=\"line\">\t\t\t<span class=\"comment\">// Fetch the URL.</span></span><br><span class=\"line\">\t\t\thttp.Get(url)</span><br><span class=\"line\">\t\t&#125;(url)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"comment\">// Wait for all HTTP fetches to complete.</span></span><br><span class=\"line\">\twg.Wait()</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n"},{"title":"usb接口键盘转PS2接口","urlname":"gnh3hv","date":"2019-03-03T15:09:24.000Z","_content":"\n## 用途\n\n公司或者主机设备没有 usb 接口，只能使用 PS/2 接口键盘。此程序完成 USB HID keyboard 协议向 PS/2 的 scan code set 2 转换。\n\n## 需要的硬件设备\n\n1. arduino uno R3\n2. USB Host Shield\n\n## 使用说明\n\n1. 默认 PS/2 接口的的四条数据线中，数据段和时钟段连接在 Arduino 的（4，2）。\n2. 使用 IDE 刷入 usb2ps2.ino 即可\n\n## 源代码地址\n\n[https://github.com/limao693/usb2ps2](https://github.com/limao693/usb2ps2)\n\n## 参考文件\n\n1. [USB HID to PS/2 Scan Code Translation Table](https://download.microsoft.com/download/1/6/1/161ba512-40e2-4cc9-843a-923143f3456c/translate.pdf)\n2. [PS2 键盘接口说明](http://www.burtonsys.com/ps2_chapweske.htm)\n3. [模拟 PS/2 键盘](https://www.arduino.cn/thread-77766-1-1.html)\n\n## Application scenario\n\nThe company or host device does not have a usb interface and can only use the PS/2 interface keyboard. This program completes the conversion of the USB HID keyboard protocol to the PS/2 scan code set 2.\n\n## Required hardware devices\n\n1. Arduino uno R3\n2. USB Host Shield\n\n## Instructions for use\n\n1. Among the four data lines of the default PS/2 interface, the data segment and the clock segment are connected to the Arduino (4, 2).\n2. Use the IDE to brush usb2ps2.ino\n\n## Source code\n\n[https://github.com/limao693/usb2ps2](https://github.com/limao693/usb2ps2)\n\n## reference document\n\n1. [USB HID to PS/2 Scan Code Translation Table](https://download.microsoft.com/download/1/6/1/161ba512-40e2-4cc9-843a-923143f3456c/translate.pdf)\n2. [PS2 Keyboard Interface Description](http://www.burtonsys.com/ps2_chapweske.htm)\n3. [Analog PS/2 Keyboard](https://www.arduino.cn/thread-77766-1-1.html)\n","source":"_posts/usb接口键盘转PS2接口.md","raw":"---\ntitle: usb接口键盘转PS2接口\nurlname: gnh3hv\ndate: 2019-03-03 23:09:24 +0800\ntags: [Arduino,硬件]\ncategories: []\n---\n\n## 用途\n\n公司或者主机设备没有 usb 接口，只能使用 PS/2 接口键盘。此程序完成 USB HID keyboard 协议向 PS/2 的 scan code set 2 转换。\n\n## 需要的硬件设备\n\n1. arduino uno R3\n2. USB Host Shield\n\n## 使用说明\n\n1. 默认 PS/2 接口的的四条数据线中，数据段和时钟段连接在 Arduino 的（4，2）。\n2. 使用 IDE 刷入 usb2ps2.ino 即可\n\n## 源代码地址\n\n[https://github.com/limao693/usb2ps2](https://github.com/limao693/usb2ps2)\n\n## 参考文件\n\n1. [USB HID to PS/2 Scan Code Translation Table](https://download.microsoft.com/download/1/6/1/161ba512-40e2-4cc9-843a-923143f3456c/translate.pdf)\n2. [PS2 键盘接口说明](http://www.burtonsys.com/ps2_chapweske.htm)\n3. [模拟 PS/2 键盘](https://www.arduino.cn/thread-77766-1-1.html)\n\n## Application scenario\n\nThe company or host device does not have a usb interface and can only use the PS/2 interface keyboard. This program completes the conversion of the USB HID keyboard protocol to the PS/2 scan code set 2.\n\n## Required hardware devices\n\n1. Arduino uno R3\n2. USB Host Shield\n\n## Instructions for use\n\n1. Among the four data lines of the default PS/2 interface, the data segment and the clock segment are connected to the Arduino (4, 2).\n2. Use the IDE to brush usb2ps2.ino\n\n## Source code\n\n[https://github.com/limao693/usb2ps2](https://github.com/limao693/usb2ps2)\n\n## reference document\n\n1. [USB HID to PS/2 Scan Code Translation Table](https://download.microsoft.com/download/1/6/1/161ba512-40e2-4cc9-843a-923143f3456c/translate.pdf)\n2. [PS2 Keyboard Interface Description](http://www.burtonsys.com/ps2_chapweske.htm)\n3. [Analog PS/2 Keyboard](https://www.arduino.cn/thread-77766-1-1.html)\n","slug":"usb接口键盘转PS2接口","published":1,"updated":"2020-05-28T16:57:36.123Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckasagnht0008x396o3hx3qts","content":"<h2 id=\"用途\"><a href=\"#用途\" class=\"headerlink\" title=\"用途\"></a>用途</h2><p>公司或者主机设备没有 usb 接口，只能使用 PS/2 接口键盘。此程序完成 USB HID keyboard 协议向 PS/2 的 scan code set 2 转换。</p>\n<h2 id=\"需要的硬件设备\"><a href=\"#需要的硬件设备\" class=\"headerlink\" title=\"需要的硬件设备\"></a>需要的硬件设备</h2><ol>\n<li>arduino uno R3</li>\n<li>USB Host Shield</li>\n</ol>\n<h2 id=\"使用说明\"><a href=\"#使用说明\" class=\"headerlink\" title=\"使用说明\"></a>使用说明</h2><ol>\n<li>默认 PS/2 接口的的四条数据线中，数据段和时钟段连接在 Arduino 的（4，2）。</li>\n<li>使用 IDE 刷入 usb2ps2.ino 即可</li>\n</ol>\n<h2 id=\"源代码地址\"><a href=\"#源代码地址\" class=\"headerlink\" title=\"源代码地址\"></a>源代码地址</h2><p><a href=\"https://github.com/limao693/usb2ps2\" target=\"_blank\" rel=\"noopener\">https://github.com/limao693/usb2ps2</a></p>\n<h2 id=\"参考文件\"><a href=\"#参考文件\" class=\"headerlink\" title=\"参考文件\"></a>参考文件</h2><ol>\n<li><a href=\"https://download.microsoft.com/download/1/6/1/161ba512-40e2-4cc9-843a-923143f3456c/translate.pdf\" target=\"_blank\" rel=\"noopener\">USB HID to PS/2 Scan Code Translation Table</a></li>\n<li><a href=\"http://www.burtonsys.com/ps2_chapweske.htm\" target=\"_blank\" rel=\"noopener\">PS2 键盘接口说明</a></li>\n<li><a href=\"https://www.arduino.cn/thread-77766-1-1.html\" target=\"_blank\" rel=\"noopener\">模拟 PS/2 键盘</a></li>\n</ol>\n<h2 id=\"Application-scenario\"><a href=\"#Application-scenario\" class=\"headerlink\" title=\"Application scenario\"></a>Application scenario</h2><p>The company or host device does not have a usb interface and can only use the PS/2 interface keyboard. This program completes the conversion of the USB HID keyboard protocol to the PS/2 scan code set 2.</p>\n<h2 id=\"Required-hardware-devices\"><a href=\"#Required-hardware-devices\" class=\"headerlink\" title=\"Required hardware devices\"></a>Required hardware devices</h2><ol>\n<li>Arduino uno R3</li>\n<li>USB Host Shield</li>\n</ol>\n<h2 id=\"Instructions-for-use\"><a href=\"#Instructions-for-use\" class=\"headerlink\" title=\"Instructions for use\"></a>Instructions for use</h2><ol>\n<li>Among the four data lines of the default PS/2 interface, the data segment and the clock segment are connected to the Arduino (4, 2).</li>\n<li>Use the IDE to brush usb2ps2.ino</li>\n</ol>\n<h2 id=\"Source-code\"><a href=\"#Source-code\" class=\"headerlink\" title=\"Source code\"></a>Source code</h2><p><a href=\"https://github.com/limao693/usb2ps2\" target=\"_blank\" rel=\"noopener\">https://github.com/limao693/usb2ps2</a></p>\n<h2 id=\"reference-document\"><a href=\"#reference-document\" class=\"headerlink\" title=\"reference document\"></a>reference document</h2><ol>\n<li><a href=\"https://download.microsoft.com/download/1/6/1/161ba512-40e2-4cc9-843a-923143f3456c/translate.pdf\" target=\"_blank\" rel=\"noopener\">USB HID to PS/2 Scan Code Translation Table</a></li>\n<li><a href=\"http://www.burtonsys.com/ps2_chapweske.htm\" target=\"_blank\" rel=\"noopener\">PS2 Keyboard Interface Description</a></li>\n<li><a href=\"https://www.arduino.cn/thread-77766-1-1.html\" target=\"_blank\" rel=\"noopener\">Analog PS/2 Keyboard</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"用途\"><a href=\"#用途\" class=\"headerlink\" title=\"用途\"></a>用途</h2><p>公司或者主机设备没有 usb 接口，只能使用 PS/2 接口键盘。此程序完成 USB HID keyboard 协议向 PS/2 的 scan code set 2 转换。</p>\n<h2 id=\"需要的硬件设备\"><a href=\"#需要的硬件设备\" class=\"headerlink\" title=\"需要的硬件设备\"></a>需要的硬件设备</h2><ol>\n<li>arduino uno R3</li>\n<li>USB Host Shield</li>\n</ol>\n<h2 id=\"使用说明\"><a href=\"#使用说明\" class=\"headerlink\" title=\"使用说明\"></a>使用说明</h2><ol>\n<li>默认 PS/2 接口的的四条数据线中，数据段和时钟段连接在 Arduino 的（4，2）。</li>\n<li>使用 IDE 刷入 usb2ps2.ino 即可</li>\n</ol>\n<h2 id=\"源代码地址\"><a href=\"#源代码地址\" class=\"headerlink\" title=\"源代码地址\"></a>源代码地址</h2><p><a href=\"https://github.com/limao693/usb2ps2\" target=\"_blank\" rel=\"noopener\">https://github.com/limao693/usb2ps2</a></p>\n<h2 id=\"参考文件\"><a href=\"#参考文件\" class=\"headerlink\" title=\"参考文件\"></a>参考文件</h2><ol>\n<li><a href=\"https://download.microsoft.com/download/1/6/1/161ba512-40e2-4cc9-843a-923143f3456c/translate.pdf\" target=\"_blank\" rel=\"noopener\">USB HID to PS/2 Scan Code Translation Table</a></li>\n<li><a href=\"http://www.burtonsys.com/ps2_chapweske.htm\" target=\"_blank\" rel=\"noopener\">PS2 键盘接口说明</a></li>\n<li><a href=\"https://www.arduino.cn/thread-77766-1-1.html\" target=\"_blank\" rel=\"noopener\">模拟 PS/2 键盘</a></li>\n</ol>\n<h2 id=\"Application-scenario\"><a href=\"#Application-scenario\" class=\"headerlink\" title=\"Application scenario\"></a>Application scenario</h2><p>The company or host device does not have a usb interface and can only use the PS/2 interface keyboard. This program completes the conversion of the USB HID keyboard protocol to the PS/2 scan code set 2.</p>\n<h2 id=\"Required-hardware-devices\"><a href=\"#Required-hardware-devices\" class=\"headerlink\" title=\"Required hardware devices\"></a>Required hardware devices</h2><ol>\n<li>Arduino uno R3</li>\n<li>USB Host Shield</li>\n</ol>\n<h2 id=\"Instructions-for-use\"><a href=\"#Instructions-for-use\" class=\"headerlink\" title=\"Instructions for use\"></a>Instructions for use</h2><ol>\n<li>Among the four data lines of the default PS/2 interface, the data segment and the clock segment are connected to the Arduino (4, 2).</li>\n<li>Use the IDE to brush usb2ps2.ino</li>\n</ol>\n<h2 id=\"Source-code\"><a href=\"#Source-code\" class=\"headerlink\" title=\"Source code\"></a>Source code</h2><p><a href=\"https://github.com/limao693/usb2ps2\" target=\"_blank\" rel=\"noopener\">https://github.com/limao693/usb2ps2</a></p>\n<h2 id=\"reference-document\"><a href=\"#reference-document\" class=\"headerlink\" title=\"reference document\"></a>reference document</h2><ol>\n<li><a href=\"https://download.microsoft.com/download/1/6/1/161ba512-40e2-4cc9-843a-923143f3456c/translate.pdf\" target=\"_blank\" rel=\"noopener\">USB HID to PS/2 Scan Code Translation Table</a></li>\n<li><a href=\"http://www.burtonsys.com/ps2_chapweske.htm\" target=\"_blank\" rel=\"noopener\">PS2 Keyboard Interface Description</a></li>\n<li><a href=\"https://www.arduino.cn/thread-77766-1-1.html\" target=\"_blank\" rel=\"noopener\">Analog PS/2 Keyboard</a></li>\n</ol>\n"},{"title":"RPC调用","urlname":"etrzfl","date":"2019-06-03T03:41:05.000Z","_content":"\n### 知识点\n\n#### Target\n\nan RPC Server's target:\n       topic and server is required; exchange is optional\nan RPC endpoint's target:\n       namespace and version is optional\nan RPC client sending a message:\n       topic is required, all other attributes optional\na Notification Server's target:\n       topic is required, exchange is optional; all other attributes ignored\na Notifier's target:\n       topic is required, exchange is optional; all other attributes ignored\n","source":"_posts/RPC调用.md","raw":"---\ntitle: RPC调用\nurlname: etrzfl\ndate: 2019-06-03 11:41:05 +0800\ntags: [rpc,HTTP]\ncategories: []\n---\n\n### 知识点\n\n#### Target\n\nan RPC Server's target:\n       topic and server is required; exchange is optional\nan RPC endpoint's target:\n       namespace and version is optional\nan RPC client sending a message:\n       topic is required, all other attributes optional\na Notification Server's target:\n       topic is required, exchange is optional; all other attributes ignored\na Notifier's target:\n       topic is required, exchange is optional; all other attributes ignored\n","slug":"RPC调用","published":1,"updated":"2020-05-28T16:57:36.083Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckasagnhv0009x396w0dcyw65","content":"<h3 id=\"知识点\"><a href=\"#知识点\" class=\"headerlink\" title=\"知识点\"></a>知识点</h3><h4 id=\"Target\"><a href=\"#Target\" class=\"headerlink\" title=\"Target\"></a>Target</h4><p>an RPC Server’s target:<br>       topic and server is required; exchange is optional<br>an RPC endpoint’s target:<br>       namespace and version is optional<br>an RPC client sending a message:<br>       topic is required, all other attributes optional<br>a Notification Server’s target:<br>       topic is required, exchange is optional; all other attributes ignored<br>a Notifier’s target:<br>       topic is required, exchange is optional; all other attributes ignored</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"知识点\"><a href=\"#知识点\" class=\"headerlink\" title=\"知识点\"></a>知识点</h3><h4 id=\"Target\"><a href=\"#Target\" class=\"headerlink\" title=\"Target\"></a>Target</h4><p>an RPC Server’s target:<br>       topic and server is required; exchange is optional<br>an RPC endpoint’s target:<br>       namespace and version is optional<br>an RPC client sending a message:<br>       topic is required, all other attributes optional<br>a Notification Server’s target:<br>       topic is required, exchange is optional; all other attributes ignored<br>a Notifier’s target:<br>       topic is required, exchange is optional; all other attributes ignored</p>\n"},{"title":"搭建hexo博客，Travis持续集成","date":"2019-01-04T15:49:16.000Z","_content":"\n[TOC]\n\n基于macOs搭建\n\n# 建立远程仓库\n\n1. 建立以个人github域名为名的软件仓库，例如`abc.github.com`，则建立`abc.github.io`的软件仓库。\n\n2. 在软件仓库中，setting设置个人域名为`abc.github.io`。\n\n# 本地准备\n\n安装`git`，`homebrew`，`node.js`，`hexo`。\n\n1. 安装homebrew\n\n    macos建议使用`homebrew`进行软件安装，对应命令为：\n\n```shell\n\n/usr/bin/ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\" \n\n```\n\n2. 安装git\n\n    使用git版本管理工具，与GitHub进行通信\n\n```shell\n\nbrew install git\n\n```\n\n## 安装hexo\n\n## 创建本地文件\n\n# Hello World\n","source":"_posts/搭建hexo博客，Travis持续集成.md","raw":"---\ntitle: 搭建hexo博客，Travis持续集成\ndate: 2019-01-04 23:49:16\ntags:\n---\n\n[TOC]\n\n基于macOs搭建\n\n# 建立远程仓库\n\n1. 建立以个人github域名为名的软件仓库，例如`abc.github.com`，则建立`abc.github.io`的软件仓库。\n\n2. 在软件仓库中，setting设置个人域名为`abc.github.io`。\n\n# 本地准备\n\n安装`git`，`homebrew`，`node.js`，`hexo`。\n\n1. 安装homebrew\n\n    macos建议使用`homebrew`进行软件安装，对应命令为：\n\n```shell\n\n/usr/bin/ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\" \n\n```\n\n2. 安装git\n\n    使用git版本管理工具，与GitHub进行通信\n\n```shell\n\nbrew install git\n\n```\n\n## 安装hexo\n\n## 创建本地文件\n\n# Hello World\n","slug":"搭建hexo博客，Travis持续集成","published":1,"updated":"2020-05-28T16:59:39.252Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckasagnhz000bx396uuwiuoqo","content":"<p>[TOC]</p>\n<p>基于macOs搭建</p>\n<h1 id=\"建立远程仓库\"><a href=\"#建立远程仓库\" class=\"headerlink\" title=\"建立远程仓库\"></a>建立远程仓库</h1><ol>\n<li><p>建立以个人github域名为名的软件仓库，例如<code>abc.github.com</code>，则建立<code>abc.github.io</code>的软件仓库。</p>\n</li>\n<li><p>在软件仓库中，setting设置个人域名为<code>abc.github.io</code>。</p>\n</li>\n</ol>\n<h1 id=\"本地准备\"><a href=\"#本地准备\" class=\"headerlink\" title=\"本地准备\"></a>本地准备</h1><p>安装<code>git</code>，<code>homebrew</code>，<code>node.js</code>，<code>hexo</code>。</p>\n<ol>\n<li><p>安装homebrew</p>\n<p> macos建议使用<code>homebrew</code>进行软件安装，对应命令为：</p>\n</li>\n</ol>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">/usr/bin/ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\"</span><br></pre></td></tr></table></figure>\n<ol start=\"2\">\n<li><p>安装git</p>\n<p> 使用git版本管理工具，与GitHub进行通信</p>\n</li>\n</ol>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">brew install git</span><br></pre></td></tr></table></figure>\n<h2 id=\"安装hexo\"><a href=\"#安装hexo\" class=\"headerlink\" title=\"安装hexo\"></a>安装hexo</h2><h2 id=\"创建本地文件\"><a href=\"#创建本地文件\" class=\"headerlink\" title=\"创建本地文件\"></a>创建本地文件</h2><h1 id=\"Hello-World\"><a href=\"#Hello-World\" class=\"headerlink\" title=\"Hello World\"></a>Hello World</h1>","site":{"data":{}},"excerpt":"","more":"<p>[TOC]</p>\n<p>基于macOs搭建</p>\n<h1 id=\"建立远程仓库\"><a href=\"#建立远程仓库\" class=\"headerlink\" title=\"建立远程仓库\"></a>建立远程仓库</h1><ol>\n<li><p>建立以个人github域名为名的软件仓库，例如<code>abc.github.com</code>，则建立<code>abc.github.io</code>的软件仓库。</p>\n</li>\n<li><p>在软件仓库中，setting设置个人域名为<code>abc.github.io</code>。</p>\n</li>\n</ol>\n<h1 id=\"本地准备\"><a href=\"#本地准备\" class=\"headerlink\" title=\"本地准备\"></a>本地准备</h1><p>安装<code>git</code>，<code>homebrew</code>，<code>node.js</code>，<code>hexo</code>。</p>\n<ol>\n<li><p>安装homebrew</p>\n<p> macos建议使用<code>homebrew</code>进行软件安装，对应命令为：</p>\n</li>\n</ol>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">/usr/bin/ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\"</span><br></pre></td></tr></table></figure>\n<ol start=\"2\">\n<li><p>安装git</p>\n<p> 使用git版本管理工具，与GitHub进行通信</p>\n</li>\n</ol>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">brew install git</span><br></pre></td></tr></table></figure>\n<h2 id=\"安装hexo\"><a href=\"#安装hexo\" class=\"headerlink\" title=\"安装hexo\"></a>安装hexo</h2><h2 id=\"创建本地文件\"><a href=\"#创建本地文件\" class=\"headerlink\" title=\"创建本地文件\"></a>创建本地文件</h2><h1 id=\"Hello-World\"><a href=\"#Hello-World\" class=\"headerlink\" title=\"Hello World\"></a>Hello World</h1>"},{"title":"Kafka - - 快速入门指南","urlname":"baugo6","date":"2019-02-01T10:41:49.000Z","_content":"\n## 简介\n\nKafka 起源于 2011 年 LikedIn 的开源项目，并不断发展。如今它是一个完整的平台，允许您冗余地存储巨大的数据量，拥有一个具有巨大吞吐量（数百万/秒）的消息总线，同时可实现实时流处理。\n\nKafka 具备的特性有：**分布式、水平扩展、高容错和日志管理**。接下来将逐个介绍特性。\n\n### 分布式\n\n分布式系统的显著特点是将任务分配到多个机器处理，即组成的集群对外暴露的形式仍为单一节点。Kafka 的分布特性在于在不同节点（代理）存储、接收和发送消息。\n\n> 分布式系统的介绍可以参阅：[A Thorough Introduction to Distributed Systems](https://medium.freecodecamp.org/a-thorough-introduction-to-distributed-systems-3b91562c9b3c)\n\n分布式系统的优势主要体现在：高可扩展性、容错性。\n\n### 水平扩展\n\n首先解释、定义垂直扩展。例如，数据库服务器过载，最直接的解决办法是添加资源（CPU、RAM 和 SSD）。垂直扩展的两大缺点是：\n\n- 现有的硬件限制了扩展能力。例如不能无线提高 CPU 核数。\n- 通常需要停机时间。\n\n**水平扩展**通过投入更多的机器来解决上述问题。添加新机器不需要停机，也没有机器数量的限制。它的缺点是，并非所有系统支持水平弹性伸缩，因为在设计之初没有考虑工作在集群环境下，同时设计也更为复杂。\n![](https://cdn.nlark.com/yuque/0/2019/jpeg/250680/1550673729515-587ccc54-647c-4f27-a36f-08848fd77da0.jpeg#align=left&display=inline&height=389&originHeight=389&originWidth=400&size=0&status=done&width=400)\n\n### 高容错性\n\n非分布式系统的一大安全隐患是单点故障（single point of failure, SPOF）。例如单实例数据库宕机，会产生无法估量的损失。\n分布式系统被设计为可配置的方式，来处理故障。例如，在 5 节点的 Kafka 集群中，即使其中两个节点关闭，系统仍然继续工作。需要注意的地方是，系统容错率与系统性能成反比，即容错率越高，性能越低。\n\n### 日志采集\n\n日志采集（事务日志）仅支持附加的持久有序数据结构，即无法修改或删除已有的记录。读取顺序从左向右如图所示。\n![](https://cdn.nlark.com/yuque/0/2019/jpeg/250680/1550675101681-613e5d8c-b7f7-4800-8c6e-f0c7a41dae65.jpeg#align=left&display=inline&height=187&originHeight=187&originWidth=396&size=0&status=done&width=396)\n在某种程度来讲，Kafka 的数据结构就是如此简单。这也是 Kafka 的核心，因为它提供了有序数据，而有序的数据结构提供了确定性的处理方式。\nKafka 实际上将所有消息存储在磁盘上，并且对他们进行排序，最大化利用硬盘顺序读取速度快的优势。\n\n- 读取和写入是整数级别 O(1)（知道记录 ID），与磁盘上的其他数据结构的操作复杂度为 O(log N)相比，有巨大优势。\n- 读取和写入是分离的。写入时不会锁定读取，反之亦然（与平衡树相反）。\n\n这两点使得 Kafka 的性能有巨大优势，因为系统性能与数据量是分离的。Kafka 无论处理 100KB 的数据量还是 100TB 的数据量，性能都是一样的。\n\n## 工作原理\n\n向 Kafka 节点（broker）发送消息（记录）的称为程序（生产者），发送给其他程序处理消息的称为消费者。产生的消息存储在一个**topic**内，消费者订阅向 topic 订阅后，可以接收到对应 topic 的新消息。\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1550761835264-486e6737-07e1-4bbb-aae7-4e09b7888f77.png#align=left&display=inline&height=178&name=image.png&originHeight=180&originWidth=258&size=8295&status=done&width=255)\n随着 topic 变得越来越大，为保持性能和可伸缩性将 topic 拆分成更小的分区。（例如，需要存储用户的登录名，可以将用户名按照首字母进行拆分存储在不同的分区）\nKafka 保证分区内的所有消息都按照它们进入的顺序排序。区分特定消息的方式是通过其**偏移量** ，可将其视为普通数组索引，在一个分区的序列号随着新消息进入而递增。\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1550762596583-9e4702c2-cd98-410f-8587-2f2a17cbfaea.png#align=left&display=inline&height=182&name=image.png&originHeight=267&originWidth=416&size=19550&status=done&width=283)\nKafka 遵循愚蠢的 broker 和聪明的消费者原则。意思是，Kafka 不会跟踪哪一条记录已经被消费者读取并删除，而是将他们按照一定的时间（例如一天）或约定某个阈值大小来存储。消费者自身从 Kafka 的 broker**主动拉取**新信息，并告知他们想要读取的片段。这意味着 broker 允许消费者按照自身的需要进行增加或减小偏移量，因此具有重新读取和重新处理信息的能力。\n需要注意的是，消费者其实是消费者群组，包含一个或多个消费进程。为避免两个进程重复读取相同的信息，每个分区仅与每个组的一个消费者进程相关联。\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1550763797220-d9a12e85-f1df-477c-adf7-ce92ddbeb9ac.png#align=left&display=inline&height=331&name=image.png&originHeight=661&originWidth=2000&size=238955&status=done&width=1000)\n\n## 数据持久化\n\nKafka 将所有记录存储在磁盘，并且不会在 RAM 中保存任何记录。你可能会惊讶于以怎样高效的方式来做明智的选择。这背后有很多值得学习的优化知识：\n\n1. Kafka 有将成组的消息合并的协议。允许网络请求将消息组合在一起减少网络开销，因此服务器一次性保留大量消息，消费者一次获取巨大的线性消息块。\n1. 磁盘顺序 I/O 读取速度很快。现代磁盘速度慢的原因是由于大量的磁盘寻道，但是在大型线性读写操作时不是问题。\n1. 线性操作由 OS 进一步优化，通过**预读取**（预读取多倍数据块）和**后写入**（将小的逻辑写入操作合并为组后再进行物理写入操作）技术。\n1. 现代 OS 利用 RAM 模拟磁盘缓存，这种技术成为 pagecache。\n1. 由于 kafka 在整个流程（生产者--->代理--->消费者）中以未经修改的标准化二进制格式存储消息，因此它可以使用**零拷贝**（zero-copy）优化。操作系统将数据从 pagecache 直接复制到套接字，有效地完全绕过了 Kafka 代理应用程序。\n\n所有这些优化都使 Kafka 能够从接近网络的速度传输消息。\n\n## 数据分发和复制\n\n在这个章节，我们讨论 Kafka 如何实现容错以及它如何在节点之间分配数据。\n\n### 数据复制\n\n分区数据在多个代理（broker）中复制，以便在其中一个代理挂掉时候，依然能够保存数据。\n在任何时候，一个代理（broker）“拥有”其中一个分区，节点通过这个分区进行读写操作。因此，此分区被称为**分区领导者**（partition leader）。将接收到的数据复制给其他***N***个其他代理，称为**跟随者**（followers）。跟随者同样存储数据，并且随时准备着当 leader 挂掉时，取而代之。\n这样的配置有助于保证任何成功发布的消息都不会丢失。通过更改复制因子，可以根据数据的重要性来交换性能以获得更强的持久性保证。\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1551192978691-57bdf14e-90a0-47df-8aeb-60224ba6254c.png#align=left&display=inline&height=765&name=image.png&originHeight=1531&originWidth=2600&size=422840&status=done&width=1300)\n在其中一个 leader 挂掉时，其他 follower 会竞选上岗，具体算法可以参考：\n[_How does a producer/consumer know who the leader of a partition is?_](https://community.hortonworks.com/questions/149532/how-producer-and-consumer-identify-the-leader-in-k.html)\n作为生产者/消费者，对一个分区进行读取时，首先需要知道对应分区的 leader。这个信息需要存储在可以被访问到的地方，Kafka 使用 Zookeeper 进行存储这些元数据。\n\n### 何为 Zookeeper\n\nZookeeper 是一个分布式键值存储结构。它针对读取进行了高度优化，但写入速度较慢。常应用于存储元数据和处理集群的核心机制（心跳包、分发更新配置等）。\n它允许服务（Kafka 的 broker）的客户订阅通知，并且能在 Zookeeper 发生变动的时候发送给客户消息。这也是为什么 brokers 能够感知分区的 leader 发生变动。Zookeeper 同时也具有成熟的容错性，或者说，Kafka 很大程度上依赖 Zookeeper 的高容错性。\nZookeeper 用于存储所有类型的元数据，包括但不限于：\n\n- 消费者群组中每个分区的偏移量（尽管现在的客户端在单独的 Kafka 主题 Topic 内存储偏移量）\n- ACL（访问控制列表），用于限制访问/授权\n- 生产者和消费者配额，包括每秒最大信息量\n- 存储分区 leader 和健康状态\n\n### 如何区分分区的领导者\n\n在以往版本中，生产者和消费者经常直接连接并与 Zookeeper 交谈以获取此（和其他）信息。  目前 Kafka 已经弃用这种耦合，从 0.8 和 0.9 版本开始，客户端直接从 Kafka 的 brokers 那里获取元数据信息，他们自己与 Zookeeper 交谈。\n\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1551274509585-90480e7a-f43d-4959-9703-a908c3983f5f.png#align=left&display=inline&height=1076&name=image.png&originHeight=2152&originWidth=2000&size=462646&status=done&width=1000)\n\n## 流\n\n在 Kafka 中，流处理器是从输入的 Topic 中连续读取数据流，并对数据进行一些处理生成数据流以生成主题的任何（或外部服务、数据库、垃圾箱等）内容。\n对于一些简单的消息，可能使用消费者或生产者的 API 接口直接处理即可，但是涉及到复杂的消息流（例如，多条数据流联合）处理的情况，Kafka 提供一个集成的[Stream API](https://kafka.apache.org/documentation/streams/)库。\n此 API 应用于自己的代码块中，而不是直接在代理（broker）上运行。它与消费者 API 类似，可以帮助你在多个应用（类似多个消费者）上扩展流处理工作。\n\n### 无状态处理\n\n流的无状态处理是确定性的，不需要依赖任何外部的处理方式。对于任何给定的数据，将始终生成与其他内容无关的相同输入。\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1551280756166-0643b4f0-57aa-483b-b51f-ff4d42fc174e.png#align=left&display=inline&height=381&name=image.png&originHeight=762&originWidth=2600&size=233348&status=done&width=1300)\n\n### 流式表的双重性\n\n首先要认识到流和表是相同的含义。流，可以解释为表，反之亦然。\n\n### 流作为表\n\n流可以看做对数据进行一系列的更新，因此最终结果作为表进行聚合。这种技术成为事件采集（Event sourcing）。\n如果你了解如何实现同步数据库的复制，你会知道它是通过所谓的流复制（**Streaming replication**），每次表格中的变动都会发送到副本服务器。事件采集的另外一个例子是，区块链分类账，它也是进行一系列变化。\nKafka 的数据流可以用相同的方式解释，即可以认为是积累到最终的状态的事件。此类流聚合保存在本地 RocksDB 中，称为**KTable**。\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1551281577256-6c7efae0-3e86-4379-9b28-3a6870bb826a.png#align=left&display=inline&height=343&name=image.png&originHeight=686&originWidth=2000&size=219233&status=done&width=1000)\n\n### 表作为流\n\n可以将表视为流中每个键的最新值的快照。  以相同的方式，流记录可以生成表，表更新可以生成更改日志流。\n\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1551281769435-7f51d3f6-30f3-4ae8-9018-19d0ebfb11a9.png#align=left&display=inline&height=646&name=image.png&originHeight=1291&originWidth=1600&size=350243&status=done&width=800)\n\n### 有状态处理\n\n一些简单的操作，例如`map()`或者`filter()`都是无状态的，不需要额外保存有关处理的任何数据。但是，在现实生活中，大部分操作都是有状态的（例如`count()`），因此需要保存当前积累的值。\n假如在流处理器上维护这些状态，流处理器可能会宕机，导致状态丢失。那么应当在哪里保存状态值才能容错呢？\n一种最简单的方式是简单地将所有状态存储在远程数据库中，并通过网络连接到该数据库。这样做的问题是，没有数据的位置和产生大量的网络交互损耗，这两者都会显着减慢您的应用程序。  一个更微妙但重要的问题是您的流处理作业的正常运行时间将紧密耦合到远程数据库，并且作业将不会自包含*（数据库中的数据库与另一个团队的更改可能会破坏您的处理）* 。\n回忆下表和流的二元性。运行我们将流转化为与我们处理位于同一位置的表。它还能提供一种处理容错的机制，即在 Kafka 的 Broker 中存储流。\n数据流处理器能够在本地表（即，RocksDB）存储状态，该表将从输入流（可能实在某些任意变换之后）更新。当进程失败时，可以通过重新请求流来恢复其数据。\n你也可以使用一个远程数据库作为流的生产者，用于在本地重建表进行高效的广播更改日志。\n\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1551282823033-1e7dcc9e-c2a2-4130-b972-b1c1776bd0f1.png#align=left&display=inline&height=729&name=image.png&originHeight=1458&originWidth=2000&size=234952&status=done&width=1000)\n\n## KSQL\n\n通常，使用 Kafka 只能使用 JVM 语言编写刘处理，因为这是 Kafka 唯一的官方 Streams API 客户端。\n\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1551799835544-909daa5c-d2ad-4f30-9060-496ba185feaf.png#align=left&display=inline&height=772&name=image.png&originHeight=1543&originWidth=1600&size=165449&status=done&width=800)\n2018.04 的 Kafka 发布**KSQL**，一种可以使用类 SQL 语言来编写简单流媒体工作的工具。\n通过设置 KSQL 服务器，并且通过 CLI 方式进行交互以此来管理处理。它使用相同的抽象（KStream 和 KTable），保证了 StreamS API 的相同有点（可伸缩性、容错性）和更加简便的方式处理工作流。\n这个特性虽然不被人经常提起，但经过实践对于测试更有用，甚至运行开发之外的人（例如，产品所有者）使用流处理。\n\n### 流的可选择性\n\nKafka 的流兼具了力量和简约的完美结合。可是说是市场上处理流工作的最佳工具，与其他流处理工具（Storm、Samza、Spark 和 Wallaroo）相比，Kafka 更容易与其他工具结合。\n大多数其他流处理的框架的问题在于它们运行和部署的复杂性。例如 Spark 这样的处理框架需要以下几点：\n\n1. 在一组计算机上控制大量的作业，并在集群上有效的分配。\n1. 为此，必须动态打包你的程序并将其部署在它需要执行的节点（以及配置、库等）。\n\n为此，要处理以上问题，使得框架尤为复杂。它们需要控制很多方面：部署、配置、监控和打包。\nKafka 流能够允许你在你需要时，提出自己的部署策略，例如 Kubernetes、Mesos、Nomad、Docker Swarm 或者其他方式。\nKafka Streams 的基本目的是使所有应用程序能够进行流处理，而无需运行和维护另一个操作复杂的集群。  唯一潜在的缺点是它与卡夫卡紧密结合，但在现代世界中，大多数（如果不是全部）实时处理由卡夫卡提供动力可能不是一个很大的劣势。\n\n## 何时启用 Kafka\n\n正如我们已经介绍的，Kafka 允许通过集中式介质获取大量消息并且存储他们，并不担心性能或数据丢失等问题。\n这意味着非常适合用在系统框架的核心，充当连接不同程序的中间媒介。Kafka 能够成为事件驱动架构的中心部分，是您能够真正的将应用程序间解耦。\n\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1551888348371-8ade2e7b-bab2-4c43-9172-231a08b074c0.png#align=left&display=inline&height=337&name=image.png&originHeight=674&originWidth=900&size=432210&status=done&width=450)\nKafka 能够非常轻松的分离不同（微）服务之间的通信。使用 Streams API，现在可以更容易的编写业务逻辑，从而丰富 Kafka 主题数据以便提供服务。\n\n## 总结\n\nApache Kafka 作为分布式流平台，每天可以处理数以万亿计的事件。Kafka 提供低延迟、高吞吐量、高容错和订阅式流水线，同时能够流式处理事件。\n我们回顾了它的基本语义（生产者、代理、消费者和 Topic），了解了它的一些优化（page cache），通过复制数据了解了它的容错能力，并且介绍了它不断增长的强大流功能。\n","source":"_posts/Kafka - - 快速入门指南.md","raw":"---\ntitle: Kafka - - 快速入门指南\nurlname: baugo6\ndate: 2019-02-01 18:41:49 +0800\ntags: [珠峰翻译计划,Kafka]\ncategories: []\n---\n\n## 简介\n\nKafka 起源于 2011 年 LikedIn 的开源项目，并不断发展。如今它是一个完整的平台，允许您冗余地存储巨大的数据量，拥有一个具有巨大吞吐量（数百万/秒）的消息总线，同时可实现实时流处理。\n\nKafka 具备的特性有：**分布式、水平扩展、高容错和日志管理**。接下来将逐个介绍特性。\n\n### 分布式\n\n分布式系统的显著特点是将任务分配到多个机器处理，即组成的集群对外暴露的形式仍为单一节点。Kafka 的分布特性在于在不同节点（代理）存储、接收和发送消息。\n\n> 分布式系统的介绍可以参阅：[A Thorough Introduction to Distributed Systems](https://medium.freecodecamp.org/a-thorough-introduction-to-distributed-systems-3b91562c9b3c)\n\n分布式系统的优势主要体现在：高可扩展性、容错性。\n\n### 水平扩展\n\n首先解释、定义垂直扩展。例如，数据库服务器过载，最直接的解决办法是添加资源（CPU、RAM 和 SSD）。垂直扩展的两大缺点是：\n\n- 现有的硬件限制了扩展能力。例如不能无线提高 CPU 核数。\n- 通常需要停机时间。\n\n**水平扩展**通过投入更多的机器来解决上述问题。添加新机器不需要停机，也没有机器数量的限制。它的缺点是，并非所有系统支持水平弹性伸缩，因为在设计之初没有考虑工作在集群环境下，同时设计也更为复杂。\n![](https://cdn.nlark.com/yuque/0/2019/jpeg/250680/1550673729515-587ccc54-647c-4f27-a36f-08848fd77da0.jpeg#align=left&display=inline&height=389&originHeight=389&originWidth=400&size=0&status=done&width=400)\n\n### 高容错性\n\n非分布式系统的一大安全隐患是单点故障（single point of failure, SPOF）。例如单实例数据库宕机，会产生无法估量的损失。\n分布式系统被设计为可配置的方式，来处理故障。例如，在 5 节点的 Kafka 集群中，即使其中两个节点关闭，系统仍然继续工作。需要注意的地方是，系统容错率与系统性能成反比，即容错率越高，性能越低。\n\n### 日志采集\n\n日志采集（事务日志）仅支持附加的持久有序数据结构，即无法修改或删除已有的记录。读取顺序从左向右如图所示。\n![](https://cdn.nlark.com/yuque/0/2019/jpeg/250680/1550675101681-613e5d8c-b7f7-4800-8c6e-f0c7a41dae65.jpeg#align=left&display=inline&height=187&originHeight=187&originWidth=396&size=0&status=done&width=396)\n在某种程度来讲，Kafka 的数据结构就是如此简单。这也是 Kafka 的核心，因为它提供了有序数据，而有序的数据结构提供了确定性的处理方式。\nKafka 实际上将所有消息存储在磁盘上，并且对他们进行排序，最大化利用硬盘顺序读取速度快的优势。\n\n- 读取和写入是整数级别 O(1)（知道记录 ID），与磁盘上的其他数据结构的操作复杂度为 O(log N)相比，有巨大优势。\n- 读取和写入是分离的。写入时不会锁定读取，反之亦然（与平衡树相反）。\n\n这两点使得 Kafka 的性能有巨大优势，因为系统性能与数据量是分离的。Kafka 无论处理 100KB 的数据量还是 100TB 的数据量，性能都是一样的。\n\n## 工作原理\n\n向 Kafka 节点（broker）发送消息（记录）的称为程序（生产者），发送给其他程序处理消息的称为消费者。产生的消息存储在一个**topic**内，消费者订阅向 topic 订阅后，可以接收到对应 topic 的新消息。\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1550761835264-486e6737-07e1-4bbb-aae7-4e09b7888f77.png#align=left&display=inline&height=178&name=image.png&originHeight=180&originWidth=258&size=8295&status=done&width=255)\n随着 topic 变得越来越大，为保持性能和可伸缩性将 topic 拆分成更小的分区。（例如，需要存储用户的登录名，可以将用户名按照首字母进行拆分存储在不同的分区）\nKafka 保证分区内的所有消息都按照它们进入的顺序排序。区分特定消息的方式是通过其**偏移量** ，可将其视为普通数组索引，在一个分区的序列号随着新消息进入而递增。\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1550762596583-9e4702c2-cd98-410f-8587-2f2a17cbfaea.png#align=left&display=inline&height=182&name=image.png&originHeight=267&originWidth=416&size=19550&status=done&width=283)\nKafka 遵循愚蠢的 broker 和聪明的消费者原则。意思是，Kafka 不会跟踪哪一条记录已经被消费者读取并删除，而是将他们按照一定的时间（例如一天）或约定某个阈值大小来存储。消费者自身从 Kafka 的 broker**主动拉取**新信息，并告知他们想要读取的片段。这意味着 broker 允许消费者按照自身的需要进行增加或减小偏移量，因此具有重新读取和重新处理信息的能力。\n需要注意的是，消费者其实是消费者群组，包含一个或多个消费进程。为避免两个进程重复读取相同的信息，每个分区仅与每个组的一个消费者进程相关联。\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1550763797220-d9a12e85-f1df-477c-adf7-ce92ddbeb9ac.png#align=left&display=inline&height=331&name=image.png&originHeight=661&originWidth=2000&size=238955&status=done&width=1000)\n\n## 数据持久化\n\nKafka 将所有记录存储在磁盘，并且不会在 RAM 中保存任何记录。你可能会惊讶于以怎样高效的方式来做明智的选择。这背后有很多值得学习的优化知识：\n\n1. Kafka 有将成组的消息合并的协议。允许网络请求将消息组合在一起减少网络开销，因此服务器一次性保留大量消息，消费者一次获取巨大的线性消息块。\n1. 磁盘顺序 I/O 读取速度很快。现代磁盘速度慢的原因是由于大量的磁盘寻道，但是在大型线性读写操作时不是问题。\n1. 线性操作由 OS 进一步优化，通过**预读取**（预读取多倍数据块）和**后写入**（将小的逻辑写入操作合并为组后再进行物理写入操作）技术。\n1. 现代 OS 利用 RAM 模拟磁盘缓存，这种技术成为 pagecache。\n1. 由于 kafka 在整个流程（生产者--->代理--->消费者）中以未经修改的标准化二进制格式存储消息，因此它可以使用**零拷贝**（zero-copy）优化。操作系统将数据从 pagecache 直接复制到套接字，有效地完全绕过了 Kafka 代理应用程序。\n\n所有这些优化都使 Kafka 能够从接近网络的速度传输消息。\n\n## 数据分发和复制\n\n在这个章节，我们讨论 Kafka 如何实现容错以及它如何在节点之间分配数据。\n\n### 数据复制\n\n分区数据在多个代理（broker）中复制，以便在其中一个代理挂掉时候，依然能够保存数据。\n在任何时候，一个代理（broker）“拥有”其中一个分区，节点通过这个分区进行读写操作。因此，此分区被称为**分区领导者**（partition leader）。将接收到的数据复制给其他***N***个其他代理，称为**跟随者**（followers）。跟随者同样存储数据，并且随时准备着当 leader 挂掉时，取而代之。\n这样的配置有助于保证任何成功发布的消息都不会丢失。通过更改复制因子，可以根据数据的重要性来交换性能以获得更强的持久性保证。\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1551192978691-57bdf14e-90a0-47df-8aeb-60224ba6254c.png#align=left&display=inline&height=765&name=image.png&originHeight=1531&originWidth=2600&size=422840&status=done&width=1300)\n在其中一个 leader 挂掉时，其他 follower 会竞选上岗，具体算法可以参考：\n[_How does a producer/consumer know who the leader of a partition is?_](https://community.hortonworks.com/questions/149532/how-producer-and-consumer-identify-the-leader-in-k.html)\n作为生产者/消费者，对一个分区进行读取时，首先需要知道对应分区的 leader。这个信息需要存储在可以被访问到的地方，Kafka 使用 Zookeeper 进行存储这些元数据。\n\n### 何为 Zookeeper\n\nZookeeper 是一个分布式键值存储结构。它针对读取进行了高度优化，但写入速度较慢。常应用于存储元数据和处理集群的核心机制（心跳包、分发更新配置等）。\n它允许服务（Kafka 的 broker）的客户订阅通知，并且能在 Zookeeper 发生变动的时候发送给客户消息。这也是为什么 brokers 能够感知分区的 leader 发生变动。Zookeeper 同时也具有成熟的容错性，或者说，Kafka 很大程度上依赖 Zookeeper 的高容错性。\nZookeeper 用于存储所有类型的元数据，包括但不限于：\n\n- 消费者群组中每个分区的偏移量（尽管现在的客户端在单独的 Kafka 主题 Topic 内存储偏移量）\n- ACL（访问控制列表），用于限制访问/授权\n- 生产者和消费者配额，包括每秒最大信息量\n- 存储分区 leader 和健康状态\n\n### 如何区分分区的领导者\n\n在以往版本中，生产者和消费者经常直接连接并与 Zookeeper 交谈以获取此（和其他）信息。  目前 Kafka 已经弃用这种耦合，从 0.8 和 0.9 版本开始，客户端直接从 Kafka 的 brokers 那里获取元数据信息，他们自己与 Zookeeper 交谈。\n\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1551274509585-90480e7a-f43d-4959-9703-a908c3983f5f.png#align=left&display=inline&height=1076&name=image.png&originHeight=2152&originWidth=2000&size=462646&status=done&width=1000)\n\n## 流\n\n在 Kafka 中，流处理器是从输入的 Topic 中连续读取数据流，并对数据进行一些处理生成数据流以生成主题的任何（或外部服务、数据库、垃圾箱等）内容。\n对于一些简单的消息，可能使用消费者或生产者的 API 接口直接处理即可，但是涉及到复杂的消息流（例如，多条数据流联合）处理的情况，Kafka 提供一个集成的[Stream API](https://kafka.apache.org/documentation/streams/)库。\n此 API 应用于自己的代码块中，而不是直接在代理（broker）上运行。它与消费者 API 类似，可以帮助你在多个应用（类似多个消费者）上扩展流处理工作。\n\n### 无状态处理\n\n流的无状态处理是确定性的，不需要依赖任何外部的处理方式。对于任何给定的数据，将始终生成与其他内容无关的相同输入。\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1551280756166-0643b4f0-57aa-483b-b51f-ff4d42fc174e.png#align=left&display=inline&height=381&name=image.png&originHeight=762&originWidth=2600&size=233348&status=done&width=1300)\n\n### 流式表的双重性\n\n首先要认识到流和表是相同的含义。流，可以解释为表，反之亦然。\n\n### 流作为表\n\n流可以看做对数据进行一系列的更新，因此最终结果作为表进行聚合。这种技术成为事件采集（Event sourcing）。\n如果你了解如何实现同步数据库的复制，你会知道它是通过所谓的流复制（**Streaming replication**），每次表格中的变动都会发送到副本服务器。事件采集的另外一个例子是，区块链分类账，它也是进行一系列变化。\nKafka 的数据流可以用相同的方式解释，即可以认为是积累到最终的状态的事件。此类流聚合保存在本地 RocksDB 中，称为**KTable**。\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1551281577256-6c7efae0-3e86-4379-9b28-3a6870bb826a.png#align=left&display=inline&height=343&name=image.png&originHeight=686&originWidth=2000&size=219233&status=done&width=1000)\n\n### 表作为流\n\n可以将表视为流中每个键的最新值的快照。  以相同的方式，流记录可以生成表，表更新可以生成更改日志流。\n\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1551281769435-7f51d3f6-30f3-4ae8-9018-19d0ebfb11a9.png#align=left&display=inline&height=646&name=image.png&originHeight=1291&originWidth=1600&size=350243&status=done&width=800)\n\n### 有状态处理\n\n一些简单的操作，例如`map()`或者`filter()`都是无状态的，不需要额外保存有关处理的任何数据。但是，在现实生活中，大部分操作都是有状态的（例如`count()`），因此需要保存当前积累的值。\n假如在流处理器上维护这些状态，流处理器可能会宕机，导致状态丢失。那么应当在哪里保存状态值才能容错呢？\n一种最简单的方式是简单地将所有状态存储在远程数据库中，并通过网络连接到该数据库。这样做的问题是，没有数据的位置和产生大量的网络交互损耗，这两者都会显着减慢您的应用程序。  一个更微妙但重要的问题是您的流处理作业的正常运行时间将紧密耦合到远程数据库，并且作业将不会自包含*（数据库中的数据库与另一个团队的更改可能会破坏您的处理）* 。\n回忆下表和流的二元性。运行我们将流转化为与我们处理位于同一位置的表。它还能提供一种处理容错的机制，即在 Kafka 的 Broker 中存储流。\n数据流处理器能够在本地表（即，RocksDB）存储状态，该表将从输入流（可能实在某些任意变换之后）更新。当进程失败时，可以通过重新请求流来恢复其数据。\n你也可以使用一个远程数据库作为流的生产者，用于在本地重建表进行高效的广播更改日志。\n\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1551282823033-1e7dcc9e-c2a2-4130-b972-b1c1776bd0f1.png#align=left&display=inline&height=729&name=image.png&originHeight=1458&originWidth=2000&size=234952&status=done&width=1000)\n\n## KSQL\n\n通常，使用 Kafka 只能使用 JVM 语言编写刘处理，因为这是 Kafka 唯一的官方 Streams API 客户端。\n\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1551799835544-909daa5c-d2ad-4f30-9060-496ba185feaf.png#align=left&display=inline&height=772&name=image.png&originHeight=1543&originWidth=1600&size=165449&status=done&width=800)\n2018.04 的 Kafka 发布**KSQL**，一种可以使用类 SQL 语言来编写简单流媒体工作的工具。\n通过设置 KSQL 服务器，并且通过 CLI 方式进行交互以此来管理处理。它使用相同的抽象（KStream 和 KTable），保证了 StreamS API 的相同有点（可伸缩性、容错性）和更加简便的方式处理工作流。\n这个特性虽然不被人经常提起，但经过实践对于测试更有用，甚至运行开发之外的人（例如，产品所有者）使用流处理。\n\n### 流的可选择性\n\nKafka 的流兼具了力量和简约的完美结合。可是说是市场上处理流工作的最佳工具，与其他流处理工具（Storm、Samza、Spark 和 Wallaroo）相比，Kafka 更容易与其他工具结合。\n大多数其他流处理的框架的问题在于它们运行和部署的复杂性。例如 Spark 这样的处理框架需要以下几点：\n\n1. 在一组计算机上控制大量的作业，并在集群上有效的分配。\n1. 为此，必须动态打包你的程序并将其部署在它需要执行的节点（以及配置、库等）。\n\n为此，要处理以上问题，使得框架尤为复杂。它们需要控制很多方面：部署、配置、监控和打包。\nKafka 流能够允许你在你需要时，提出自己的部署策略，例如 Kubernetes、Mesos、Nomad、Docker Swarm 或者其他方式。\nKafka Streams 的基本目的是使所有应用程序能够进行流处理，而无需运行和维护另一个操作复杂的集群。  唯一潜在的缺点是它与卡夫卡紧密结合，但在现代世界中，大多数（如果不是全部）实时处理由卡夫卡提供动力可能不是一个很大的劣势。\n\n## 何时启用 Kafka\n\n正如我们已经介绍的，Kafka 允许通过集中式介质获取大量消息并且存储他们，并不担心性能或数据丢失等问题。\n这意味着非常适合用在系统框架的核心，充当连接不同程序的中间媒介。Kafka 能够成为事件驱动架构的中心部分，是您能够真正的将应用程序间解耦。\n\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1551888348371-8ade2e7b-bab2-4c43-9172-231a08b074c0.png#align=left&display=inline&height=337&name=image.png&originHeight=674&originWidth=900&size=432210&status=done&width=450)\nKafka 能够非常轻松的分离不同（微）服务之间的通信。使用 Streams API，现在可以更容易的编写业务逻辑，从而丰富 Kafka 主题数据以便提供服务。\n\n## 总结\n\nApache Kafka 作为分布式流平台，每天可以处理数以万亿计的事件。Kafka 提供低延迟、高吞吐量、高容错和订阅式流水线，同时能够流式处理事件。\n我们回顾了它的基本语义（生产者、代理、消费者和 Topic），了解了它的一些优化（page cache），通过复制数据了解了它的容错能力，并且介绍了它不断增长的强大流功能。\n","slug":"Kafka - - 快速入门指南","published":1,"updated":"2020-05-28T16:57:36.320Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckasagni1000cx396np0ahzfn","content":"<h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>Kafka 起源于 2011 年 LikedIn 的开源项目，并不断发展。如今它是一个完整的平台，允许您冗余地存储巨大的数据量，拥有一个具有巨大吞吐量（数百万/秒）的消息总线，同时可实现实时流处理。</p>\n<p>Kafka 具备的特性有：<strong>分布式、水平扩展、高容错和日志管理</strong>。接下来将逐个介绍特性。</p>\n<h3 id=\"分布式\"><a href=\"#分布式\" class=\"headerlink\" title=\"分布式\"></a>分布式</h3><p>分布式系统的显著特点是将任务分配到多个机器处理，即组成的集群对外暴露的形式仍为单一节点。Kafka 的分布特性在于在不同节点（代理）存储、接收和发送消息。</p>\n<blockquote>\n<p>分布式系统的介绍可以参阅：<a href=\"https://medium.freecodecamp.org/a-thorough-introduction-to-distributed-systems-3b91562c9b3c\" target=\"_blank\" rel=\"noopener\">A Thorough Introduction to Distributed Systems</a></p>\n</blockquote>\n<p>分布式系统的优势主要体现在：高可扩展性、容错性。</p>\n<h3 id=\"水平扩展\"><a href=\"#水平扩展\" class=\"headerlink\" title=\"水平扩展\"></a>水平扩展</h3><p>首先解释、定义垂直扩展。例如，数据库服务器过载，最直接的解决办法是添加资源（CPU、RAM 和 SSD）。垂直扩展的两大缺点是：</p>\n<ul>\n<li>现有的硬件限制了扩展能力。例如不能无线提高 CPU 核数。</li>\n<li>通常需要停机时间。</li>\n</ul>\n<p><strong>水平扩展</strong>通过投入更多的机器来解决上述问题。添加新机器不需要停机，也没有机器数量的限制。它的缺点是，并非所有系统支持水平弹性伸缩，因为在设计之初没有考虑工作在集群环境下，同时设计也更为复杂。<br><img src=\"https://cdn.nlark.com/yuque/0/2019/jpeg/250680/1550673729515-587ccc54-647c-4f27-a36f-08848fd77da0.jpeg#align=left&amp;display=inline&amp;height=389&amp;originHeight=389&amp;originWidth=400&amp;size=0&amp;status=done&amp;width=400\" alt=\"\"></p>\n<h3 id=\"高容错性\"><a href=\"#高容错性\" class=\"headerlink\" title=\"高容错性\"></a>高容错性</h3><p>非分布式系统的一大安全隐患是单点故障（single point of failure, SPOF）。例如单实例数据库宕机，会产生无法估量的损失。<br>分布式系统被设计为可配置的方式，来处理故障。例如，在 5 节点的 Kafka 集群中，即使其中两个节点关闭，系统仍然继续工作。需要注意的地方是，系统容错率与系统性能成反比，即容错率越高，性能越低。</p>\n<h3 id=\"日志采集\"><a href=\"#日志采集\" class=\"headerlink\" title=\"日志采集\"></a>日志采集</h3><p>日志采集（事务日志）仅支持附加的持久有序数据结构，即无法修改或删除已有的记录。读取顺序从左向右如图所示。<br><img src=\"https://cdn.nlark.com/yuque/0/2019/jpeg/250680/1550675101681-613e5d8c-b7f7-4800-8c6e-f0c7a41dae65.jpeg#align=left&amp;display=inline&amp;height=187&amp;originHeight=187&amp;originWidth=396&amp;size=0&amp;status=done&amp;width=396\" alt=\"\"><br>在某种程度来讲，Kafka 的数据结构就是如此简单。这也是 Kafka 的核心，因为它提供了有序数据，而有序的数据结构提供了确定性的处理方式。<br>Kafka 实际上将所有消息存储在磁盘上，并且对他们进行排序，最大化利用硬盘顺序读取速度快的优势。</p>\n<ul>\n<li>读取和写入是整数级别 O(1)（知道记录 ID），与磁盘上的其他数据结构的操作复杂度为 O(log N)相比，有巨大优势。</li>\n<li>读取和写入是分离的。写入时不会锁定读取，反之亦然（与平衡树相反）。</li>\n</ul>\n<p>这两点使得 Kafka 的性能有巨大优势，因为系统性能与数据量是分离的。Kafka 无论处理 100KB 的数据量还是 100TB 的数据量，性能都是一样的。</p>\n<h2 id=\"工作原理\"><a href=\"#工作原理\" class=\"headerlink\" title=\"工作原理\"></a>工作原理</h2><p>向 Kafka 节点（broker）发送消息（记录）的称为程序（生产者），发送给其他程序处理消息的称为消费者。产生的消息存储在一个<strong>topic</strong>内，消费者订阅向 topic 订阅后，可以接收到对应 topic 的新消息。<br><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1550761835264-486e6737-07e1-4bbb-aae7-4e09b7888f77.png#align=left&amp;display=inline&amp;height=178&amp;name=image.png&amp;originHeight=180&amp;originWidth=258&amp;size=8295&amp;status=done&amp;width=255\" alt=\"image.png\"><br>随着 topic 变得越来越大，为保持性能和可伸缩性将 topic 拆分成更小的分区。（例如，需要存储用户的登录名，可以将用户名按照首字母进行拆分存储在不同的分区）<br>Kafka 保证分区内的所有消息都按照它们进入的顺序排序。区分特定消息的方式是通过其<strong>偏移量</strong> ，可将其视为普通数组索引，在一个分区的序列号随着新消息进入而递增。<br><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1550762596583-9e4702c2-cd98-410f-8587-2f2a17cbfaea.png#align=left&amp;display=inline&amp;height=182&amp;name=image.png&amp;originHeight=267&amp;originWidth=416&amp;size=19550&amp;status=done&amp;width=283\" alt=\"image.png\"><br>Kafka 遵循愚蠢的 broker 和聪明的消费者原则。意思是，Kafka 不会跟踪哪一条记录已经被消费者读取并删除，而是将他们按照一定的时间（例如一天）或约定某个阈值大小来存储。消费者自身从 Kafka 的 broker<strong>主动拉取</strong>新信息，并告知他们想要读取的片段。这意味着 broker 允许消费者按照自身的需要进行增加或减小偏移量，因此具有重新读取和重新处理信息的能力。<br>需要注意的是，消费者其实是消费者群组，包含一个或多个消费进程。为避免两个进程重复读取相同的信息，每个分区仅与每个组的一个消费者进程相关联。<br><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1550763797220-d9a12e85-f1df-477c-adf7-ce92ddbeb9ac.png#align=left&amp;display=inline&amp;height=331&amp;name=image.png&amp;originHeight=661&amp;originWidth=2000&amp;size=238955&amp;status=done&amp;width=1000\" alt=\"image.png\"></p>\n<h2 id=\"数据持久化\"><a href=\"#数据持久化\" class=\"headerlink\" title=\"数据持久化\"></a>数据持久化</h2><p>Kafka 将所有记录存储在磁盘，并且不会在 RAM 中保存任何记录。你可能会惊讶于以怎样高效的方式来做明智的选择。这背后有很多值得学习的优化知识：</p>\n<ol>\n<li>Kafka 有将成组的消息合并的协议。允许网络请求将消息组合在一起减少网络开销，因此服务器一次性保留大量消息，消费者一次获取巨大的线性消息块。</li>\n<li>磁盘顺序 I/O 读取速度很快。现代磁盘速度慢的原因是由于大量的磁盘寻道，但是在大型线性读写操作时不是问题。</li>\n<li>线性操作由 OS 进一步优化，通过<strong>预读取</strong>（预读取多倍数据块）和<strong>后写入</strong>（将小的逻辑写入操作合并为组后再进行物理写入操作）技术。</li>\n<li>现代 OS 利用 RAM 模拟磁盘缓存，这种技术成为 pagecache。</li>\n<li>由于 kafka 在整个流程（生产者—&gt;代理—&gt;消费者）中以未经修改的标准化二进制格式存储消息，因此它可以使用<strong>零拷贝</strong>（zero-copy）优化。操作系统将数据从 pagecache 直接复制到套接字，有效地完全绕过了 Kafka 代理应用程序。</li>\n</ol>\n<p>所有这些优化都使 Kafka 能够从接近网络的速度传输消息。</p>\n<h2 id=\"数据分发和复制\"><a href=\"#数据分发和复制\" class=\"headerlink\" title=\"数据分发和复制\"></a>数据分发和复制</h2><p>在这个章节，我们讨论 Kafka 如何实现容错以及它如何在节点之间分配数据。</p>\n<h3 id=\"数据复制\"><a href=\"#数据复制\" class=\"headerlink\" title=\"数据复制\"></a>数据复制</h3><p>分区数据在多个代理（broker）中复制，以便在其中一个代理挂掉时候，依然能够保存数据。<br>在任何时候，一个代理（broker）“拥有”其中一个分区，节点通过这个分区进行读写操作。因此，此分区被称为<strong>分区领导者</strong>（partition leader）。将接收到的数据复制给其他<strong><em>N</em></strong>个其他代理，称为<strong>跟随者</strong>（followers）。跟随者同样存储数据，并且随时准备着当 leader 挂掉时，取而代之。<br>这样的配置有助于保证任何成功发布的消息都不会丢失。通过更改复制因子，可以根据数据的重要性来交换性能以获得更强的持久性保证。<br><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1551192978691-57bdf14e-90a0-47df-8aeb-60224ba6254c.png#align=left&amp;display=inline&amp;height=765&amp;name=image.png&amp;originHeight=1531&amp;originWidth=2600&amp;size=422840&amp;status=done&amp;width=1300\" alt=\"image.png\"><br>在其中一个 leader 挂掉时，其他 follower 会竞选上岗，具体算法可以参考：<br><a href=\"https://community.hortonworks.com/questions/149532/how-producer-and-consumer-identify-the-leader-in-k.html\" target=\"_blank\" rel=\"noopener\"><em>How does a producer/consumer know who the leader of a partition is?</em></a><br>作为生产者/消费者，对一个分区进行读取时，首先需要知道对应分区的 leader。这个信息需要存储在可以被访问到的地方，Kafka 使用 Zookeeper 进行存储这些元数据。</p>\n<h3 id=\"何为-Zookeeper\"><a href=\"#何为-Zookeeper\" class=\"headerlink\" title=\"何为 Zookeeper\"></a>何为 Zookeeper</h3><p>Zookeeper 是一个分布式键值存储结构。它针对读取进行了高度优化，但写入速度较慢。常应用于存储元数据和处理集群的核心机制（心跳包、分发更新配置等）。<br>它允许服务（Kafka 的 broker）的客户订阅通知，并且能在 Zookeeper 发生变动的时候发送给客户消息。这也是为什么 brokers 能够感知分区的 leader 发生变动。Zookeeper 同时也具有成熟的容错性，或者说，Kafka 很大程度上依赖 Zookeeper 的高容错性。<br>Zookeeper 用于存储所有类型的元数据，包括但不限于：</p>\n<ul>\n<li>消费者群组中每个分区的偏移量（尽管现在的客户端在单独的 Kafka 主题 Topic 内存储偏移量）</li>\n<li>ACL（访问控制列表），用于限制访问/授权</li>\n<li>生产者和消费者配额，包括每秒最大信息量</li>\n<li>存储分区 leader 和健康状态</li>\n</ul>\n<h3 id=\"如何区分分区的领导者\"><a href=\"#如何区分分区的领导者\" class=\"headerlink\" title=\"如何区分分区的领导者\"></a>如何区分分区的领导者</h3><p>在以往版本中，生产者和消费者经常直接连接并与 Zookeeper 交谈以获取此（和其他）信息。  目前 Kafka 已经弃用这种耦合，从 0.8 和 0.9 版本开始，客户端直接从 Kafka 的 brokers 那里获取元数据信息，他们自己与 Zookeeper 交谈。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1551274509585-90480e7a-f43d-4959-9703-a908c3983f5f.png#align=left&amp;display=inline&amp;height=1076&amp;name=image.png&amp;originHeight=2152&amp;originWidth=2000&amp;size=462646&amp;status=done&amp;width=1000\" alt=\"image.png\"></p>\n<h2 id=\"流\"><a href=\"#流\" class=\"headerlink\" title=\"流\"></a>流</h2><p>在 Kafka 中，流处理器是从输入的 Topic 中连续读取数据流，并对数据进行一些处理生成数据流以生成主题的任何（或外部服务、数据库、垃圾箱等）内容。<br>对于一些简单的消息，可能使用消费者或生产者的 API 接口直接处理即可，但是涉及到复杂的消息流（例如，多条数据流联合）处理的情况，Kafka 提供一个集成的<a href=\"https://kafka.apache.org/documentation/streams/\" target=\"_blank\" rel=\"noopener\">Stream API</a>库。<br>此 API 应用于自己的代码块中，而不是直接在代理（broker）上运行。它与消费者 API 类似，可以帮助你在多个应用（类似多个消费者）上扩展流处理工作。</p>\n<h3 id=\"无状态处理\"><a href=\"#无状态处理\" class=\"headerlink\" title=\"无状态处理\"></a>无状态处理</h3><p>流的无状态处理是确定性的，不需要依赖任何外部的处理方式。对于任何给定的数据，将始终生成与其他内容无关的相同输入。<br><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1551280756166-0643b4f0-57aa-483b-b51f-ff4d42fc174e.png#align=left&amp;display=inline&amp;height=381&amp;name=image.png&amp;originHeight=762&amp;originWidth=2600&amp;size=233348&amp;status=done&amp;width=1300\" alt=\"image.png\"></p>\n<h3 id=\"流式表的双重性\"><a href=\"#流式表的双重性\" class=\"headerlink\" title=\"流式表的双重性\"></a>流式表的双重性</h3><p>首先要认识到流和表是相同的含义。流，可以解释为表，反之亦然。</p>\n<h3 id=\"流作为表\"><a href=\"#流作为表\" class=\"headerlink\" title=\"流作为表\"></a>流作为表</h3><p>流可以看做对数据进行一系列的更新，因此最终结果作为表进行聚合。这种技术成为事件采集（Event sourcing）。<br>如果你了解如何实现同步数据库的复制，你会知道它是通过所谓的流复制（<strong>Streaming replication</strong>），每次表格中的变动都会发送到副本服务器。事件采集的另外一个例子是，区块链分类账，它也是进行一系列变化。<br>Kafka 的数据流可以用相同的方式解释，即可以认为是积累到最终的状态的事件。此类流聚合保存在本地 RocksDB 中，称为<strong>KTable</strong>。<br><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1551281577256-6c7efae0-3e86-4379-9b28-3a6870bb826a.png#align=left&amp;display=inline&amp;height=343&amp;name=image.png&amp;originHeight=686&amp;originWidth=2000&amp;size=219233&amp;status=done&amp;width=1000\" alt=\"image.png\"></p>\n<h3 id=\"表作为流\"><a href=\"#表作为流\" class=\"headerlink\" title=\"表作为流\"></a>表作为流</h3><p>可以将表视为流中每个键的最新值的快照。  以相同的方式，流记录可以生成表，表更新可以生成更改日志流。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1551281769435-7f51d3f6-30f3-4ae8-9018-19d0ebfb11a9.png#align=left&amp;display=inline&amp;height=646&amp;name=image.png&amp;originHeight=1291&amp;originWidth=1600&amp;size=350243&amp;status=done&amp;width=800\" alt=\"image.png\"></p>\n<h3 id=\"有状态处理\"><a href=\"#有状态处理\" class=\"headerlink\" title=\"有状态处理\"></a>有状态处理</h3><p>一些简单的操作，例如<code>map()</code>或者<code>filter()</code>都是无状态的，不需要额外保存有关处理的任何数据。但是，在现实生活中，大部分操作都是有状态的（例如<code>count()</code>），因此需要保存当前积累的值。<br>假如在流处理器上维护这些状态，流处理器可能会宕机，导致状态丢失。那么应当在哪里保存状态值才能容错呢？<br>一种最简单的方式是简单地将所有状态存储在远程数据库中，并通过网络连接到该数据库。这样做的问题是，没有数据的位置和产生大量的网络交互损耗，这两者都会显着减慢您的应用程序。  一个更微妙但重要的问题是您的流处理作业的正常运行时间将紧密耦合到远程数据库，并且作业将不会自包含<em>（数据库中的数据库与另一个团队的更改可能会破坏您的处理）</em> 。<br>回忆下表和流的二元性。运行我们将流转化为与我们处理位于同一位置的表。它还能提供一种处理容错的机制，即在 Kafka 的 Broker 中存储流。<br>数据流处理器能够在本地表（即，RocksDB）存储状态，该表将从输入流（可能实在某些任意变换之后）更新。当进程失败时，可以通过重新请求流来恢复其数据。<br>你也可以使用一个远程数据库作为流的生产者，用于在本地重建表进行高效的广播更改日志。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1551282823033-1e7dcc9e-c2a2-4130-b972-b1c1776bd0f1.png#align=left&amp;display=inline&amp;height=729&amp;name=image.png&amp;originHeight=1458&amp;originWidth=2000&amp;size=234952&amp;status=done&amp;width=1000\" alt=\"image.png\"></p>\n<h2 id=\"KSQL\"><a href=\"#KSQL\" class=\"headerlink\" title=\"KSQL\"></a>KSQL</h2><p>通常，使用 Kafka 只能使用 JVM 语言编写刘处理，因为这是 Kafka 唯一的官方 Streams API 客户端。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1551799835544-909daa5c-d2ad-4f30-9060-496ba185feaf.png#align=left&amp;display=inline&amp;height=772&amp;name=image.png&amp;originHeight=1543&amp;originWidth=1600&amp;size=165449&amp;status=done&amp;width=800\" alt=\"image.png\"><br>2018.04 的 Kafka 发布<strong>KSQL</strong>，一种可以使用类 SQL 语言来编写简单流媒体工作的工具。<br>通过设置 KSQL 服务器，并且通过 CLI 方式进行交互以此来管理处理。它使用相同的抽象（KStream 和 KTable），保证了 StreamS API 的相同有点（可伸缩性、容错性）和更加简便的方式处理工作流。<br>这个特性虽然不被人经常提起，但经过实践对于测试更有用，甚至运行开发之外的人（例如，产品所有者）使用流处理。</p>\n<h3 id=\"流的可选择性\"><a href=\"#流的可选择性\" class=\"headerlink\" title=\"流的可选择性\"></a>流的可选择性</h3><p>Kafka 的流兼具了力量和简约的完美结合。可是说是市场上处理流工作的最佳工具，与其他流处理工具（Storm、Samza、Spark 和 Wallaroo）相比，Kafka 更容易与其他工具结合。<br>大多数其他流处理的框架的问题在于它们运行和部署的复杂性。例如 Spark 这样的处理框架需要以下几点：</p>\n<ol>\n<li>在一组计算机上控制大量的作业，并在集群上有效的分配。</li>\n<li>为此，必须动态打包你的程序并将其部署在它需要执行的节点（以及配置、库等）。</li>\n</ol>\n<p>为此，要处理以上问题，使得框架尤为复杂。它们需要控制很多方面：部署、配置、监控和打包。<br>Kafka 流能够允许你在你需要时，提出自己的部署策略，例如 Kubernetes、Mesos、Nomad、Docker Swarm 或者其他方式。<br>Kafka Streams 的基本目的是使所有应用程序能够进行流处理，而无需运行和维护另一个操作复杂的集群。  唯一潜在的缺点是它与卡夫卡紧密结合，但在现代世界中，大多数（如果不是全部）实时处理由卡夫卡提供动力可能不是一个很大的劣势。</p>\n<h2 id=\"何时启用-Kafka\"><a href=\"#何时启用-Kafka\" class=\"headerlink\" title=\"何时启用 Kafka\"></a>何时启用 Kafka</h2><p>正如我们已经介绍的，Kafka 允许通过集中式介质获取大量消息并且存储他们，并不担心性能或数据丢失等问题。<br>这意味着非常适合用在系统框架的核心，充当连接不同程序的中间媒介。Kafka 能够成为事件驱动架构的中心部分，是您能够真正的将应用程序间解耦。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1551888348371-8ade2e7b-bab2-4c43-9172-231a08b074c0.png#align=left&amp;display=inline&amp;height=337&amp;name=image.png&amp;originHeight=674&amp;originWidth=900&amp;size=432210&amp;status=done&amp;width=450\" alt=\"image.png\"><br>Kafka 能够非常轻松的分离不同（微）服务之间的通信。使用 Streams API，现在可以更容易的编写业务逻辑，从而丰富 Kafka 主题数据以便提供服务。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>Apache Kafka 作为分布式流平台，每天可以处理数以万亿计的事件。Kafka 提供低延迟、高吞吐量、高容错和订阅式流水线，同时能够流式处理事件。<br>我们回顾了它的基本语义（生产者、代理、消费者和 Topic），了解了它的一些优化（page cache），通过复制数据了解了它的容错能力，并且介绍了它不断增长的强大流功能。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>Kafka 起源于 2011 年 LikedIn 的开源项目，并不断发展。如今它是一个完整的平台，允许您冗余地存储巨大的数据量，拥有一个具有巨大吞吐量（数百万/秒）的消息总线，同时可实现实时流处理。</p>\n<p>Kafka 具备的特性有：<strong>分布式、水平扩展、高容错和日志管理</strong>。接下来将逐个介绍特性。</p>\n<h3 id=\"分布式\"><a href=\"#分布式\" class=\"headerlink\" title=\"分布式\"></a>分布式</h3><p>分布式系统的显著特点是将任务分配到多个机器处理，即组成的集群对外暴露的形式仍为单一节点。Kafka 的分布特性在于在不同节点（代理）存储、接收和发送消息。</p>\n<blockquote>\n<p>分布式系统的介绍可以参阅：<a href=\"https://medium.freecodecamp.org/a-thorough-introduction-to-distributed-systems-3b91562c9b3c\" target=\"_blank\" rel=\"noopener\">A Thorough Introduction to Distributed Systems</a></p>\n</blockquote>\n<p>分布式系统的优势主要体现在：高可扩展性、容错性。</p>\n<h3 id=\"水平扩展\"><a href=\"#水平扩展\" class=\"headerlink\" title=\"水平扩展\"></a>水平扩展</h3><p>首先解释、定义垂直扩展。例如，数据库服务器过载，最直接的解决办法是添加资源（CPU、RAM 和 SSD）。垂直扩展的两大缺点是：</p>\n<ul>\n<li>现有的硬件限制了扩展能力。例如不能无线提高 CPU 核数。</li>\n<li>通常需要停机时间。</li>\n</ul>\n<p><strong>水平扩展</strong>通过投入更多的机器来解决上述问题。添加新机器不需要停机，也没有机器数量的限制。它的缺点是，并非所有系统支持水平弹性伸缩，因为在设计之初没有考虑工作在集群环境下，同时设计也更为复杂。<br><img src=\"https://cdn.nlark.com/yuque/0/2019/jpeg/250680/1550673729515-587ccc54-647c-4f27-a36f-08848fd77da0.jpeg#align=left&amp;display=inline&amp;height=389&amp;originHeight=389&amp;originWidth=400&amp;size=0&amp;status=done&amp;width=400\" alt=\"\"></p>\n<h3 id=\"高容错性\"><a href=\"#高容错性\" class=\"headerlink\" title=\"高容错性\"></a>高容错性</h3><p>非分布式系统的一大安全隐患是单点故障（single point of failure, SPOF）。例如单实例数据库宕机，会产生无法估量的损失。<br>分布式系统被设计为可配置的方式，来处理故障。例如，在 5 节点的 Kafka 集群中，即使其中两个节点关闭，系统仍然继续工作。需要注意的地方是，系统容错率与系统性能成反比，即容错率越高，性能越低。</p>\n<h3 id=\"日志采集\"><a href=\"#日志采集\" class=\"headerlink\" title=\"日志采集\"></a>日志采集</h3><p>日志采集（事务日志）仅支持附加的持久有序数据结构，即无法修改或删除已有的记录。读取顺序从左向右如图所示。<br><img src=\"https://cdn.nlark.com/yuque/0/2019/jpeg/250680/1550675101681-613e5d8c-b7f7-4800-8c6e-f0c7a41dae65.jpeg#align=left&amp;display=inline&amp;height=187&amp;originHeight=187&amp;originWidth=396&amp;size=0&amp;status=done&amp;width=396\" alt=\"\"><br>在某种程度来讲，Kafka 的数据结构就是如此简单。这也是 Kafka 的核心，因为它提供了有序数据，而有序的数据结构提供了确定性的处理方式。<br>Kafka 实际上将所有消息存储在磁盘上，并且对他们进行排序，最大化利用硬盘顺序读取速度快的优势。</p>\n<ul>\n<li>读取和写入是整数级别 O(1)（知道记录 ID），与磁盘上的其他数据结构的操作复杂度为 O(log N)相比，有巨大优势。</li>\n<li>读取和写入是分离的。写入时不会锁定读取，反之亦然（与平衡树相反）。</li>\n</ul>\n<p>这两点使得 Kafka 的性能有巨大优势，因为系统性能与数据量是分离的。Kafka 无论处理 100KB 的数据量还是 100TB 的数据量，性能都是一样的。</p>\n<h2 id=\"工作原理\"><a href=\"#工作原理\" class=\"headerlink\" title=\"工作原理\"></a>工作原理</h2><p>向 Kafka 节点（broker）发送消息（记录）的称为程序（生产者），发送给其他程序处理消息的称为消费者。产生的消息存储在一个<strong>topic</strong>内，消费者订阅向 topic 订阅后，可以接收到对应 topic 的新消息。<br><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1550761835264-486e6737-07e1-4bbb-aae7-4e09b7888f77.png#align=left&amp;display=inline&amp;height=178&amp;name=image.png&amp;originHeight=180&amp;originWidth=258&amp;size=8295&amp;status=done&amp;width=255\" alt=\"image.png\"><br>随着 topic 变得越来越大，为保持性能和可伸缩性将 topic 拆分成更小的分区。（例如，需要存储用户的登录名，可以将用户名按照首字母进行拆分存储在不同的分区）<br>Kafka 保证分区内的所有消息都按照它们进入的顺序排序。区分特定消息的方式是通过其<strong>偏移量</strong> ，可将其视为普通数组索引，在一个分区的序列号随着新消息进入而递增。<br><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1550762596583-9e4702c2-cd98-410f-8587-2f2a17cbfaea.png#align=left&amp;display=inline&amp;height=182&amp;name=image.png&amp;originHeight=267&amp;originWidth=416&amp;size=19550&amp;status=done&amp;width=283\" alt=\"image.png\"><br>Kafka 遵循愚蠢的 broker 和聪明的消费者原则。意思是，Kafka 不会跟踪哪一条记录已经被消费者读取并删除，而是将他们按照一定的时间（例如一天）或约定某个阈值大小来存储。消费者自身从 Kafka 的 broker<strong>主动拉取</strong>新信息，并告知他们想要读取的片段。这意味着 broker 允许消费者按照自身的需要进行增加或减小偏移量，因此具有重新读取和重新处理信息的能力。<br>需要注意的是，消费者其实是消费者群组，包含一个或多个消费进程。为避免两个进程重复读取相同的信息，每个分区仅与每个组的一个消费者进程相关联。<br><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1550763797220-d9a12e85-f1df-477c-adf7-ce92ddbeb9ac.png#align=left&amp;display=inline&amp;height=331&amp;name=image.png&amp;originHeight=661&amp;originWidth=2000&amp;size=238955&amp;status=done&amp;width=1000\" alt=\"image.png\"></p>\n<h2 id=\"数据持久化\"><a href=\"#数据持久化\" class=\"headerlink\" title=\"数据持久化\"></a>数据持久化</h2><p>Kafka 将所有记录存储在磁盘，并且不会在 RAM 中保存任何记录。你可能会惊讶于以怎样高效的方式来做明智的选择。这背后有很多值得学习的优化知识：</p>\n<ol>\n<li>Kafka 有将成组的消息合并的协议。允许网络请求将消息组合在一起减少网络开销，因此服务器一次性保留大量消息，消费者一次获取巨大的线性消息块。</li>\n<li>磁盘顺序 I/O 读取速度很快。现代磁盘速度慢的原因是由于大量的磁盘寻道，但是在大型线性读写操作时不是问题。</li>\n<li>线性操作由 OS 进一步优化，通过<strong>预读取</strong>（预读取多倍数据块）和<strong>后写入</strong>（将小的逻辑写入操作合并为组后再进行物理写入操作）技术。</li>\n<li>现代 OS 利用 RAM 模拟磁盘缓存，这种技术成为 pagecache。</li>\n<li>由于 kafka 在整个流程（生产者—&gt;代理—&gt;消费者）中以未经修改的标准化二进制格式存储消息，因此它可以使用<strong>零拷贝</strong>（zero-copy）优化。操作系统将数据从 pagecache 直接复制到套接字，有效地完全绕过了 Kafka 代理应用程序。</li>\n</ol>\n<p>所有这些优化都使 Kafka 能够从接近网络的速度传输消息。</p>\n<h2 id=\"数据分发和复制\"><a href=\"#数据分发和复制\" class=\"headerlink\" title=\"数据分发和复制\"></a>数据分发和复制</h2><p>在这个章节，我们讨论 Kafka 如何实现容错以及它如何在节点之间分配数据。</p>\n<h3 id=\"数据复制\"><a href=\"#数据复制\" class=\"headerlink\" title=\"数据复制\"></a>数据复制</h3><p>分区数据在多个代理（broker）中复制，以便在其中一个代理挂掉时候，依然能够保存数据。<br>在任何时候，一个代理（broker）“拥有”其中一个分区，节点通过这个分区进行读写操作。因此，此分区被称为<strong>分区领导者</strong>（partition leader）。将接收到的数据复制给其他<strong><em>N</em></strong>个其他代理，称为<strong>跟随者</strong>（followers）。跟随者同样存储数据，并且随时准备着当 leader 挂掉时，取而代之。<br>这样的配置有助于保证任何成功发布的消息都不会丢失。通过更改复制因子，可以根据数据的重要性来交换性能以获得更强的持久性保证。<br><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1551192978691-57bdf14e-90a0-47df-8aeb-60224ba6254c.png#align=left&amp;display=inline&amp;height=765&amp;name=image.png&amp;originHeight=1531&amp;originWidth=2600&amp;size=422840&amp;status=done&amp;width=1300\" alt=\"image.png\"><br>在其中一个 leader 挂掉时，其他 follower 会竞选上岗，具体算法可以参考：<br><a href=\"https://community.hortonworks.com/questions/149532/how-producer-and-consumer-identify-the-leader-in-k.html\" target=\"_blank\" rel=\"noopener\"><em>How does a producer/consumer know who the leader of a partition is?</em></a><br>作为生产者/消费者，对一个分区进行读取时，首先需要知道对应分区的 leader。这个信息需要存储在可以被访问到的地方，Kafka 使用 Zookeeper 进行存储这些元数据。</p>\n<h3 id=\"何为-Zookeeper\"><a href=\"#何为-Zookeeper\" class=\"headerlink\" title=\"何为 Zookeeper\"></a>何为 Zookeeper</h3><p>Zookeeper 是一个分布式键值存储结构。它针对读取进行了高度优化，但写入速度较慢。常应用于存储元数据和处理集群的核心机制（心跳包、分发更新配置等）。<br>它允许服务（Kafka 的 broker）的客户订阅通知，并且能在 Zookeeper 发生变动的时候发送给客户消息。这也是为什么 brokers 能够感知分区的 leader 发生变动。Zookeeper 同时也具有成熟的容错性，或者说，Kafka 很大程度上依赖 Zookeeper 的高容错性。<br>Zookeeper 用于存储所有类型的元数据，包括但不限于：</p>\n<ul>\n<li>消费者群组中每个分区的偏移量（尽管现在的客户端在单独的 Kafka 主题 Topic 内存储偏移量）</li>\n<li>ACL（访问控制列表），用于限制访问/授权</li>\n<li>生产者和消费者配额，包括每秒最大信息量</li>\n<li>存储分区 leader 和健康状态</li>\n</ul>\n<h3 id=\"如何区分分区的领导者\"><a href=\"#如何区分分区的领导者\" class=\"headerlink\" title=\"如何区分分区的领导者\"></a>如何区分分区的领导者</h3><p>在以往版本中，生产者和消费者经常直接连接并与 Zookeeper 交谈以获取此（和其他）信息。  目前 Kafka 已经弃用这种耦合，从 0.8 和 0.9 版本开始，客户端直接从 Kafka 的 brokers 那里获取元数据信息，他们自己与 Zookeeper 交谈。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1551274509585-90480e7a-f43d-4959-9703-a908c3983f5f.png#align=left&amp;display=inline&amp;height=1076&amp;name=image.png&amp;originHeight=2152&amp;originWidth=2000&amp;size=462646&amp;status=done&amp;width=1000\" alt=\"image.png\"></p>\n<h2 id=\"流\"><a href=\"#流\" class=\"headerlink\" title=\"流\"></a>流</h2><p>在 Kafka 中，流处理器是从输入的 Topic 中连续读取数据流，并对数据进行一些处理生成数据流以生成主题的任何（或外部服务、数据库、垃圾箱等）内容。<br>对于一些简单的消息，可能使用消费者或生产者的 API 接口直接处理即可，但是涉及到复杂的消息流（例如，多条数据流联合）处理的情况，Kafka 提供一个集成的<a href=\"https://kafka.apache.org/documentation/streams/\" target=\"_blank\" rel=\"noopener\">Stream API</a>库。<br>此 API 应用于自己的代码块中，而不是直接在代理（broker）上运行。它与消费者 API 类似，可以帮助你在多个应用（类似多个消费者）上扩展流处理工作。</p>\n<h3 id=\"无状态处理\"><a href=\"#无状态处理\" class=\"headerlink\" title=\"无状态处理\"></a>无状态处理</h3><p>流的无状态处理是确定性的，不需要依赖任何外部的处理方式。对于任何给定的数据，将始终生成与其他内容无关的相同输入。<br><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1551280756166-0643b4f0-57aa-483b-b51f-ff4d42fc174e.png#align=left&amp;display=inline&amp;height=381&amp;name=image.png&amp;originHeight=762&amp;originWidth=2600&amp;size=233348&amp;status=done&amp;width=1300\" alt=\"image.png\"></p>\n<h3 id=\"流式表的双重性\"><a href=\"#流式表的双重性\" class=\"headerlink\" title=\"流式表的双重性\"></a>流式表的双重性</h3><p>首先要认识到流和表是相同的含义。流，可以解释为表，反之亦然。</p>\n<h3 id=\"流作为表\"><a href=\"#流作为表\" class=\"headerlink\" title=\"流作为表\"></a>流作为表</h3><p>流可以看做对数据进行一系列的更新，因此最终结果作为表进行聚合。这种技术成为事件采集（Event sourcing）。<br>如果你了解如何实现同步数据库的复制，你会知道它是通过所谓的流复制（<strong>Streaming replication</strong>），每次表格中的变动都会发送到副本服务器。事件采集的另外一个例子是，区块链分类账，它也是进行一系列变化。<br>Kafka 的数据流可以用相同的方式解释，即可以认为是积累到最终的状态的事件。此类流聚合保存在本地 RocksDB 中，称为<strong>KTable</strong>。<br><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1551281577256-6c7efae0-3e86-4379-9b28-3a6870bb826a.png#align=left&amp;display=inline&amp;height=343&amp;name=image.png&amp;originHeight=686&amp;originWidth=2000&amp;size=219233&amp;status=done&amp;width=1000\" alt=\"image.png\"></p>\n<h3 id=\"表作为流\"><a href=\"#表作为流\" class=\"headerlink\" title=\"表作为流\"></a>表作为流</h3><p>可以将表视为流中每个键的最新值的快照。  以相同的方式，流记录可以生成表，表更新可以生成更改日志流。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1551281769435-7f51d3f6-30f3-4ae8-9018-19d0ebfb11a9.png#align=left&amp;display=inline&amp;height=646&amp;name=image.png&amp;originHeight=1291&amp;originWidth=1600&amp;size=350243&amp;status=done&amp;width=800\" alt=\"image.png\"></p>\n<h3 id=\"有状态处理\"><a href=\"#有状态处理\" class=\"headerlink\" title=\"有状态处理\"></a>有状态处理</h3><p>一些简单的操作，例如<code>map()</code>或者<code>filter()</code>都是无状态的，不需要额外保存有关处理的任何数据。但是，在现实生活中，大部分操作都是有状态的（例如<code>count()</code>），因此需要保存当前积累的值。<br>假如在流处理器上维护这些状态，流处理器可能会宕机，导致状态丢失。那么应当在哪里保存状态值才能容错呢？<br>一种最简单的方式是简单地将所有状态存储在远程数据库中，并通过网络连接到该数据库。这样做的问题是，没有数据的位置和产生大量的网络交互损耗，这两者都会显着减慢您的应用程序。  一个更微妙但重要的问题是您的流处理作业的正常运行时间将紧密耦合到远程数据库，并且作业将不会自包含<em>（数据库中的数据库与另一个团队的更改可能会破坏您的处理）</em> 。<br>回忆下表和流的二元性。运行我们将流转化为与我们处理位于同一位置的表。它还能提供一种处理容错的机制，即在 Kafka 的 Broker 中存储流。<br>数据流处理器能够在本地表（即，RocksDB）存储状态，该表将从输入流（可能实在某些任意变换之后）更新。当进程失败时，可以通过重新请求流来恢复其数据。<br>你也可以使用一个远程数据库作为流的生产者，用于在本地重建表进行高效的广播更改日志。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1551282823033-1e7dcc9e-c2a2-4130-b972-b1c1776bd0f1.png#align=left&amp;display=inline&amp;height=729&amp;name=image.png&amp;originHeight=1458&amp;originWidth=2000&amp;size=234952&amp;status=done&amp;width=1000\" alt=\"image.png\"></p>\n<h2 id=\"KSQL\"><a href=\"#KSQL\" class=\"headerlink\" title=\"KSQL\"></a>KSQL</h2><p>通常，使用 Kafka 只能使用 JVM 语言编写刘处理，因为这是 Kafka 唯一的官方 Streams API 客户端。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1551799835544-909daa5c-d2ad-4f30-9060-496ba185feaf.png#align=left&amp;display=inline&amp;height=772&amp;name=image.png&amp;originHeight=1543&amp;originWidth=1600&amp;size=165449&amp;status=done&amp;width=800\" alt=\"image.png\"><br>2018.04 的 Kafka 发布<strong>KSQL</strong>，一种可以使用类 SQL 语言来编写简单流媒体工作的工具。<br>通过设置 KSQL 服务器，并且通过 CLI 方式进行交互以此来管理处理。它使用相同的抽象（KStream 和 KTable），保证了 StreamS API 的相同有点（可伸缩性、容错性）和更加简便的方式处理工作流。<br>这个特性虽然不被人经常提起，但经过实践对于测试更有用，甚至运行开发之外的人（例如，产品所有者）使用流处理。</p>\n<h3 id=\"流的可选择性\"><a href=\"#流的可选择性\" class=\"headerlink\" title=\"流的可选择性\"></a>流的可选择性</h3><p>Kafka 的流兼具了力量和简约的完美结合。可是说是市场上处理流工作的最佳工具，与其他流处理工具（Storm、Samza、Spark 和 Wallaroo）相比，Kafka 更容易与其他工具结合。<br>大多数其他流处理的框架的问题在于它们运行和部署的复杂性。例如 Spark 这样的处理框架需要以下几点：</p>\n<ol>\n<li>在一组计算机上控制大量的作业，并在集群上有效的分配。</li>\n<li>为此，必须动态打包你的程序并将其部署在它需要执行的节点（以及配置、库等）。</li>\n</ol>\n<p>为此，要处理以上问题，使得框架尤为复杂。它们需要控制很多方面：部署、配置、监控和打包。<br>Kafka 流能够允许你在你需要时，提出自己的部署策略，例如 Kubernetes、Mesos、Nomad、Docker Swarm 或者其他方式。<br>Kafka Streams 的基本目的是使所有应用程序能够进行流处理，而无需运行和维护另一个操作复杂的集群。  唯一潜在的缺点是它与卡夫卡紧密结合，但在现代世界中，大多数（如果不是全部）实时处理由卡夫卡提供动力可能不是一个很大的劣势。</p>\n<h2 id=\"何时启用-Kafka\"><a href=\"#何时启用-Kafka\" class=\"headerlink\" title=\"何时启用 Kafka\"></a>何时启用 Kafka</h2><p>正如我们已经介绍的，Kafka 允许通过集中式介质获取大量消息并且存储他们，并不担心性能或数据丢失等问题。<br>这意味着非常适合用在系统框架的核心，充当连接不同程序的中间媒介。Kafka 能够成为事件驱动架构的中心部分，是您能够真正的将应用程序间解耦。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1551888348371-8ade2e7b-bab2-4c43-9172-231a08b074c0.png#align=left&amp;display=inline&amp;height=337&amp;name=image.png&amp;originHeight=674&amp;originWidth=900&amp;size=432210&amp;status=done&amp;width=450\" alt=\"image.png\"><br>Kafka 能够非常轻松的分离不同（微）服务之间的通信。使用 Streams API，现在可以更容易的编写业务逻辑，从而丰富 Kafka 主题数据以便提供服务。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>Apache Kafka 作为分布式流平台，每天可以处理数以万亿计的事件。Kafka 提供低延迟、高吞吐量、高容错和订阅式流水线，同时能够流式处理事件。<br>我们回顾了它的基本语义（生产者、代理、消费者和 Topic），了解了它的一些优化（page cache），通过复制数据了解了它的容错能力，并且介绍了它不断增长的强大流功能。</p>\n"},{"title":"python协程gevent","urlname":"burgq0","date":"2020-05-26T15:00:58.000Z","_content":"\n## 协程\n\n由于 python 解释器使用全局解释器锁（Global Interpreter Lock，GIL），设计锁是为了同步线程。能够确保任一时刻，仅有一个线程真正的在工作。\n所以为了能够实现多线程工作，引出了协程（Coroutine）。协程作为一种计算机程序组件，能够允许挂起和恢复执行来概括非抢占式多任务处理的子流程。协程非常适合于实现熟悉的程序组件，例如协作任务，异常，事件循环，迭代器，无线列表和管道。\n","source":"_posts/python协程gevent.md","raw":"---\ntitle: python协程gevent\nurlname: burgq0\ndate: 2020-05-26 23:00:58 +0800\ntags: []\ncategories: []\n---\n\n## 协程\n\n由于 python 解释器使用全局解释器锁（Global Interpreter Lock，GIL），设计锁是为了同步线程。能够确保任一时刻，仅有一个线程真正的在工作。\n所以为了能够实现多线程工作，引出了协程（Coroutine）。协程作为一种计算机程序组件，能够允许挂起和恢复执行来概括非抢占式多任务处理的子流程。协程非常适合于实现熟悉的程序组件，例如协作任务，异常，事件循环，迭代器，无线列表和管道。\n","slug":"python协程gevent","published":1,"updated":"2020-05-28T16:57:35.821Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckasagni4000ex396jg55os2c","content":"<h2 id=\"协程\"><a href=\"#协程\" class=\"headerlink\" title=\"协程\"></a>协程</h2><p>由于 python 解释器使用全局解释器锁（Global Interpreter Lock，GIL），设计锁是为了同步线程。能够确保任一时刻，仅有一个线程真正的在工作。<br>所以为了能够实现多线程工作，引出了协程（Coroutine）。协程作为一种计算机程序组件，能够允许挂起和恢复执行来概括非抢占式多任务处理的子流程。协程非常适合于实现熟悉的程序组件，例如协作任务，异常，事件循环，迭代器，无线列表和管道。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"协程\"><a href=\"#协程\" class=\"headerlink\" title=\"协程\"></a>协程</h2><p>由于 python 解释器使用全局解释器锁（Global Interpreter Lock，GIL），设计锁是为了同步线程。能够确保任一时刻，仅有一个线程真正的在工作。<br>所以为了能够实现多线程工作，引出了协程（Coroutine）。协程作为一种计算机程序组件，能够允许挂起和恢复执行来概括非抢占式多任务处理的子流程。协程非常适合于实现熟悉的程序组件，例如协作任务，异常，事件循环，迭代器，无线列表和管道。</p>\n"},{"title":"技术系分","urlname":"qtgsdn","date":"2019-01-21T15:13:25.000Z","_content":"\n<!doctype html><div data-lake-element=\"root\" class=\"lake-engine lake-typography-traditional\" data-parser-by=\"lake2html\"></div>\n","source":"_posts/技术系分.md","raw":"---\ntitle: 技术系分\nurlname: qtgsdn\ndate: 2019-01-21 23:13:25 +0800\ntags: []\ncategories: []\n---\n\n<!doctype html><div data-lake-element=\"root\" class=\"lake-engine lake-typography-traditional\" data-parser-by=\"lake2html\"></div>\n","slug":"技术系分","published":1,"updated":"2020-05-28T16:57:36.357Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckasagni5000gx3969o34v70p","content":"<p>&lt;!doctype html&gt;<div data-lake-element=\"root\" class=\"lake-engine lake-typography-traditional\" data-parser-by=\"lake2html\"></div></p>\n","site":{"data":{}},"excerpt":"","more":"<p>&lt;!doctype html&gt;<div data-lake-element=\"root\" class=\"lake-engine lake-typography-traditional\" data-parser-by=\"lake2html\"></div></p>\n"},{"title":"测试语雀-Travis-Hexo","urlname":"dbxh9r","date":"2019-01-28T16:16:15.000Z","_content":"\n## 信息来源\n\n本次语雀到 Travis 的配置，来源于：\n[https://segmentfault.com/a/1190000017797561#articleHeader1](https://segmentfault.com/a/1190000017797561#articleHeader1)\n\n仅分享搭建历程，及代码分析。\n\n## TEST 步骤\n\n第一次，init 测试。检测是否同步信息，有效期 5 分钟。过期删除\n第二次测试，时间 5 分钟\n第三次测试，时间 3 分钟\n第四次测试，时间 3 分钟，仅测试 POSTMan 触发请求，查看语雀是否会同步至 github。失败\n第五次测试，测试 yuque-hexo 组件 clean/sync 命令的先后顺序。\n第六次测试，测试 yuque-hexo 组件，先 clean 后执行 sync 命令。\n第七次测试，测试 POSTMan 触发请求。\n第八次测试，测试 serverless 函数的正确性。\n第九次测试，测试 serverless 函数的正确性。\n第十次测试，测试 serverless 函数的正确性,参数进行硬编码。\n第十一次测试，测试 serverless 函数的正确性.\n第十二次测试，测试 serverless 函数的正确性.\n第十二次测试，测试 serverless 函数的正确性,测试返回值。\n第十三次测试，测试 Travis pull queest 的设置是否阻止的触发。\n第十四次测试，测试 serverless 函数的正确性,移除触发 body 体的 message。\n第十五次测试，更改上次 body 体的错误，错误传输<‘hexo’>，加了单引号，未识别。\n成功了，哈哈。。。\n2019.1.30\n","source":"_posts/测试语雀-Travis-Hexo.md","raw":"---\ntitle: 测试语雀-Travis-Hexo\nurlname: dbxh9r\ndate: 2019-01-29 00:16:15 +0800\ntags: []\ncategories: []\n---\n\n## 信息来源\n\n本次语雀到 Travis 的配置，来源于：\n[https://segmentfault.com/a/1190000017797561#articleHeader1](https://segmentfault.com/a/1190000017797561#articleHeader1)\n\n仅分享搭建历程，及代码分析。\n\n## TEST 步骤\n\n第一次，init 测试。检测是否同步信息，有效期 5 分钟。过期删除\n第二次测试，时间 5 分钟\n第三次测试，时间 3 分钟\n第四次测试，时间 3 分钟，仅测试 POSTMan 触发请求，查看语雀是否会同步至 github。失败\n第五次测试，测试 yuque-hexo 组件 clean/sync 命令的先后顺序。\n第六次测试，测试 yuque-hexo 组件，先 clean 后执行 sync 命令。\n第七次测试，测试 POSTMan 触发请求。\n第八次测试，测试 serverless 函数的正确性。\n第九次测试，测试 serverless 函数的正确性。\n第十次测试，测试 serverless 函数的正确性,参数进行硬编码。\n第十一次测试，测试 serverless 函数的正确性.\n第十二次测试，测试 serverless 函数的正确性.\n第十二次测试，测试 serverless 函数的正确性,测试返回值。\n第十三次测试，测试 Travis pull queest 的设置是否阻止的触发。\n第十四次测试，测试 serverless 函数的正确性,移除触发 body 体的 message。\n第十五次测试，更改上次 body 体的错误，错误传输<‘hexo’>，加了单引号，未识别。\n成功了，哈哈。。。\n2019.1.30\n","slug":"测试语雀-Travis-Hexo","published":1,"updated":"2020-05-28T16:57:36.350Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckasagni7000jx396gqm8zzdh","content":"<h2 id=\"信息来源\"><a href=\"#信息来源\" class=\"headerlink\" title=\"信息来源\"></a>信息来源</h2><p>本次语雀到 Travis 的配置，来源于：<br><a href=\"https://segmentfault.com/a/1190000017797561#articleHeader1\" target=\"_blank\" rel=\"noopener\">https://segmentfault.com/a/1190000017797561#articleHeader1</a></p>\n<p>仅分享搭建历程，及代码分析。</p>\n<h2 id=\"TEST-步骤\"><a href=\"#TEST-步骤\" class=\"headerlink\" title=\"TEST 步骤\"></a>TEST 步骤</h2><p>第一次，init 测试。检测是否同步信息，有效期 5 分钟。过期删除<br>第二次测试，时间 5 分钟<br>第三次测试，时间 3 分钟<br>第四次测试，时间 3 分钟，仅测试 POSTMan 触发请求，查看语雀是否会同步至 github。失败<br>第五次测试，测试 yuque-hexo 组件 clean/sync 命令的先后顺序。<br>第六次测试，测试 yuque-hexo 组件，先 clean 后执行 sync 命令。<br>第七次测试，测试 POSTMan 触发请求。<br>第八次测试，测试 serverless 函数的正确性。<br>第九次测试，测试 serverless 函数的正确性。<br>第十次测试，测试 serverless 函数的正确性,参数进行硬编码。<br>第十一次测试，测试 serverless 函数的正确性.<br>第十二次测试，测试 serverless 函数的正确性.<br>第十二次测试，测试 serverless 函数的正确性,测试返回值。<br>第十三次测试，测试 Travis pull queest 的设置是否阻止的触发。<br>第十四次测试，测试 serverless 函数的正确性,移除触发 body 体的 message。<br>第十五次测试，更改上次 body 体的错误，错误传输&lt;‘hexo’&gt;，加了单引号，未识别。<br>成功了，哈哈。。。<br>2019.1.30</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"信息来源\"><a href=\"#信息来源\" class=\"headerlink\" title=\"信息来源\"></a>信息来源</h2><p>本次语雀到 Travis 的配置，来源于：<br><a href=\"https://segmentfault.com/a/1190000017797561#articleHeader1\" target=\"_blank\" rel=\"noopener\">https://segmentfault.com/a/1190000017797561#articleHeader1</a></p>\n<p>仅分享搭建历程，及代码分析。</p>\n<h2 id=\"TEST-步骤\"><a href=\"#TEST-步骤\" class=\"headerlink\" title=\"TEST 步骤\"></a>TEST 步骤</h2><p>第一次，init 测试。检测是否同步信息，有效期 5 分钟。过期删除<br>第二次测试，时间 5 分钟<br>第三次测试，时间 3 分钟<br>第四次测试，时间 3 分钟，仅测试 POSTMan 触发请求，查看语雀是否会同步至 github。失败<br>第五次测试，测试 yuque-hexo 组件 clean/sync 命令的先后顺序。<br>第六次测试，测试 yuque-hexo 组件，先 clean 后执行 sync 命令。<br>第七次测试，测试 POSTMan 触发请求。<br>第八次测试，测试 serverless 函数的正确性。<br>第九次测试，测试 serverless 函数的正确性。<br>第十次测试，测试 serverless 函数的正确性,参数进行硬编码。<br>第十一次测试，测试 serverless 函数的正确性.<br>第十二次测试，测试 serverless 函数的正确性.<br>第十二次测试，测试 serverless 函数的正确性,测试返回值。<br>第十三次测试，测试 Travis pull queest 的设置是否阻止的触发。<br>第十四次测试，测试 serverless 函数的正确性,移除触发 body 体的 message。<br>第十五次测试，更改上次 body 体的错误，错误传输&lt;‘hexo’&gt;，加了单引号，未识别。<br>成功了，哈哈。。。<br>2019.1.30</p>\n"},{"title":"Docker基础知识--Cgroup","date":"2020-01-08T14:24:05.000Z","_content":"<a name=\"JddnB\"></a>\n## 前言\n上篇中，已经讨论了Docker作为虚拟化技术，所采用的基础技术namespace，以此来进行资源隔离。同时，我们也想到了另外一个问题，在资源隔离后，实际上仍然是占用host的资源，如何保证资源（CPU、内存和IO）被有效的控制，为此Docker引入另外一项关键技术---Control group ( `Cgroup`)。\n<a name=\"RUUyP\"></a>\n## 何为Cgroup\n在Linux系统中，内核本身的调度和管理并不对进程和线程进行区分，只会根据`clone`创建时传入的值不同，来区分进程和线程。<br />Cgroup全称为 `control grup` ，由06年合入linux内核，就是把任务放在一个组里进行控制。我们给出官方的定义：<br />cgroup是Linux内核提供的一种机制，这种机制可以根据需要把一系列的系统任务和对应的子任务整合（或者分割）到资源划分等级的不同组内。从而对系统的资源，提供了一个完整的控制框架。\n<a name=\"TwlUt\"></a>\n## Cgroup的四个特点\n\n1. cgroup的API以仿文件系统的方式实现，用户态的进程可以通过管理文件的方式完成组织管理\n1. cgroup的组织管理，最小颗粒度为线程级别，此外用户有权限创建和销毁cgroup，从而实现资源再分配\n1. 所有的资源管理的功能都以**子系统**的方式实现，保证API接口的统一性\n1. 所有子系统的资源组与父任务相同\n\n所有我们，可以认为，cgroup是附加在程序上的钩子（hook），通过程序运行时，对资源进行调度触发钩子达到资源监控和控制。\n\n<a name=\"W4If8\"></a>\n## Cgroup原理\n在介绍Cgroup原理之前，我们先熟悉两个概念：组织结构与基本规则、子系统。\n<a name=\"HbJbH\"></a>\n### Cgroup的组织结构\n传统的Unix体系中，首先启动init的进程作为root进程，再由init进程扩展创建子系统作为子节点，而每个子节点又重复此方式，往复循序。而Cgroup也创建类似树状结构，子节点继承自父节点。<br />与传统init方式不同，cgroup运行多个父节点，即cgroup子节点对应的父节点可以有多个。在Docker中每个子系统独自构成一个层级，便于管理。\n<a name=\"mN4zx\"></a>\n#### Cgroup的组织规则\n\n1. 同一个层级可以附加多个子系统\n1. 一个子系统可以附加到多个层级，但前提是，关联的层级仅能与此子系统相连，即当且仅当目标层级只有唯一一个子系统时。\n1. 系统每次创建一个新的层级，该系统上所有任务默认加入这个新建层级的初始化层级，即 `root cgroup` 。任务在同一层级，仅能有一份。\n1. 任务在 `fork/clone` 自身时，创建的子任务默认与原任务在同一层级（cgroup）中，但子任务运行被移动到不同个的cgroup中。\n<a name=\"1CXfE\"></a>\n### 子系统介绍\nblkio -- 这个子系统为块设备设定输入/输出限制，比如物理设备（磁盘，固态硬盘，USB 等等）。<br />cpu -- 这个子系统使用调度程序提供对 CPU 的 cgroup 任务访问。<br />cpuacct -- 这个子系统自动生成 cgroup 中任务所使用的 CPU 报告。<br />cpuset -- 这个子系统为 cgroup 中的任务分配独立 CPU（在多核系统）和内存节点。<br />devices -- 这个子系统可允许或者拒绝 cgroup 中的任务访问设备。<br />freezer -- 这个子系统挂起或者恢复 cgroup 中的任务。<br />memory -- 这个子系统设定 cgroup 中任务使用的内存限制，并自动生成由那些任务使用的内存资源报告。<br />net_cls -- 这个子系统使用等级识别符（classid）标记网络数据包，可允许 Linux 流量控制程序（tc）识别从具体 cgroup 中生成的数据包。<br />ns -- 名称空间子系统。\n\n\n\n\n\n","source":"_posts/yuque/Docker基础知识--Cgroup.md","raw":"\n---\ntitle: Docker基础知识--Cgroup\ndate: 2020-01-08 22:24:05 +0800\ntags: [docker,Cgroup]\ncategories: \n---\n<a name=\"JddnB\"></a>\n## 前言\n上篇中，已经讨论了Docker作为虚拟化技术，所采用的基础技术namespace，以此来进行资源隔离。同时，我们也想到了另外一个问题，在资源隔离后，实际上仍然是占用host的资源，如何保证资源（CPU、内存和IO）被有效的控制，为此Docker引入另外一项关键技术---Control group ( `Cgroup`)。\n<a name=\"RUUyP\"></a>\n## 何为Cgroup\n在Linux系统中，内核本身的调度和管理并不对进程和线程进行区分，只会根据`clone`创建时传入的值不同，来区分进程和线程。<br />Cgroup全称为 `control grup` ，由06年合入linux内核，就是把任务放在一个组里进行控制。我们给出官方的定义：<br />cgroup是Linux内核提供的一种机制，这种机制可以根据需要把一系列的系统任务和对应的子任务整合（或者分割）到资源划分等级的不同组内。从而对系统的资源，提供了一个完整的控制框架。\n<a name=\"TwlUt\"></a>\n## Cgroup的四个特点\n\n1. cgroup的API以仿文件系统的方式实现，用户态的进程可以通过管理文件的方式完成组织管理\n1. cgroup的组织管理，最小颗粒度为线程级别，此外用户有权限创建和销毁cgroup，从而实现资源再分配\n1. 所有的资源管理的功能都以**子系统**的方式实现，保证API接口的统一性\n1. 所有子系统的资源组与父任务相同\n\n所有我们，可以认为，cgroup是附加在程序上的钩子（hook），通过程序运行时，对资源进行调度触发钩子达到资源监控和控制。\n\n<a name=\"W4If8\"></a>\n## Cgroup原理\n在介绍Cgroup原理之前，我们先熟悉两个概念：组织结构与基本规则、子系统。\n<a name=\"HbJbH\"></a>\n### Cgroup的组织结构\n传统的Unix体系中，首先启动init的进程作为root进程，再由init进程扩展创建子系统作为子节点，而每个子节点又重复此方式，往复循序。而Cgroup也创建类似树状结构，子节点继承自父节点。<br />与传统init方式不同，cgroup运行多个父节点，即cgroup子节点对应的父节点可以有多个。在Docker中每个子系统独自构成一个层级，便于管理。\n<a name=\"mN4zx\"></a>\n#### Cgroup的组织规则\n\n1. 同一个层级可以附加多个子系统\n1. 一个子系统可以附加到多个层级，但前提是，关联的层级仅能与此子系统相连，即当且仅当目标层级只有唯一一个子系统时。\n1. 系统每次创建一个新的层级，该系统上所有任务默认加入这个新建层级的初始化层级，即 `root cgroup` 。任务在同一层级，仅能有一份。\n1. 任务在 `fork/clone` 自身时，创建的子任务默认与原任务在同一层级（cgroup）中，但子任务运行被移动到不同个的cgroup中。\n<a name=\"1CXfE\"></a>\n### 子系统介绍\nblkio -- 这个子系统为块设备设定输入/输出限制，比如物理设备（磁盘，固态硬盘，USB 等等）。<br />cpu -- 这个子系统使用调度程序提供对 CPU 的 cgroup 任务访问。<br />cpuacct -- 这个子系统自动生成 cgroup 中任务所使用的 CPU 报告。<br />cpuset -- 这个子系统为 cgroup 中的任务分配独立 CPU（在多核系统）和内存节点。<br />devices -- 这个子系统可允许或者拒绝 cgroup 中的任务访问设备。<br />freezer -- 这个子系统挂起或者恢复 cgroup 中的任务。<br />memory -- 这个子系统设定 cgroup 中任务使用的内存限制，并自动生成由那些任务使用的内存资源报告。<br />net_cls -- 这个子系统使用等级识别符（classid）标记网络数据包，可允许 Linux 流量控制程序（tc）识别从具体 cgroup 中生成的数据包。<br />ns -- 名称空间子系统。\n\n\n\n\n\n","slug":"yuque/Docker基础知识--Cgroup","published":1,"updated":"2020-05-28T16:59:39.248Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckasagnix000yx396jrt5o9rx","content":"<p><a name=\"JddnB\"></a></p>\n<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>上篇中，已经讨论了Docker作为虚拟化技术，所采用的基础技术namespace，以此来进行资源隔离。同时，我们也想到了另外一个问题，在资源隔离后，实际上仍然是占用host的资源，如何保证资源（CPU、内存和IO）被有效的控制，为此Docker引入另外一项关键技术—Control group ( <code>Cgroup</code>)。<br><a name=\"RUUyP\"></a></p>\n<h2 id=\"何为Cgroup\"><a href=\"#何为Cgroup\" class=\"headerlink\" title=\"何为Cgroup\"></a>何为Cgroup</h2><p>在Linux系统中，内核本身的调度和管理并不对进程和线程进行区分，只会根据<code>clone</code>创建时传入的值不同，来区分进程和线程。<br>Cgroup全称为 <code>control grup</code> ，由06年合入linux内核，就是把任务放在一个组里进行控制。我们给出官方的定义：<br>cgroup是Linux内核提供的一种机制，这种机制可以根据需要把一系列的系统任务和对应的子任务整合（或者分割）到资源划分等级的不同组内。从而对系统的资源，提供了一个完整的控制框架。<br><a name=\"TwlUt\"></a></p>\n<h2 id=\"Cgroup的四个特点\"><a href=\"#Cgroup的四个特点\" class=\"headerlink\" title=\"Cgroup的四个特点\"></a>Cgroup的四个特点</h2><ol>\n<li>cgroup的API以仿文件系统的方式实现，用户态的进程可以通过管理文件的方式完成组织管理</li>\n<li>cgroup的组织管理，最小颗粒度为线程级别，此外用户有权限创建和销毁cgroup，从而实现资源再分配</li>\n<li>所有的资源管理的功能都以<strong>子系统</strong>的方式实现，保证API接口的统一性</li>\n<li>所有子系统的资源组与父任务相同</li>\n</ol>\n<p>所有我们，可以认为，cgroup是附加在程序上的钩子（hook），通过程序运行时，对资源进行调度触发钩子达到资源监控和控制。</p>\n<p><a name=\"W4If8\"></a></p>\n<h2 id=\"Cgroup原理\"><a href=\"#Cgroup原理\" class=\"headerlink\" title=\"Cgroup原理\"></a>Cgroup原理</h2><p>在介绍Cgroup原理之前，我们先熟悉两个概念：组织结构与基本规则、子系统。<br><a name=\"HbJbH\"></a></p>\n<h3 id=\"Cgroup的组织结构\"><a href=\"#Cgroup的组织结构\" class=\"headerlink\" title=\"Cgroup的组织结构\"></a>Cgroup的组织结构</h3><p>传统的Unix体系中，首先启动init的进程作为root进程，再由init进程扩展创建子系统作为子节点，而每个子节点又重复此方式，往复循序。而Cgroup也创建类似树状结构，子节点继承自父节点。<br>与传统init方式不同，cgroup运行多个父节点，即cgroup子节点对应的父节点可以有多个。在Docker中每个子系统独自构成一个层级，便于管理。<br><a name=\"mN4zx\"></a></p>\n<h4 id=\"Cgroup的组织规则\"><a href=\"#Cgroup的组织规则\" class=\"headerlink\" title=\"Cgroup的组织规则\"></a>Cgroup的组织规则</h4><ol>\n<li>同一个层级可以附加多个子系统</li>\n<li>一个子系统可以附加到多个层级，但前提是，关联的层级仅能与此子系统相连，即当且仅当目标层级只有唯一一个子系统时。</li>\n<li>系统每次创建一个新的层级，该系统上所有任务默认加入这个新建层级的初始化层级，即 <code>root cgroup</code> 。任务在同一层级，仅能有一份。</li>\n<li>任务在 <code>fork/clone</code> 自身时，创建的子任务默认与原任务在同一层级（cgroup）中，但子任务运行被移动到不同个的cgroup中。<br><a name=\"1CXfE\"></a><h3 id=\"子系统介绍\"><a href=\"#子系统介绍\" class=\"headerlink\" title=\"子系统介绍\"></a>子系统介绍</h3>blkio – 这个子系统为块设备设定输入/输出限制，比如物理设备（磁盘，固态硬盘，USB 等等）。<br>cpu – 这个子系统使用调度程序提供对 CPU 的 cgroup 任务访问。<br>cpuacct – 这个子系统自动生成 cgroup 中任务所使用的 CPU 报告。<br>cpuset – 这个子系统为 cgroup 中的任务分配独立 CPU（在多核系统）和内存节点。<br>devices – 这个子系统可允许或者拒绝 cgroup 中的任务访问设备。<br>freezer – 这个子系统挂起或者恢复 cgroup 中的任务。<br>memory – 这个子系统设定 cgroup 中任务使用的内存限制，并自动生成由那些任务使用的内存资源报告。<br>net_cls – 这个子系统使用等级识别符（classid）标记网络数据包，可允许 Linux 流量控制程序（tc）识别从具体 cgroup 中生成的数据包。<br>ns – 名称空间子系统。</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<p><a name=\"JddnB\"></a></p>\n<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>上篇中，已经讨论了Docker作为虚拟化技术，所采用的基础技术namespace，以此来进行资源隔离。同时，我们也想到了另外一个问题，在资源隔离后，实际上仍然是占用host的资源，如何保证资源（CPU、内存和IO）被有效的控制，为此Docker引入另外一项关键技术—Control group ( <code>Cgroup</code>)。<br><a name=\"RUUyP\"></a></p>\n<h2 id=\"何为Cgroup\"><a href=\"#何为Cgroup\" class=\"headerlink\" title=\"何为Cgroup\"></a>何为Cgroup</h2><p>在Linux系统中，内核本身的调度和管理并不对进程和线程进行区分，只会根据<code>clone</code>创建时传入的值不同，来区分进程和线程。<br>Cgroup全称为 <code>control grup</code> ，由06年合入linux内核，就是把任务放在一个组里进行控制。我们给出官方的定义：<br>cgroup是Linux内核提供的一种机制，这种机制可以根据需要把一系列的系统任务和对应的子任务整合（或者分割）到资源划分等级的不同组内。从而对系统的资源，提供了一个完整的控制框架。<br><a name=\"TwlUt\"></a></p>\n<h2 id=\"Cgroup的四个特点\"><a href=\"#Cgroup的四个特点\" class=\"headerlink\" title=\"Cgroup的四个特点\"></a>Cgroup的四个特点</h2><ol>\n<li>cgroup的API以仿文件系统的方式实现，用户态的进程可以通过管理文件的方式完成组织管理</li>\n<li>cgroup的组织管理，最小颗粒度为线程级别，此外用户有权限创建和销毁cgroup，从而实现资源再分配</li>\n<li>所有的资源管理的功能都以<strong>子系统</strong>的方式实现，保证API接口的统一性</li>\n<li>所有子系统的资源组与父任务相同</li>\n</ol>\n<p>所有我们，可以认为，cgroup是附加在程序上的钩子（hook），通过程序运行时，对资源进行调度触发钩子达到资源监控和控制。</p>\n<p><a name=\"W4If8\"></a></p>\n<h2 id=\"Cgroup原理\"><a href=\"#Cgroup原理\" class=\"headerlink\" title=\"Cgroup原理\"></a>Cgroup原理</h2><p>在介绍Cgroup原理之前，我们先熟悉两个概念：组织结构与基本规则、子系统。<br><a name=\"HbJbH\"></a></p>\n<h3 id=\"Cgroup的组织结构\"><a href=\"#Cgroup的组织结构\" class=\"headerlink\" title=\"Cgroup的组织结构\"></a>Cgroup的组织结构</h3><p>传统的Unix体系中，首先启动init的进程作为root进程，再由init进程扩展创建子系统作为子节点，而每个子节点又重复此方式，往复循序。而Cgroup也创建类似树状结构，子节点继承自父节点。<br>与传统init方式不同，cgroup运行多个父节点，即cgroup子节点对应的父节点可以有多个。在Docker中每个子系统独自构成一个层级，便于管理。<br><a name=\"mN4zx\"></a></p>\n<h4 id=\"Cgroup的组织规则\"><a href=\"#Cgroup的组织规则\" class=\"headerlink\" title=\"Cgroup的组织规则\"></a>Cgroup的组织规则</h4><ol>\n<li>同一个层级可以附加多个子系统</li>\n<li>一个子系统可以附加到多个层级，但前提是，关联的层级仅能与此子系统相连，即当且仅当目标层级只有唯一一个子系统时。</li>\n<li>系统每次创建一个新的层级，该系统上所有任务默认加入这个新建层级的初始化层级，即 <code>root cgroup</code> 。任务在同一层级，仅能有一份。</li>\n<li>任务在 <code>fork/clone</code> 自身时，创建的子任务默认与原任务在同一层级（cgroup）中，但子任务运行被移动到不同个的cgroup中。<br><a name=\"1CXfE\"></a><h3 id=\"子系统介绍\"><a href=\"#子系统介绍\" class=\"headerlink\" title=\"子系统介绍\"></a>子系统介绍</h3>blkio – 这个子系统为块设备设定输入/输出限制，比如物理设备（磁盘，固态硬盘，USB 等等）。<br>cpu – 这个子系统使用调度程序提供对 CPU 的 cgroup 任务访问。<br>cpuacct – 这个子系统自动生成 cgroup 中任务所使用的 CPU 报告。<br>cpuset – 这个子系统为 cgroup 中的任务分配独立 CPU（在多核系统）和内存节点。<br>devices – 这个子系统可允许或者拒绝 cgroup 中的任务访问设备。<br>freezer – 这个子系统挂起或者恢复 cgroup 中的任务。<br>memory – 这个子系统设定 cgroup 中任务使用的内存限制，并自动生成由那些任务使用的内存资源报告。<br>net_cls – 这个子系统使用等级识别符（classid）标记网络数据包，可允许 Linux 流量控制程序（tc）识别从具体 cgroup 中生成的数据包。<br>ns – 名称空间子系统。</li>\n</ol>\n"},{"title":"Docker基础原理--namespace（pid与network）","date":"2019-12-18T13:10:11.000Z","_content":"<a name=\"zz3z6\"></a>\n## 前言\n在计算机系统中为了标识不同的作用域，而引入namespace（命名空间）的概念。namespace作用在内核级别的隔离，可以有效阻止不同进程间的通信。在日常的Linux系统中，通常服务在启动后的进程，彼此之间不会特意进行隔离，例如Web服务器中，Nginx、MySQL和rides，三个服务之间亦可访问任意主机中的文件。如果任一服务不慎被攻破，会被入侵其他的服务。因而namespace的引入，可以有效防止不同服务或进程间的相互干扰。<br />Docker使用Linux的namespace技术，对实现的容器，做了多种层次的隔离。Docker所使用的七种namespace如下：`CLONE_NEWCGROUP`、`CLONE_NEWIPC`、`CLONE_NEWNET`、`CLONE_NEWNS`、`CLONE_NEWPID`、`CLONE_NEWUSER` 和 `CLONE_NEWUTS`。通过在进程中添加如上属性，便能保证与宿主机的对应资源进行有效隔离。\n\n<a name=\"Xv7G5\"></a>\n## 进程\n在分时操作系统中，进程作为程序的基本执行单元，也是资源（CPU、内存）分配的基本单位。当服务、程序启动后，操作系统为其开辟一个进程，并为它分配资源，除等待CPU资源，其他资源以及就绪，此时进入到**就绪态。**当时间片分割的进程，在高优先级调度队列被调度后，进程开始运行。<br />进程的三种状态：就绪态、运行态和阻断状态。<br />Linux的进程，可以通过`ps -elf`命令进行查看，下图为Centos系统的截图：\n```bash\nps -ef\nUID        PID  PPID  C STIME TTY          TIME CMD\nroot         1     0  0 9月24 ?       00:01:32 /usr/lib/systemd/systemd --switched-root --system --deserialize 22\nroot         2     0  0 9月24 ?       00:00:00 [kthreadd]\nroot         3     2  0 9月24 ?       00:00:00 [rcu_gp]\nroot         4     2  0 9月24 ?       00:00:00 [rcu_par_gp]\n```\n当前机器中，运行着很多进程，但都以一个 1号进程开始，即pid=1的进程init。此进程作为所以后续进程的父进程。例如pid=39的进程，其父进程（PPID=1）。\n\n- pid=0号进程idle，其前身是系统创建的第一个进程，也是唯一一个没有通过fork或者kernel_thread产生的进程。完成加载系统后，演变为进程调度、交换\n- pid=1号进程init，负责执行内核的初始化工作和系统配置。\n- pid=2的kthreadd进程，始终运行在内核空间, 负责所有内核线程的调度和管理。\n<a name=\"8tSQB\"></a>\n## Docker容器内进程PID\n以RabbitMQ容器为例，通过如下命令进入rabbitmq容器后，使用ps -ef命令，再次查看容器内的进程，可以与上面的系统进程进行比较。\n\n```bash\n[root@li1559-144 ~]# docker exec -it 28b6862b34a9 bash\nroot@28b6862b34a9:/# ps -ef\nUID        PID  PPID  C STIME TTY          TIME CMD\nrabbitmq     1     0  0 16:07 ?        00:00:00 /bin/sh /opt/rabbitmq/sbin/rabbitmq-server\nrabbitmq   138     1  0 16:07 ?        00:00:00 /usr/local/lib/erlang/erts-10.4.4/bin/epmd -daemon\n```\n当前容器内，PID=1的进程为 rabbitmq-server，与Linux的宿主机的PID=1的init进程不同。此时，容器内的进程以及与宿主机完全隔离。<br />宿主机与rabbitmq容器之间的进程对应关系，如下所示（摘自@Draveness）：<br />![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1576771885943-5e1c23b8-82e6-43ee-bb68-1f9ef836e98d.png#align=left&display=inline&height=260&name=image.png&originHeight=520&originWidth=1200&size=83888&status=done&style=none&width=600)<br />因此容器内的进程，对宿主机的进程一无所知。实现了内核级的隔离。\n\nDocker在使用上述隔离技术，进行资源的隔离。当我们每次运行 `docker run` 或者 `docker start` 时，都会调用以下代码块（moby:[https://github.com/moby](https://github.com/moby)），创建资源隔离的容器：\n\n```go\nfunc (daemon *Daemon) createSpec(c *container.Container) (retSpec *specs.Spec, err error) {\n\tvar (\n\t\topts []coci.SpecOpts\n\t\ts    = oci.DefaultSpec()\n\t)\n\topts = append(opts,\n\t\tWithCommonOptions(daemon, c),\n\t\tWithCgroups(daemon, c),\t//添加Cgroups，进行资源限制\n\t\tWithResources(c),\n\t\tWithSysctls(c),\n\t\tWithDevices(daemon, c),\n\t\tWithUser(c),\n\t\tWithRlimits(daemon, c),\n\t\tWithNamespaces(daemon, c),\t//添加namespace，进行资源隔离\n\t\tWithCapabilities(c),\n\t\tWithSeccomp(daemon, c),\n\t\tWithMounts(daemon, c),\t\t//添加挂载点\n\t\tWithLibnetwork(daemon, c),\n\t\tWithApparmor(c),\n\t\tWithSelinux(c),\n\t\tWithOOMScore(&c.HostConfig.OomScoreAdj),\n\t)\n```\n在 `WithNamespaces(daemon, c)` 函数中，会设置 `user` `network` `ipc` `pid`  `uts` 以及 `cgroup` ，需要主要的是moby项目中，`CLONE_NEWNS`即文件系统被单独在 `WithMounts(daemon, c)` 函数中设置。\n\n```go\nfunc WithNamespaces(daemon *Daemon, c *container.Container) coci.SpecOpts {\n\treturn func(ctx context.Context, _ coci.Client, _ *containers.Container, s *coci.Spec) error {\n\t\tuserNS := false\n\t\t// user\n        // network\n        // ipc\n        //pid\n        if c.HostConfig.PidMode.IsContainer() {\n\t\t\tns := specs.LinuxNamespace{Type: \"pid\"}\n\t\t\tpc, err := daemon.getPidContainer(c)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tns.Path = fmt.Sprintf(\"/proc/%d/ns/pid\", pc.State.GetPID())\n\t\t\tsetNamespace(s, ns)\n\t\t\tif userNS {\n\t\t\t\t// to share a PID namespace, they must also share a user namespace\n\t\t\t\tnsUser := specs.LinuxNamespace{Type: \"user\"}\n\t\t\t\tnsUser.Path = fmt.Sprintf(\"/proc/%d/ns/user\", pc.State.GetPID())\n\t\t\t\tsetNamespace(s, nsUser)\n\t\t\t}\n\t\t} else if c.HostConfig.PidMode.IsHost() {\n\t\t\toci.RemoveNamespace(s, specs.LinuxNamespaceType(\"pid\"))\n\t\t} else {\n\t\t\tns := specs.LinuxNamespace{Type: \"pid\"}\n\t\t\tsetNamespace(s, ns)\n\t\t}\n        // uts\n        //cgroup\n        return nil\n\t}\n}       \n```\n<a name=\"doIqz\"></a>\n## Docker容器内网络Network\n\nLinux的namespace主要隔离的对象有：网络设备、IPv4和IPv6协议栈、路由表、防火墙、/proc/net目录、/sys/class/net目录、套接字（socket）等。Linux中，物理网络设备默认放置在root namespace中。<br />Docker中为实现网络的独立，又能与宿主机进行通信，为此创建veth pair。将其中的一段放置在容器内通常，通常命名为eth0，另外一段挂载为物理网络设备上所在的namespace中。实际中，docker在docker daemon启动后会创建docker0网桥，docker容器的网络对另一端通常绑定在docker0网桥。<br />现行的docker项目中，自docker>1.9之后，已经将网络单独剥离为 `libnetwork` 库，自此网络模式也被抽象为同样接口。docker现有的网络模式有五种： `bridge驱动` 、 `host驱动` 、 `overlay驱动` 、 `remote驱动` 、 `null驱动` 。<br />接下来，我们手动创建 `veth pair` ，用于模仿docker网桥模式。docker0（lxcbr0）网桥作为二层交换网桥，之所以在上面配置IP，可以认为内部有一个可以用于配置IP信息的网卡接口。Docker在桥接模式下，docker0网桥用于连接容器上的默认网关而存在，并且可以保证在必要时候与宿主机进行网络隔离。\n\n```bash\n## 首先，我们先增加一个网桥lxcbr0，模仿docker0\nbrctl addbr lxcbr0\nbrctl stp lxcbr0 off\nifconfig lxcbr0 192.168.10.1/24 up #为网桥设置IP地址\n \n## 接下来，我们要创建一个network namespace - ns1\n \n# 增加一个namesapce 命令为 ns1 （使用ip netns add命令）\nip netns add ns1 \n \n# 激活namespace中的loopback，即127.0.0.1（使用ip netns exec ns1来操作ns1中的命令）\nip netns exec ns1   ip link set dev lo up \n \n## 然后，我们需要增加一对虚拟网卡\n \n# 增加一个pair虚拟网卡，注意其中的veth类型，其中一个网卡要按进容器中\nip link add veth-ns1 type veth peer name lxcbr0.1\n \n# 把 veth-ns1 按到namespace ns1中，这样容器中就会有一个新的网卡了\nip link set veth-ns1 netns ns1\n \n# 把容器里的 veth-ns1改名为 eth0 （容器外会冲突，容器内就不会了）\nip netns exec ns1  ip link set dev veth-ns1 name eth0 \n \n# 为容器中的网卡分配一个IP地址，并激活它\nip netns exec ns1 ifconfig eth0 192.168.10.11/24 up\n \n \n# 上面我们把veth-ns1这个网卡按到了容器中，然后我们要把lxcbr0.1添加上网桥上\nbrctl addif lxcbr0 lxcbr0.1\n \n# 为容器增加一个路由规则，让容器可以访问外面的网络\nip netns exec ns1     ip route add default via 192.168.10.1\n \n# 在/etc/netns下创建network namespce名称为ns1的目录，\n# 然后为这个namespace设置resolv.conf，这样，容器内就可以访问域名了\nmkdir -p /etc/netns/ns1\necho \"nameserver 8.8.8.8\" > /etc/netns/ns1/resolv.conf\n\n## 引自：https://coolshell.cn/articles/17029.html\n```\n\n详细的Linux的 `ip` 命令，可以参见：[https://wangchujiang.com/linux-command/c/ip.html](https://wangchujiang.com/linux-command/c/ip.html)\n\n","source":"_posts/yuque/Docker基础原理--namespace（pid与network）.md","raw":"\n---\ntitle: Docker基础原理--namespace（pid与network）\ndate: 2019-12-18 21:10:11 +0800\ntags: [docker,namespace]\ncategories: \n---\n<a name=\"zz3z6\"></a>\n## 前言\n在计算机系统中为了标识不同的作用域，而引入namespace（命名空间）的概念。namespace作用在内核级别的隔离，可以有效阻止不同进程间的通信。在日常的Linux系统中，通常服务在启动后的进程，彼此之间不会特意进行隔离，例如Web服务器中，Nginx、MySQL和rides，三个服务之间亦可访问任意主机中的文件。如果任一服务不慎被攻破，会被入侵其他的服务。因而namespace的引入，可以有效防止不同服务或进程间的相互干扰。<br />Docker使用Linux的namespace技术，对实现的容器，做了多种层次的隔离。Docker所使用的七种namespace如下：`CLONE_NEWCGROUP`、`CLONE_NEWIPC`、`CLONE_NEWNET`、`CLONE_NEWNS`、`CLONE_NEWPID`、`CLONE_NEWUSER` 和 `CLONE_NEWUTS`。通过在进程中添加如上属性，便能保证与宿主机的对应资源进行有效隔离。\n\n<a name=\"Xv7G5\"></a>\n## 进程\n在分时操作系统中，进程作为程序的基本执行单元，也是资源（CPU、内存）分配的基本单位。当服务、程序启动后，操作系统为其开辟一个进程，并为它分配资源，除等待CPU资源，其他资源以及就绪，此时进入到**就绪态。**当时间片分割的进程，在高优先级调度队列被调度后，进程开始运行。<br />进程的三种状态：就绪态、运行态和阻断状态。<br />Linux的进程，可以通过`ps -elf`命令进行查看，下图为Centos系统的截图：\n```bash\nps -ef\nUID        PID  PPID  C STIME TTY          TIME CMD\nroot         1     0  0 9月24 ?       00:01:32 /usr/lib/systemd/systemd --switched-root --system --deserialize 22\nroot         2     0  0 9月24 ?       00:00:00 [kthreadd]\nroot         3     2  0 9月24 ?       00:00:00 [rcu_gp]\nroot         4     2  0 9月24 ?       00:00:00 [rcu_par_gp]\n```\n当前机器中，运行着很多进程，但都以一个 1号进程开始，即pid=1的进程init。此进程作为所以后续进程的父进程。例如pid=39的进程，其父进程（PPID=1）。\n\n- pid=0号进程idle，其前身是系统创建的第一个进程，也是唯一一个没有通过fork或者kernel_thread产生的进程。完成加载系统后，演变为进程调度、交换\n- pid=1号进程init，负责执行内核的初始化工作和系统配置。\n- pid=2的kthreadd进程，始终运行在内核空间, 负责所有内核线程的调度和管理。\n<a name=\"8tSQB\"></a>\n## Docker容器内进程PID\n以RabbitMQ容器为例，通过如下命令进入rabbitmq容器后，使用ps -ef命令，再次查看容器内的进程，可以与上面的系统进程进行比较。\n\n```bash\n[root@li1559-144 ~]# docker exec -it 28b6862b34a9 bash\nroot@28b6862b34a9:/# ps -ef\nUID        PID  PPID  C STIME TTY          TIME CMD\nrabbitmq     1     0  0 16:07 ?        00:00:00 /bin/sh /opt/rabbitmq/sbin/rabbitmq-server\nrabbitmq   138     1  0 16:07 ?        00:00:00 /usr/local/lib/erlang/erts-10.4.4/bin/epmd -daemon\n```\n当前容器内，PID=1的进程为 rabbitmq-server，与Linux的宿主机的PID=1的init进程不同。此时，容器内的进程以及与宿主机完全隔离。<br />宿主机与rabbitmq容器之间的进程对应关系，如下所示（摘自@Draveness）：<br />![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1576771885943-5e1c23b8-82e6-43ee-bb68-1f9ef836e98d.png#align=left&display=inline&height=260&name=image.png&originHeight=520&originWidth=1200&size=83888&status=done&style=none&width=600)<br />因此容器内的进程，对宿主机的进程一无所知。实现了内核级的隔离。\n\nDocker在使用上述隔离技术，进行资源的隔离。当我们每次运行 `docker run` 或者 `docker start` 时，都会调用以下代码块（moby:[https://github.com/moby](https://github.com/moby)），创建资源隔离的容器：\n\n```go\nfunc (daemon *Daemon) createSpec(c *container.Container) (retSpec *specs.Spec, err error) {\n\tvar (\n\t\topts []coci.SpecOpts\n\t\ts    = oci.DefaultSpec()\n\t)\n\topts = append(opts,\n\t\tWithCommonOptions(daemon, c),\n\t\tWithCgroups(daemon, c),\t//添加Cgroups，进行资源限制\n\t\tWithResources(c),\n\t\tWithSysctls(c),\n\t\tWithDevices(daemon, c),\n\t\tWithUser(c),\n\t\tWithRlimits(daemon, c),\n\t\tWithNamespaces(daemon, c),\t//添加namespace，进行资源隔离\n\t\tWithCapabilities(c),\n\t\tWithSeccomp(daemon, c),\n\t\tWithMounts(daemon, c),\t\t//添加挂载点\n\t\tWithLibnetwork(daemon, c),\n\t\tWithApparmor(c),\n\t\tWithSelinux(c),\n\t\tWithOOMScore(&c.HostConfig.OomScoreAdj),\n\t)\n```\n在 `WithNamespaces(daemon, c)` 函数中，会设置 `user` `network` `ipc` `pid`  `uts` 以及 `cgroup` ，需要主要的是moby项目中，`CLONE_NEWNS`即文件系统被单独在 `WithMounts(daemon, c)` 函数中设置。\n\n```go\nfunc WithNamespaces(daemon *Daemon, c *container.Container) coci.SpecOpts {\n\treturn func(ctx context.Context, _ coci.Client, _ *containers.Container, s *coci.Spec) error {\n\t\tuserNS := false\n\t\t// user\n        // network\n        // ipc\n        //pid\n        if c.HostConfig.PidMode.IsContainer() {\n\t\t\tns := specs.LinuxNamespace{Type: \"pid\"}\n\t\t\tpc, err := daemon.getPidContainer(c)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tns.Path = fmt.Sprintf(\"/proc/%d/ns/pid\", pc.State.GetPID())\n\t\t\tsetNamespace(s, ns)\n\t\t\tif userNS {\n\t\t\t\t// to share a PID namespace, they must also share a user namespace\n\t\t\t\tnsUser := specs.LinuxNamespace{Type: \"user\"}\n\t\t\t\tnsUser.Path = fmt.Sprintf(\"/proc/%d/ns/user\", pc.State.GetPID())\n\t\t\t\tsetNamespace(s, nsUser)\n\t\t\t}\n\t\t} else if c.HostConfig.PidMode.IsHost() {\n\t\t\toci.RemoveNamespace(s, specs.LinuxNamespaceType(\"pid\"))\n\t\t} else {\n\t\t\tns := specs.LinuxNamespace{Type: \"pid\"}\n\t\t\tsetNamespace(s, ns)\n\t\t}\n        // uts\n        //cgroup\n        return nil\n\t}\n}       \n```\n<a name=\"doIqz\"></a>\n## Docker容器内网络Network\n\nLinux的namespace主要隔离的对象有：网络设备、IPv4和IPv6协议栈、路由表、防火墙、/proc/net目录、/sys/class/net目录、套接字（socket）等。Linux中，物理网络设备默认放置在root namespace中。<br />Docker中为实现网络的独立，又能与宿主机进行通信，为此创建veth pair。将其中的一段放置在容器内通常，通常命名为eth0，另外一段挂载为物理网络设备上所在的namespace中。实际中，docker在docker daemon启动后会创建docker0网桥，docker容器的网络对另一端通常绑定在docker0网桥。<br />现行的docker项目中，自docker>1.9之后，已经将网络单独剥离为 `libnetwork` 库，自此网络模式也被抽象为同样接口。docker现有的网络模式有五种： `bridge驱动` 、 `host驱动` 、 `overlay驱动` 、 `remote驱动` 、 `null驱动` 。<br />接下来，我们手动创建 `veth pair` ，用于模仿docker网桥模式。docker0（lxcbr0）网桥作为二层交换网桥，之所以在上面配置IP，可以认为内部有一个可以用于配置IP信息的网卡接口。Docker在桥接模式下，docker0网桥用于连接容器上的默认网关而存在，并且可以保证在必要时候与宿主机进行网络隔离。\n\n```bash\n## 首先，我们先增加一个网桥lxcbr0，模仿docker0\nbrctl addbr lxcbr0\nbrctl stp lxcbr0 off\nifconfig lxcbr0 192.168.10.1/24 up #为网桥设置IP地址\n \n## 接下来，我们要创建一个network namespace - ns1\n \n# 增加一个namesapce 命令为 ns1 （使用ip netns add命令）\nip netns add ns1 \n \n# 激活namespace中的loopback，即127.0.0.1（使用ip netns exec ns1来操作ns1中的命令）\nip netns exec ns1   ip link set dev lo up \n \n## 然后，我们需要增加一对虚拟网卡\n \n# 增加一个pair虚拟网卡，注意其中的veth类型，其中一个网卡要按进容器中\nip link add veth-ns1 type veth peer name lxcbr0.1\n \n# 把 veth-ns1 按到namespace ns1中，这样容器中就会有一个新的网卡了\nip link set veth-ns1 netns ns1\n \n# 把容器里的 veth-ns1改名为 eth0 （容器外会冲突，容器内就不会了）\nip netns exec ns1  ip link set dev veth-ns1 name eth0 \n \n# 为容器中的网卡分配一个IP地址，并激活它\nip netns exec ns1 ifconfig eth0 192.168.10.11/24 up\n \n \n# 上面我们把veth-ns1这个网卡按到了容器中，然后我们要把lxcbr0.1添加上网桥上\nbrctl addif lxcbr0 lxcbr0.1\n \n# 为容器增加一个路由规则，让容器可以访问外面的网络\nip netns exec ns1     ip route add default via 192.168.10.1\n \n# 在/etc/netns下创建network namespce名称为ns1的目录，\n# 然后为这个namespace设置resolv.conf，这样，容器内就可以访问域名了\nmkdir -p /etc/netns/ns1\necho \"nameserver 8.8.8.8\" > /etc/netns/ns1/resolv.conf\n\n## 引自：https://coolshell.cn/articles/17029.html\n```\n\n详细的Linux的 `ip` 命令，可以参见：[https://wangchujiang.com/linux-command/c/ip.html](https://wangchujiang.com/linux-command/c/ip.html)\n\n","slug":"yuque/Docker基础原理--namespace（pid与network）","published":1,"updated":"2020-05-28T16:59:39.247Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckasagniy000zx3964j84f1sh","content":"<p><a name=\"zz3z6\"></a></p>\n<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>在计算机系统中为了标识不同的作用域，而引入namespace（命名空间）的概念。namespace作用在内核级别的隔离，可以有效阻止不同进程间的通信。在日常的Linux系统中，通常服务在启动后的进程，彼此之间不会特意进行隔离，例如Web服务器中，Nginx、MySQL和rides，三个服务之间亦可访问任意主机中的文件。如果任一服务不慎被攻破，会被入侵其他的服务。因而namespace的引入，可以有效防止不同服务或进程间的相互干扰。<br>Docker使用Linux的namespace技术，对实现的容器，做了多种层次的隔离。Docker所使用的七种namespace如下：<code>CLONE_NEWCGROUP</code>、<code>CLONE_NEWIPC</code>、<code>CLONE_NEWNET</code>、<code>CLONE_NEWNS</code>、<code>CLONE_NEWPID</code>、<code>CLONE_NEWUSER</code> 和 <code>CLONE_NEWUTS</code>。通过在进程中添加如上属性，便能保证与宿主机的对应资源进行有效隔离。</p>\n<p><a name=\"Xv7G5\"></a></p>\n<h2 id=\"进程\"><a href=\"#进程\" class=\"headerlink\" title=\"进程\"></a>进程</h2><p>在分时操作系统中，进程作为程序的基本执行单元，也是资源（CPU、内存）分配的基本单位。当服务、程序启动后，操作系统为其开辟一个进程，并为它分配资源，除等待CPU资源，其他资源以及就绪，此时进入到<strong>就绪态。</strong>当时间片分割的进程，在高优先级调度队列被调度后，进程开始运行。<br>进程的三种状态：就绪态、运行态和阻断状态。<br>Linux的进程，可以通过<code>ps -elf</code>命令进行查看，下图为Centos系统的截图：<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ps -ef</span><br><span class=\"line\">UID        PID  PPID  C STIME TTY          TIME CMD</span><br><span class=\"line\">root         1     0  0 9月24 ?       00:01:32 /usr/lib/systemd/systemd --switched-root --system --deserialize 22</span><br><span class=\"line\">root         2     0  0 9月24 ?       00:00:00 [kthreadd]</span><br><span class=\"line\">root         3     2  0 9月24 ?       00:00:00 [rcu_gp]</span><br><span class=\"line\">root         4     2  0 9月24 ?       00:00:00 [rcu_par_gp]</span><br></pre></td></tr></table></figure></p>\n<p>当前机器中，运行着很多进程，但都以一个 1号进程开始，即pid=1的进程init。此进程作为所以后续进程的父进程。例如pid=39的进程，其父进程（PPID=1）。</p>\n<ul>\n<li>pid=0号进程idle，其前身是系统创建的第一个进程，也是唯一一个没有通过fork或者kernel_thread产生的进程。完成加载系统后，演变为进程调度、交换</li>\n<li>pid=1号进程init，负责执行内核的初始化工作和系统配置。</li>\n<li>pid=2的kthreadd进程，始终运行在内核空间, 负责所有内核线程的调度和管理。<br><a name=\"8tSQB\"></a><h2 id=\"Docker容器内进程PID\"><a href=\"#Docker容器内进程PID\" class=\"headerlink\" title=\"Docker容器内进程PID\"></a>Docker容器内进程PID</h2>以RabbitMQ容器为例，通过如下命令进入rabbitmq容器后，使用ps -ef命令，再次查看容器内的进程，可以与上面的系统进程进行比较。</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@li1559-144 ~]<span class=\"comment\"># docker exec -it 28b6862b34a9 bash</span></span><br><span class=\"line\">root@28b6862b34a9:/<span class=\"comment\"># ps -ef</span></span><br><span class=\"line\">UID        PID  PPID  C STIME TTY          TIME CMD</span><br><span class=\"line\">rabbitmq     1     0  0 16:07 ?        00:00:00 /bin/sh /opt/rabbitmq/sbin/rabbitmq-server</span><br><span class=\"line\">rabbitmq   138     1  0 16:07 ?        00:00:00 /usr/<span class=\"built_in\">local</span>/lib/erlang/erts-10.4.4/bin/epmd -daemon</span><br></pre></td></tr></table></figure>\n<p>当前容器内，PID=1的进程为 rabbitmq-server，与Linux的宿主机的PID=1的init进程不同。此时，容器内的进程以及与宿主机完全隔离。<br>宿主机与rabbitmq容器之间的进程对应关系，如下所示（摘自@Draveness）：<br><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1576771885943-5e1c23b8-82e6-43ee-bb68-1f9ef836e98d.png#align=left&amp;display=inline&amp;height=260&amp;name=image.png&amp;originHeight=520&amp;originWidth=1200&amp;size=83888&amp;status=done&amp;style=none&amp;width=600\" alt=\"image.png\"><br>因此容器内的进程，对宿主机的进程一无所知。实现了内核级的隔离。</p>\n<p>Docker在使用上述隔离技术，进行资源的隔离。当我们每次运行 <code>docker run</code> 或者 <code>docker start</code> 时，都会调用以下代码块（moby:<a href=\"https://github.com/moby\" target=\"_blank\" rel=\"noopener\">https://github.com/moby</a>），创建资源隔离的容器：</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(daemon *Daemon)</span> <span class=\"title\">createSpec</span><span class=\"params\">(c *container.Container)</span> <span class=\"params\">(retSpec *specs.Spec, err error)</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">var</span> (</span><br><span class=\"line\">\t\topts []coci.SpecOpts</span><br><span class=\"line\">\t\ts    = oci.DefaultSpec()</span><br><span class=\"line\">\t)</span><br><span class=\"line\">\topts = <span class=\"built_in\">append</span>(opts,</span><br><span class=\"line\">\t\tWithCommonOptions(daemon, c),</span><br><span class=\"line\">\t\tWithCgroups(daemon, c),\t<span class=\"comment\">//添加Cgroups，进行资源限制</span></span><br><span class=\"line\">\t\tWithResources(c),</span><br><span class=\"line\">\t\tWithSysctls(c),</span><br><span class=\"line\">\t\tWithDevices(daemon, c),</span><br><span class=\"line\">\t\tWithUser(c),</span><br><span class=\"line\">\t\tWithRlimits(daemon, c),</span><br><span class=\"line\">\t\tWithNamespaces(daemon, c),\t<span class=\"comment\">//添加namespace，进行资源隔离</span></span><br><span class=\"line\">\t\tWithCapabilities(c),</span><br><span class=\"line\">\t\tWithSeccomp(daemon, c),</span><br><span class=\"line\">\t\tWithMounts(daemon, c),\t\t<span class=\"comment\">//添加挂载点</span></span><br><span class=\"line\">\t\tWithLibnetwork(daemon, c),</span><br><span class=\"line\">\t\tWithApparmor(c),</span><br><span class=\"line\">\t\tWithSelinux(c),</span><br><span class=\"line\">\t\tWithOOMScore(&amp;c.HostConfig.OomScoreAdj),</span><br><span class=\"line\">\t)</span><br></pre></td></tr></table></figure>\n<p>在 <code>WithNamespaces(daemon, c)</code> 函数中，会设置 <code>user</code> <code>network</code> <code>ipc</code> <code>pid</code>  <code>uts</code> 以及 <code>cgroup</code> ，需要主要的是moby项目中，<code>CLONE_NEWNS</code>即文件系统被单独在 <code>WithMounts(daemon, c)</code> 函数中设置。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">WithNamespaces</span><span class=\"params\">(daemon *Daemon, c *container.Container)</span> <span class=\"title\">coci</span>.<span class=\"title\">SpecOpts</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">(ctx context.Context, _ coci.Client, _ *containers.Container, s *coci.Spec)</span> <span class=\"title\">error</span></span> &#123;</span><br><span class=\"line\">\t\tuserNS := <span class=\"literal\">false</span></span><br><span class=\"line\">\t\t<span class=\"comment\">// user</span></span><br><span class=\"line\">        <span class=\"comment\">// network</span></span><br><span class=\"line\">        <span class=\"comment\">// ipc</span></span><br><span class=\"line\">        <span class=\"comment\">//pid</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> c.HostConfig.PidMode.IsContainer() &#123;</span><br><span class=\"line\">\t\t\tns := specs.LinuxNamespace&#123;Type: <span class=\"string\">\"pid\"</span>&#125;</span><br><span class=\"line\">\t\t\tpc, err := daemon.getPidContainer(c)</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">return</span> err</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t\tns.Path = fmt.Sprintf(<span class=\"string\">\"/proc/%d/ns/pid\"</span>, pc.State.GetPID())</span><br><span class=\"line\">\t\t\tsetNamespace(s, ns)</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> userNS &#123;</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">// to share a PID namespace, they must also share a user namespace</span></span><br><span class=\"line\">\t\t\t\tnsUser := specs.LinuxNamespace&#123;Type: <span class=\"string\">\"user\"</span>&#125;</span><br><span class=\"line\">\t\t\t\tnsUser.Path = fmt.Sprintf(<span class=\"string\">\"/proc/%d/ns/user\"</span>, pc.State.GetPID())</span><br><span class=\"line\">\t\t\t\tsetNamespace(s, nsUser)</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> c.HostConfig.PidMode.IsHost() &#123;</span><br><span class=\"line\">\t\t\toci.RemoveNamespace(s, specs.LinuxNamespaceType(<span class=\"string\">\"pid\"</span>))</span><br><span class=\"line\">\t\t&#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">\t\t\tns := specs.LinuxNamespace&#123;Type: <span class=\"string\">\"pid\"</span>&#125;</span><br><span class=\"line\">\t\t\tsetNamespace(s, ns)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">        <span class=\"comment\">// uts</span></span><br><span class=\"line\">        <span class=\"comment\">//cgroup</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">nil</span></span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><a name=\"doIqz\"></a></p>\n<h2 id=\"Docker容器内网络Network\"><a href=\"#Docker容器内网络Network\" class=\"headerlink\" title=\"Docker容器内网络Network\"></a>Docker容器内网络Network</h2><p>Linux的namespace主要隔离的对象有：网络设备、IPv4和IPv6协议栈、路由表、防火墙、/proc/net目录、/sys/class/net目录、套接字（socket）等。Linux中，物理网络设备默认放置在root namespace中。<br>Docker中为实现网络的独立，又能与宿主机进行通信，为此创建veth pair。将其中的一段放置在容器内通常，通常命名为eth0，另外一段挂载为物理网络设备上所在的namespace中。实际中，docker在docker daemon启动后会创建docker0网桥，docker容器的网络对另一端通常绑定在docker0网桥。<br>现行的docker项目中，自docker&gt;1.9之后，已经将网络单独剥离为 <code>libnetwork</code> 库，自此网络模式也被抽象为同样接口。docker现有的网络模式有五种： <code>bridge驱动</code> 、 <code>host驱动</code> 、 <code>overlay驱动</code> 、 <code>remote驱动</code> 、 <code>null驱动</code> 。<br>接下来，我们手动创建 <code>veth pair</code> ，用于模仿docker网桥模式。docker0（lxcbr0）网桥作为二层交换网桥，之所以在上面配置IP，可以认为内部有一个可以用于配置IP信息的网卡接口。Docker在桥接模式下，docker0网桥用于连接容器上的默认网关而存在，并且可以保证在必要时候与宿主机进行网络隔离。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 首先，我们先增加一个网桥lxcbr0，模仿docker0</span></span><br><span class=\"line\">brctl addbr lxcbr0</span><br><span class=\"line\">brctl stp lxcbr0 off</span><br><span class=\"line\">ifconfig lxcbr0 192.168.10.1/24 up <span class=\"comment\">#为网桥设置IP地址</span></span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\">## 接下来，我们要创建一个network namespace - ns1</span></span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\"># 增加一个namesapce 命令为 ns1 （使用ip netns add命令）</span></span><br><span class=\"line\">ip netns add ns1 </span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\"># 激活namespace中的loopback，即127.0.0.1（使用ip netns exec ns1来操作ns1中的命令）</span></span><br><span class=\"line\">ip netns <span class=\"built_in\">exec</span> ns1   ip link <span class=\"built_in\">set</span> dev lo up </span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\">## 然后，我们需要增加一对虚拟网卡</span></span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\"># 增加一个pair虚拟网卡，注意其中的veth类型，其中一个网卡要按进容器中</span></span><br><span class=\"line\">ip link add veth-ns1 <span class=\"built_in\">type</span> veth peer name lxcbr0.1</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\"># 把 veth-ns1 按到namespace ns1中，这样容器中就会有一个新的网卡了</span></span><br><span class=\"line\">ip link <span class=\"built_in\">set</span> veth-ns1 netns ns1</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\"># 把容器里的 veth-ns1改名为 eth0 （容器外会冲突，容器内就不会了）</span></span><br><span class=\"line\">ip netns <span class=\"built_in\">exec</span> ns1  ip link <span class=\"built_in\">set</span> dev veth-ns1 name eth0 </span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\"># 为容器中的网卡分配一个IP地址，并激活它</span></span><br><span class=\"line\">ip netns <span class=\"built_in\">exec</span> ns1 ifconfig eth0 192.168.10.11/24 up</span><br><span class=\"line\"> </span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\"># 上面我们把veth-ns1这个网卡按到了容器中，然后我们要把lxcbr0.1添加上网桥上</span></span><br><span class=\"line\">brctl addif lxcbr0 lxcbr0.1</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\"># 为容器增加一个路由规则，让容器可以访问外面的网络</span></span><br><span class=\"line\">ip netns <span class=\"built_in\">exec</span> ns1     ip route add default via 192.168.10.1</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\"># 在/etc/netns下创建network namespce名称为ns1的目录，</span></span><br><span class=\"line\"><span class=\"comment\"># 然后为这个namespace设置resolv.conf，这样，容器内就可以访问域名了</span></span><br><span class=\"line\">mkdir -p /etc/netns/ns1</span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">\"nameserver 8.8.8.8\"</span> &gt; /etc/netns/ns1/resolv.conf</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 引自：https://coolshell.cn/articles/17029.html</span></span><br></pre></td></tr></table></figure>\n<p>详细的Linux的 <code>ip</code> 命令，可以参见：<a href=\"https://wangchujiang.com/linux-command/c/ip.html\" target=\"_blank\" rel=\"noopener\">https://wangchujiang.com/linux-command/c/ip.html</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p><a name=\"zz3z6\"></a></p>\n<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>在计算机系统中为了标识不同的作用域，而引入namespace（命名空间）的概念。namespace作用在内核级别的隔离，可以有效阻止不同进程间的通信。在日常的Linux系统中，通常服务在启动后的进程，彼此之间不会特意进行隔离，例如Web服务器中，Nginx、MySQL和rides，三个服务之间亦可访问任意主机中的文件。如果任一服务不慎被攻破，会被入侵其他的服务。因而namespace的引入，可以有效防止不同服务或进程间的相互干扰。<br>Docker使用Linux的namespace技术，对实现的容器，做了多种层次的隔离。Docker所使用的七种namespace如下：<code>CLONE_NEWCGROUP</code>、<code>CLONE_NEWIPC</code>、<code>CLONE_NEWNET</code>、<code>CLONE_NEWNS</code>、<code>CLONE_NEWPID</code>、<code>CLONE_NEWUSER</code> 和 <code>CLONE_NEWUTS</code>。通过在进程中添加如上属性，便能保证与宿主机的对应资源进行有效隔离。</p>\n<p><a name=\"Xv7G5\"></a></p>\n<h2 id=\"进程\"><a href=\"#进程\" class=\"headerlink\" title=\"进程\"></a>进程</h2><p>在分时操作系统中，进程作为程序的基本执行单元，也是资源（CPU、内存）分配的基本单位。当服务、程序启动后，操作系统为其开辟一个进程，并为它分配资源，除等待CPU资源，其他资源以及就绪，此时进入到<strong>就绪态。</strong>当时间片分割的进程，在高优先级调度队列被调度后，进程开始运行。<br>进程的三种状态：就绪态、运行态和阻断状态。<br>Linux的进程，可以通过<code>ps -elf</code>命令进行查看，下图为Centos系统的截图：<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ps -ef</span><br><span class=\"line\">UID        PID  PPID  C STIME TTY          TIME CMD</span><br><span class=\"line\">root         1     0  0 9月24 ?       00:01:32 /usr/lib/systemd/systemd --switched-root --system --deserialize 22</span><br><span class=\"line\">root         2     0  0 9月24 ?       00:00:00 [kthreadd]</span><br><span class=\"line\">root         3     2  0 9月24 ?       00:00:00 [rcu_gp]</span><br><span class=\"line\">root         4     2  0 9月24 ?       00:00:00 [rcu_par_gp]</span><br></pre></td></tr></table></figure></p>\n<p>当前机器中，运行着很多进程，但都以一个 1号进程开始，即pid=1的进程init。此进程作为所以后续进程的父进程。例如pid=39的进程，其父进程（PPID=1）。</p>\n<ul>\n<li>pid=0号进程idle，其前身是系统创建的第一个进程，也是唯一一个没有通过fork或者kernel_thread产生的进程。完成加载系统后，演变为进程调度、交换</li>\n<li>pid=1号进程init，负责执行内核的初始化工作和系统配置。</li>\n<li>pid=2的kthreadd进程，始终运行在内核空间, 负责所有内核线程的调度和管理。<br><a name=\"8tSQB\"></a><h2 id=\"Docker容器内进程PID\"><a href=\"#Docker容器内进程PID\" class=\"headerlink\" title=\"Docker容器内进程PID\"></a>Docker容器内进程PID</h2>以RabbitMQ容器为例，通过如下命令进入rabbitmq容器后，使用ps -ef命令，再次查看容器内的进程，可以与上面的系统进程进行比较。</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@li1559-144 ~]<span class=\"comment\"># docker exec -it 28b6862b34a9 bash</span></span><br><span class=\"line\">root@28b6862b34a9:/<span class=\"comment\"># ps -ef</span></span><br><span class=\"line\">UID        PID  PPID  C STIME TTY          TIME CMD</span><br><span class=\"line\">rabbitmq     1     0  0 16:07 ?        00:00:00 /bin/sh /opt/rabbitmq/sbin/rabbitmq-server</span><br><span class=\"line\">rabbitmq   138     1  0 16:07 ?        00:00:00 /usr/<span class=\"built_in\">local</span>/lib/erlang/erts-10.4.4/bin/epmd -daemon</span><br></pre></td></tr></table></figure>\n<p>当前容器内，PID=1的进程为 rabbitmq-server，与Linux的宿主机的PID=1的init进程不同。此时，容器内的进程以及与宿主机完全隔离。<br>宿主机与rabbitmq容器之间的进程对应关系，如下所示（摘自@Draveness）：<br><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1576771885943-5e1c23b8-82e6-43ee-bb68-1f9ef836e98d.png#align=left&amp;display=inline&amp;height=260&amp;name=image.png&amp;originHeight=520&amp;originWidth=1200&amp;size=83888&amp;status=done&amp;style=none&amp;width=600\" alt=\"image.png\"><br>因此容器内的进程，对宿主机的进程一无所知。实现了内核级的隔离。</p>\n<p>Docker在使用上述隔离技术，进行资源的隔离。当我们每次运行 <code>docker run</code> 或者 <code>docker start</code> 时，都会调用以下代码块（moby:<a href=\"https://github.com/moby\" target=\"_blank\" rel=\"noopener\">https://github.com/moby</a>），创建资源隔离的容器：</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(daemon *Daemon)</span> <span class=\"title\">createSpec</span><span class=\"params\">(c *container.Container)</span> <span class=\"params\">(retSpec *specs.Spec, err error)</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">var</span> (</span><br><span class=\"line\">\t\topts []coci.SpecOpts</span><br><span class=\"line\">\t\ts    = oci.DefaultSpec()</span><br><span class=\"line\">\t)</span><br><span class=\"line\">\topts = <span class=\"built_in\">append</span>(opts,</span><br><span class=\"line\">\t\tWithCommonOptions(daemon, c),</span><br><span class=\"line\">\t\tWithCgroups(daemon, c),\t<span class=\"comment\">//添加Cgroups，进行资源限制</span></span><br><span class=\"line\">\t\tWithResources(c),</span><br><span class=\"line\">\t\tWithSysctls(c),</span><br><span class=\"line\">\t\tWithDevices(daemon, c),</span><br><span class=\"line\">\t\tWithUser(c),</span><br><span class=\"line\">\t\tWithRlimits(daemon, c),</span><br><span class=\"line\">\t\tWithNamespaces(daemon, c),\t<span class=\"comment\">//添加namespace，进行资源隔离</span></span><br><span class=\"line\">\t\tWithCapabilities(c),</span><br><span class=\"line\">\t\tWithSeccomp(daemon, c),</span><br><span class=\"line\">\t\tWithMounts(daemon, c),\t\t<span class=\"comment\">//添加挂载点</span></span><br><span class=\"line\">\t\tWithLibnetwork(daemon, c),</span><br><span class=\"line\">\t\tWithApparmor(c),</span><br><span class=\"line\">\t\tWithSelinux(c),</span><br><span class=\"line\">\t\tWithOOMScore(&amp;c.HostConfig.OomScoreAdj),</span><br><span class=\"line\">\t)</span><br></pre></td></tr></table></figure>\n<p>在 <code>WithNamespaces(daemon, c)</code> 函数中，会设置 <code>user</code> <code>network</code> <code>ipc</code> <code>pid</code>  <code>uts</code> 以及 <code>cgroup</code> ，需要主要的是moby项目中，<code>CLONE_NEWNS</code>即文件系统被单独在 <code>WithMounts(daemon, c)</code> 函数中设置。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">WithNamespaces</span><span class=\"params\">(daemon *Daemon, c *container.Container)</span> <span class=\"title\">coci</span>.<span class=\"title\">SpecOpts</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">(ctx context.Context, _ coci.Client, _ *containers.Container, s *coci.Spec)</span> <span class=\"title\">error</span></span> &#123;</span><br><span class=\"line\">\t\tuserNS := <span class=\"literal\">false</span></span><br><span class=\"line\">\t\t<span class=\"comment\">// user</span></span><br><span class=\"line\">        <span class=\"comment\">// network</span></span><br><span class=\"line\">        <span class=\"comment\">// ipc</span></span><br><span class=\"line\">        <span class=\"comment\">//pid</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> c.HostConfig.PidMode.IsContainer() &#123;</span><br><span class=\"line\">\t\t\tns := specs.LinuxNamespace&#123;Type: <span class=\"string\">\"pid\"</span>&#125;</span><br><span class=\"line\">\t\t\tpc, err := daemon.getPidContainer(c)</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">return</span> err</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t\tns.Path = fmt.Sprintf(<span class=\"string\">\"/proc/%d/ns/pid\"</span>, pc.State.GetPID())</span><br><span class=\"line\">\t\t\tsetNamespace(s, ns)</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> userNS &#123;</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">// to share a PID namespace, they must also share a user namespace</span></span><br><span class=\"line\">\t\t\t\tnsUser := specs.LinuxNamespace&#123;Type: <span class=\"string\">\"user\"</span>&#125;</span><br><span class=\"line\">\t\t\t\tnsUser.Path = fmt.Sprintf(<span class=\"string\">\"/proc/%d/ns/user\"</span>, pc.State.GetPID())</span><br><span class=\"line\">\t\t\t\tsetNamespace(s, nsUser)</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> c.HostConfig.PidMode.IsHost() &#123;</span><br><span class=\"line\">\t\t\toci.RemoveNamespace(s, specs.LinuxNamespaceType(<span class=\"string\">\"pid\"</span>))</span><br><span class=\"line\">\t\t&#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">\t\t\tns := specs.LinuxNamespace&#123;Type: <span class=\"string\">\"pid\"</span>&#125;</span><br><span class=\"line\">\t\t\tsetNamespace(s, ns)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">        <span class=\"comment\">// uts</span></span><br><span class=\"line\">        <span class=\"comment\">//cgroup</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">nil</span></span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><a name=\"doIqz\"></a></p>\n<h2 id=\"Docker容器内网络Network\"><a href=\"#Docker容器内网络Network\" class=\"headerlink\" title=\"Docker容器内网络Network\"></a>Docker容器内网络Network</h2><p>Linux的namespace主要隔离的对象有：网络设备、IPv4和IPv6协议栈、路由表、防火墙、/proc/net目录、/sys/class/net目录、套接字（socket）等。Linux中，物理网络设备默认放置在root namespace中。<br>Docker中为实现网络的独立，又能与宿主机进行通信，为此创建veth pair。将其中的一段放置在容器内通常，通常命名为eth0，另外一段挂载为物理网络设备上所在的namespace中。实际中，docker在docker daemon启动后会创建docker0网桥，docker容器的网络对另一端通常绑定在docker0网桥。<br>现行的docker项目中，自docker&gt;1.9之后，已经将网络单独剥离为 <code>libnetwork</code> 库，自此网络模式也被抽象为同样接口。docker现有的网络模式有五种： <code>bridge驱动</code> 、 <code>host驱动</code> 、 <code>overlay驱动</code> 、 <code>remote驱动</code> 、 <code>null驱动</code> 。<br>接下来，我们手动创建 <code>veth pair</code> ，用于模仿docker网桥模式。docker0（lxcbr0）网桥作为二层交换网桥，之所以在上面配置IP，可以认为内部有一个可以用于配置IP信息的网卡接口。Docker在桥接模式下，docker0网桥用于连接容器上的默认网关而存在，并且可以保证在必要时候与宿主机进行网络隔离。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## 首先，我们先增加一个网桥lxcbr0，模仿docker0</span></span><br><span class=\"line\">brctl addbr lxcbr0</span><br><span class=\"line\">brctl stp lxcbr0 off</span><br><span class=\"line\">ifconfig lxcbr0 192.168.10.1/24 up <span class=\"comment\">#为网桥设置IP地址</span></span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\">## 接下来，我们要创建一个network namespace - ns1</span></span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\"># 增加一个namesapce 命令为 ns1 （使用ip netns add命令）</span></span><br><span class=\"line\">ip netns add ns1 </span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\"># 激活namespace中的loopback，即127.0.0.1（使用ip netns exec ns1来操作ns1中的命令）</span></span><br><span class=\"line\">ip netns <span class=\"built_in\">exec</span> ns1   ip link <span class=\"built_in\">set</span> dev lo up </span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\">## 然后，我们需要增加一对虚拟网卡</span></span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\"># 增加一个pair虚拟网卡，注意其中的veth类型，其中一个网卡要按进容器中</span></span><br><span class=\"line\">ip link add veth-ns1 <span class=\"built_in\">type</span> veth peer name lxcbr0.1</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\"># 把 veth-ns1 按到namespace ns1中，这样容器中就会有一个新的网卡了</span></span><br><span class=\"line\">ip link <span class=\"built_in\">set</span> veth-ns1 netns ns1</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\"># 把容器里的 veth-ns1改名为 eth0 （容器外会冲突，容器内就不会了）</span></span><br><span class=\"line\">ip netns <span class=\"built_in\">exec</span> ns1  ip link <span class=\"built_in\">set</span> dev veth-ns1 name eth0 </span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\"># 为容器中的网卡分配一个IP地址，并激活它</span></span><br><span class=\"line\">ip netns <span class=\"built_in\">exec</span> ns1 ifconfig eth0 192.168.10.11/24 up</span><br><span class=\"line\"> </span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\"># 上面我们把veth-ns1这个网卡按到了容器中，然后我们要把lxcbr0.1添加上网桥上</span></span><br><span class=\"line\">brctl addif lxcbr0 lxcbr0.1</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\"># 为容器增加一个路由规则，让容器可以访问外面的网络</span></span><br><span class=\"line\">ip netns <span class=\"built_in\">exec</span> ns1     ip route add default via 192.168.10.1</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\"># 在/etc/netns下创建network namespce名称为ns1的目录，</span></span><br><span class=\"line\"><span class=\"comment\"># 然后为这个namespace设置resolv.conf，这样，容器内就可以访问域名了</span></span><br><span class=\"line\">mkdir -p /etc/netns/ns1</span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">\"nameserver 8.8.8.8\"</span> &gt; /etc/netns/ns1/resolv.conf</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 引自：https://coolshell.cn/articles/17029.html</span></span><br></pre></td></tr></table></figure>\n<p>详细的Linux的 <code>ip</code> 命令，可以参见：<a href=\"https://wangchujiang.com/linux-command/c/ip.html\" target=\"_blank\" rel=\"noopener\">https://wangchujiang.com/linux-command/c/ip.html</a></p>\n"},{"title":"Go语言的sync模块","date":"2019-09-03T16:11:27.000Z","_content":"在程序进行并发操作时，当不同线程使用同一变量时，由于无法判断是否有其他线程在进行写操作，即线程之间出现竞争（资源竞争），因此引入锁机制。<br />Go语言使用sync模块保证线程在操作变量的互斥性。当变量被一个线程操作时，先使用sync将变量上锁，退出操作时，解锁。<br />sync 模块提供基础的同步原语，例如互斥锁（mutual exclusion locks）。除了**Once**和**WaitGroup**类型，大部分的sync模块的方法使用在低级库。更高级别的同步方式是使用通道（channel）和通信（communication）。<br />本文主要介绍sync包内，一些锁的概念及使用方式。\n<a name=\"ELGHO\"></a>\n## sync包基础\nsync包围绕sync.Locker进行，其中interface为：\n\n```go\ntype Locker interface {\n        Lock()\n        Unlock()\n}\n```\n\n<a name=\"6lkjn\"></a>\n## 基本锁Mutex\nsync.Mutex是互斥锁，相当于在变量入口处确保只有一个线程能够操作变量。<br />假如 num 是一个需要锁处理的存储在共享内存中的变量。通过Mutex处理加锁与解锁。具体例子如下：\n\n```go\nimport \"sync\"\n\ntype num struct {\n\tmutex sync.Mutex\n    nu int\n}\n\n//flash num\nfunc update(num *num) {\n    num.mutex.Lock()\n    //update num\n    num.nu = // new value\n    num.mutex.Unlock()  //任何 goroutine 都可用开锁\n}\n```\n\n<a name=\"weK7l\"></a>\n## 单写多读锁RWMutex\n顾名思义，允许多个线程进行读取，但仅允许单个线程进行写操作。通过 Rlock() 允许同一时间多个线程读操作；如果使用 Lock() ，则RWMutex变成Mutex。<br />RWMutex的方法有：\n```go\n    func (rw *RWMutex) Lock()\n    func (rw *RWMutex) RLock()\n    func (rw *RWMutex) RLocker() Locker\n    func (rw *RWMutex) RUnlock()\n    func (rw *RWMutex) Unlock()\n```\n对应的策略有：\n\n- **允许存在多个读锁，但只能有一把写锁**；<br />\n- **当写锁未被释放时或此时有正被等待的写锁，读锁不可用**；<br />\n- **只有当全部读锁结束，写锁才可用**；<br />\n\n<a name=\"RSEIF\"></a>\n## sync.Once\nsync.Once可以保证被调用的func，只调用一次。<br />Once数据结构为：\n\n```go\ntype Once struct {\n\tm Mutex\n\tdone uint32\n}\n\nfunc (o *Once) Do(f func()) {\n\tif atomic.LoadUint32(&o.done) == 1 {\n\t\treturn\n\t}\n\t// Slow-path.\n\to.m.Lock()\n\tdefer o.m.Unlock()\n\tif o.done == 0 {\n\t\tdefer atomic.StoreUint32(&o.done, 1)\n\t\tf()\n\t}\n}\n```\n\n由once.Do可以看出，当_once.Do(f)_被调用多次时，只有第一次会调用功能函数f。其核心思想是，使用原子计数记录被执行的次数。其中的锁机制，仍旧使用**Mutex.**\n\n官方给出的一个示例，及对应的执行结果如下：\n```go\n//官方例子\npackage main\n\nimport (\n\t\"fmt\"\n\t\"sync\"\n)\n\nfunc main() {\n\tvar once sync.Once\n\tonceBody := func() {\n\t\tfmt.Println(\"Only once\")\n\t}\n\tdone := make(chan bool)\n\tfor i := 0; i < 10; i++ {\n\t\tgo func() {\n\t\t\tonce.Do(onceBody)\n\t\t\tdone <- true\n\t\t}()\n\t}\n\tfor i := 0; i < 10; i++ {\n\t\t<-done\n\t}\n}\n\n// 打印输出为：\nOnly once\n\n```\n\n<a name=\"bJsYV\"></a>\n## sync.WaitGroup\n> A WaitGroup waits for a collection of goroutines to finish. The main goroutine calls Add to set the number of goroutines to wait for. Then each of the goroutines runs and calls Done when finished. At the same time, Wait can be used to block until all goroutines have finished.\n\nWaitGroup可以保证集合内所有goroutines协程完成后，主进程再执行其他动作。避免协程未执行完，主进程就退出或执行其他影响协程的动作。\n\n<a name=\"aWZUt\"></a>\n### WaitGroup操作方式\n执行协程前使用 func (*WaitGroup) Add 添加等待计数器。协程完成一次，执行func (*WaitGroup) Done，在waitgroup计数器中减少一个，直至计数器为零，释放锁。\n\n<a name=\"6AL5C\"></a>\n### 使用举例\n\n```go\npackage main\n\nimport (\n\t\"sync\"\n)\n\ntype httpPkg struct{}\n\nfunc (httpPkg) Get(url string) {}\n\nvar http httpPkg\n\nfunc main() {\n\tvar wg sync.WaitGroup\n\tvar urls = []string{\n\t\t\"http://www.golang.org/\",\n\t\t\"http://www.google.com/\",\n\t\t\"http://www.somestupidname.com/\",\n\t}\n\tfor _, url := range urls {\n\t\t// Increment the WaitGroup counter.\n\t\twg.Add(1)\n\t\t// Launch a goroutine to fetch the URL.\n\t\tgo func(url string) {\n\t\t\t// Decrement the counter when the goroutine completes.\n\t\t\tdefer wg.Done()\n\t\t\t// Fetch the URL.\n\t\t\thttp.Get(url)\n\t\t}(url)\n\t}\n\t// Wait for all HTTP fetches to complete.\n\twg.Wait()\n}\n```\n\n\n\n\n\n","source":"_posts/yuque/Go语言的sync模块.md","raw":"\n---\ntitle: Go语言的sync模块\ndate: 2019-09-04 00:11:27 +0800\ntags: []\ncategories: \n---\n在程序进行并发操作时，当不同线程使用同一变量时，由于无法判断是否有其他线程在进行写操作，即线程之间出现竞争（资源竞争），因此引入锁机制。<br />Go语言使用sync模块保证线程在操作变量的互斥性。当变量被一个线程操作时，先使用sync将变量上锁，退出操作时，解锁。<br />sync 模块提供基础的同步原语，例如互斥锁（mutual exclusion locks）。除了**Once**和**WaitGroup**类型，大部分的sync模块的方法使用在低级库。更高级别的同步方式是使用通道（channel）和通信（communication）。<br />本文主要介绍sync包内，一些锁的概念及使用方式。\n<a name=\"ELGHO\"></a>\n## sync包基础\nsync包围绕sync.Locker进行，其中interface为：\n\n```go\ntype Locker interface {\n        Lock()\n        Unlock()\n}\n```\n\n<a name=\"6lkjn\"></a>\n## 基本锁Mutex\nsync.Mutex是互斥锁，相当于在变量入口处确保只有一个线程能够操作变量。<br />假如 num 是一个需要锁处理的存储在共享内存中的变量。通过Mutex处理加锁与解锁。具体例子如下：\n\n```go\nimport \"sync\"\n\ntype num struct {\n\tmutex sync.Mutex\n    nu int\n}\n\n//flash num\nfunc update(num *num) {\n    num.mutex.Lock()\n    //update num\n    num.nu = // new value\n    num.mutex.Unlock()  //任何 goroutine 都可用开锁\n}\n```\n\n<a name=\"weK7l\"></a>\n## 单写多读锁RWMutex\n顾名思义，允许多个线程进行读取，但仅允许单个线程进行写操作。通过 Rlock() 允许同一时间多个线程读操作；如果使用 Lock() ，则RWMutex变成Mutex。<br />RWMutex的方法有：\n```go\n    func (rw *RWMutex) Lock()\n    func (rw *RWMutex) RLock()\n    func (rw *RWMutex) RLocker() Locker\n    func (rw *RWMutex) RUnlock()\n    func (rw *RWMutex) Unlock()\n```\n对应的策略有：\n\n- **允许存在多个读锁，但只能有一把写锁**；<br />\n- **当写锁未被释放时或此时有正被等待的写锁，读锁不可用**；<br />\n- **只有当全部读锁结束，写锁才可用**；<br />\n\n<a name=\"RSEIF\"></a>\n## sync.Once\nsync.Once可以保证被调用的func，只调用一次。<br />Once数据结构为：\n\n```go\ntype Once struct {\n\tm Mutex\n\tdone uint32\n}\n\nfunc (o *Once) Do(f func()) {\n\tif atomic.LoadUint32(&o.done) == 1 {\n\t\treturn\n\t}\n\t// Slow-path.\n\to.m.Lock()\n\tdefer o.m.Unlock()\n\tif o.done == 0 {\n\t\tdefer atomic.StoreUint32(&o.done, 1)\n\t\tf()\n\t}\n}\n```\n\n由once.Do可以看出，当_once.Do(f)_被调用多次时，只有第一次会调用功能函数f。其核心思想是，使用原子计数记录被执行的次数。其中的锁机制，仍旧使用**Mutex.**\n\n官方给出的一个示例，及对应的执行结果如下：\n```go\n//官方例子\npackage main\n\nimport (\n\t\"fmt\"\n\t\"sync\"\n)\n\nfunc main() {\n\tvar once sync.Once\n\tonceBody := func() {\n\t\tfmt.Println(\"Only once\")\n\t}\n\tdone := make(chan bool)\n\tfor i := 0; i < 10; i++ {\n\t\tgo func() {\n\t\t\tonce.Do(onceBody)\n\t\t\tdone <- true\n\t\t}()\n\t}\n\tfor i := 0; i < 10; i++ {\n\t\t<-done\n\t}\n}\n\n// 打印输出为：\nOnly once\n\n```\n\n<a name=\"bJsYV\"></a>\n## sync.WaitGroup\n> A WaitGroup waits for a collection of goroutines to finish. The main goroutine calls Add to set the number of goroutines to wait for. Then each of the goroutines runs and calls Done when finished. At the same time, Wait can be used to block until all goroutines have finished.\n\nWaitGroup可以保证集合内所有goroutines协程完成后，主进程再执行其他动作。避免协程未执行完，主进程就退出或执行其他影响协程的动作。\n\n<a name=\"aWZUt\"></a>\n### WaitGroup操作方式\n执行协程前使用 func (*WaitGroup) Add 添加等待计数器。协程完成一次，执行func (*WaitGroup) Done，在waitgroup计数器中减少一个，直至计数器为零，释放锁。\n\n<a name=\"6AL5C\"></a>\n### 使用举例\n\n```go\npackage main\n\nimport (\n\t\"sync\"\n)\n\ntype httpPkg struct{}\n\nfunc (httpPkg) Get(url string) {}\n\nvar http httpPkg\n\nfunc main() {\n\tvar wg sync.WaitGroup\n\tvar urls = []string{\n\t\t\"http://www.golang.org/\",\n\t\t\"http://www.google.com/\",\n\t\t\"http://www.somestupidname.com/\",\n\t}\n\tfor _, url := range urls {\n\t\t// Increment the WaitGroup counter.\n\t\twg.Add(1)\n\t\t// Launch a goroutine to fetch the URL.\n\t\tgo func(url string) {\n\t\t\t// Decrement the counter when the goroutine completes.\n\t\t\tdefer wg.Done()\n\t\t\t// Fetch the URL.\n\t\t\thttp.Get(url)\n\t\t}(url)\n\t}\n\t// Wait for all HTTP fetches to complete.\n\twg.Wait()\n}\n```\n\n\n\n\n\n","slug":"yuque/Go语言的sync模块","published":1,"updated":"2020-05-28T16:59:39.249Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckasagnj00011x3969vcz5uto","content":"<p>在程序进行并发操作时，当不同线程使用同一变量时，由于无法判断是否有其他线程在进行写操作，即线程之间出现竞争（资源竞争），因此引入锁机制。<br>Go语言使用sync模块保证线程在操作变量的互斥性。当变量被一个线程操作时，先使用sync将变量上锁，退出操作时，解锁。<br>sync 模块提供基础的同步原语，例如互斥锁（mutual exclusion locks）。除了<strong>Once</strong>和<strong>WaitGroup</strong>类型，大部分的sync模块的方法使用在低级库。更高级别的同步方式是使用通道（channel）和通信（communication）。<br>本文主要介绍sync包内，一些锁的概念及使用方式。<br><a name=\"ELGHO\"></a></p>\n<h2 id=\"sync包基础\"><a href=\"#sync包基础\" class=\"headerlink\" title=\"sync包基础\"></a>sync包基础</h2><p>sync包围绕sync.Locker进行，其中interface为：</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">type</span> Locker <span class=\"keyword\">interface</span> &#123;</span><br><span class=\"line\">        Lock()</span><br><span class=\"line\">        Unlock()</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><a name=\"6lkjn\"></a></p>\n<h2 id=\"基本锁Mutex\"><a href=\"#基本锁Mutex\" class=\"headerlink\" title=\"基本锁Mutex\"></a>基本锁Mutex</h2><p>sync.Mutex是互斥锁，相当于在变量入口处确保只有一个线程能够操作变量。<br>假如 num 是一个需要锁处理的存储在共享内存中的变量。通过Mutex处理加锁与解锁。具体例子如下：</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> <span class=\"string\">\"sync\"</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">type</span> num <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">\tmutex sync.Mutex</span><br><span class=\"line\">    nu <span class=\"keyword\">int</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//flash num</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">update</span><span class=\"params\">(num *num)</span></span> &#123;</span><br><span class=\"line\">    num.mutex.Lock()</span><br><span class=\"line\">    <span class=\"comment\">//update num</span></span><br><span class=\"line\">    num.nu = <span class=\"comment\">// new value</span></span><br><span class=\"line\">    num.mutex.Unlock()  <span class=\"comment\">//任何 goroutine 都可用开锁</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><a name=\"weK7l\"></a></p>\n<h2 id=\"单写多读锁RWMutex\"><a href=\"#单写多读锁RWMutex\" class=\"headerlink\" title=\"单写多读锁RWMutex\"></a>单写多读锁RWMutex</h2><p>顾名思义，允许多个线程进行读取，但仅允许单个线程进行写操作。通过 Rlock() 允许同一时间多个线程读操作；如果使用 Lock() ，则RWMutex变成Mutex。<br>RWMutex的方法有：<br><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(rw *RWMutex)</span> <span class=\"title\">Lock</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">func</span> <span class=\"params\">(rw *RWMutex)</span> <span class=\"title\">RLock</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">func</span> <span class=\"params\">(rw *RWMutex)</span> <span class=\"title\">RLocker</span><span class=\"params\">()</span> <span class=\"title\">Locker</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">func</span> <span class=\"params\">(rw *RWMutex)</span> <span class=\"title\">RUnlock</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">func</span> <span class=\"params\">(rw *RWMutex)</span> <span class=\"title\">Unlock</span><span class=\"params\">()</span></span></span><br></pre></td></tr></table></figure></p>\n<p>对应的策略有：</p>\n<ul>\n<li><strong>允许存在多个读锁，但只能有一把写锁</strong>；<br></li>\n<li><strong>当写锁未被释放时或此时有正被等待的写锁，读锁不可用</strong>；<br></li>\n<li><strong>只有当全部读锁结束，写锁才可用</strong>；<br></li>\n</ul>\n<p><a name=\"RSEIF\"></a></p>\n<h2 id=\"sync-Once\"><a href=\"#sync-Once\" class=\"headerlink\" title=\"sync.Once\"></a>sync.Once</h2><p>sync.Once可以保证被调用的func，只调用一次。<br>Once数据结构为：</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">type</span> Once <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">\tm Mutex</span><br><span class=\"line\">\tdone <span class=\"keyword\">uint32</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(o *Once)</span> <span class=\"title\">Do</span><span class=\"params\">(f <span class=\"keyword\">func</span>()</span>)</span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> atomic.LoadUint32(&amp;o.done) == <span class=\"number\">1</span> &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span></span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"comment\">// Slow-path.</span></span><br><span class=\"line\">\to.m.Lock()</span><br><span class=\"line\">\t<span class=\"keyword\">defer</span> o.m.Unlock()</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> o.done == <span class=\"number\">0</span> &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">defer</span> atomic.StoreUint32(&amp;o.done, <span class=\"number\">1</span>)</span><br><span class=\"line\">\t\tf()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>由once.Do可以看出，当<em>once.Do(f)</em>被调用多次时，只有第一次会调用功能函数f。其核心思想是，使用原子计数记录被执行的次数。其中的锁机制，仍旧使用<strong>Mutex.</strong></p>\n<p>官方给出的一个示例，及对应的执行结果如下：<br><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//官方例子</span></span><br><span class=\"line\"><span class=\"keyword\">package</span> main</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> (</span><br><span class=\"line\">\t<span class=\"string\">\"fmt\"</span></span><br><span class=\"line\">\t<span class=\"string\">\"sync\"</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">var</span> once sync.Once</span><br><span class=\"line\">\tonceBody := <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t\tfmt.Println(<span class=\"string\">\"Only once\"</span>)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tdone := <span class=\"built_in\">make</span>(<span class=\"keyword\">chan</span> <span class=\"keyword\">bool</span>)</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i := <span class=\"number\">0</span>; i &lt; <span class=\"number\">10</span>; i++ &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">go</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t\t\tonce.Do(onceBody)</span><br><span class=\"line\">\t\t\tdone &lt;- <span class=\"literal\">true</span></span><br><span class=\"line\">\t\t&#125;()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i := <span class=\"number\">0</span>; i &lt; <span class=\"number\">10</span>; i++ &#123;</span><br><span class=\"line\">\t\t&lt;-done</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 打印输出为：</span></span><br><span class=\"line\">Only once</span><br></pre></td></tr></table></figure></p>\n<p><a name=\"bJsYV\"></a></p>\n<h2 id=\"sync-WaitGroup\"><a href=\"#sync-WaitGroup\" class=\"headerlink\" title=\"sync.WaitGroup\"></a>sync.WaitGroup</h2><blockquote>\n<p>A WaitGroup waits for a collection of goroutines to finish. The main goroutine calls Add to set the number of goroutines to wait for. Then each of the goroutines runs and calls Done when finished. At the same time, Wait can be used to block until all goroutines have finished.</p>\n</blockquote>\n<p>WaitGroup可以保证集合内所有goroutines协程完成后，主进程再执行其他动作。避免协程未执行完，主进程就退出或执行其他影响协程的动作。</p>\n<p><a name=\"aWZUt\"></a></p>\n<h3 id=\"WaitGroup操作方式\"><a href=\"#WaitGroup操作方式\" class=\"headerlink\" title=\"WaitGroup操作方式\"></a>WaitGroup操作方式</h3><p>执行协程前使用 func (<em>WaitGroup) Add 添加等待计数器。协程完成一次，执行func (</em>WaitGroup) Done，在waitgroup计数器中减少一个，直至计数器为零，释放锁。</p>\n<p><a name=\"6AL5C\"></a></p>\n<h3 id=\"使用举例\"><a href=\"#使用举例\" class=\"headerlink\" title=\"使用举例\"></a>使用举例</h3><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> main</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> (</span><br><span class=\"line\">\t<span class=\"string\">\"sync\"</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">type</span> httpPkg <span class=\"keyword\">struct</span>&#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(httpPkg)</span> <span class=\"title\">Get</span><span class=\"params\">(url <span class=\"keyword\">string</span>)</span></span> &#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> http httpPkg</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">var</span> wg sync.WaitGroup</span><br><span class=\"line\">\t<span class=\"keyword\">var</span> urls = []<span class=\"keyword\">string</span>&#123;</span><br><span class=\"line\">\t\t<span class=\"string\">\"http://www.golang.org/\"</span>,</span><br><span class=\"line\">\t\t<span class=\"string\">\"http://www.google.com/\"</span>,</span><br><span class=\"line\">\t\t<span class=\"string\">\"http://www.somestupidname.com/\"</span>,</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> _, url := <span class=\"keyword\">range</span> urls &#123;</span><br><span class=\"line\">\t\t<span class=\"comment\">// Increment the WaitGroup counter.</span></span><br><span class=\"line\">\t\twg.Add(<span class=\"number\">1</span>)</span><br><span class=\"line\">\t\t<span class=\"comment\">// Launch a goroutine to fetch the URL.</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">go</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">(url <span class=\"keyword\">string</span>)</span></span> &#123;</span><br><span class=\"line\">\t\t\t<span class=\"comment\">// Decrement the counter when the goroutine completes.</span></span><br><span class=\"line\">\t\t\t<span class=\"keyword\">defer</span> wg.Done()</span><br><span class=\"line\">\t\t\t<span class=\"comment\">// Fetch the URL.</span></span><br><span class=\"line\">\t\t\thttp.Get(url)</span><br><span class=\"line\">\t\t&#125;(url)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"comment\">// Wait for all HTTP fetches to complete.</span></span><br><span class=\"line\">\twg.Wait()</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<p>在程序进行并发操作时，当不同线程使用同一变量时，由于无法判断是否有其他线程在进行写操作，即线程之间出现竞争（资源竞争），因此引入锁机制。<br>Go语言使用sync模块保证线程在操作变量的互斥性。当变量被一个线程操作时，先使用sync将变量上锁，退出操作时，解锁。<br>sync 模块提供基础的同步原语，例如互斥锁（mutual exclusion locks）。除了<strong>Once</strong>和<strong>WaitGroup</strong>类型，大部分的sync模块的方法使用在低级库。更高级别的同步方式是使用通道（channel）和通信（communication）。<br>本文主要介绍sync包内，一些锁的概念及使用方式。<br><a name=\"ELGHO\"></a></p>\n<h2 id=\"sync包基础\"><a href=\"#sync包基础\" class=\"headerlink\" title=\"sync包基础\"></a>sync包基础</h2><p>sync包围绕sync.Locker进行，其中interface为：</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">type</span> Locker <span class=\"keyword\">interface</span> &#123;</span><br><span class=\"line\">        Lock()</span><br><span class=\"line\">        Unlock()</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><a name=\"6lkjn\"></a></p>\n<h2 id=\"基本锁Mutex\"><a href=\"#基本锁Mutex\" class=\"headerlink\" title=\"基本锁Mutex\"></a>基本锁Mutex</h2><p>sync.Mutex是互斥锁，相当于在变量入口处确保只有一个线程能够操作变量。<br>假如 num 是一个需要锁处理的存储在共享内存中的变量。通过Mutex处理加锁与解锁。具体例子如下：</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> <span class=\"string\">\"sync\"</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">type</span> num <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">\tmutex sync.Mutex</span><br><span class=\"line\">    nu <span class=\"keyword\">int</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//flash num</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">update</span><span class=\"params\">(num *num)</span></span> &#123;</span><br><span class=\"line\">    num.mutex.Lock()</span><br><span class=\"line\">    <span class=\"comment\">//update num</span></span><br><span class=\"line\">    num.nu = <span class=\"comment\">// new value</span></span><br><span class=\"line\">    num.mutex.Unlock()  <span class=\"comment\">//任何 goroutine 都可用开锁</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><a name=\"weK7l\"></a></p>\n<h2 id=\"单写多读锁RWMutex\"><a href=\"#单写多读锁RWMutex\" class=\"headerlink\" title=\"单写多读锁RWMutex\"></a>单写多读锁RWMutex</h2><p>顾名思义，允许多个线程进行读取，但仅允许单个线程进行写操作。通过 Rlock() 允许同一时间多个线程读操作；如果使用 Lock() ，则RWMutex变成Mutex。<br>RWMutex的方法有：<br><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(rw *RWMutex)</span> <span class=\"title\">Lock</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">func</span> <span class=\"params\">(rw *RWMutex)</span> <span class=\"title\">RLock</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">func</span> <span class=\"params\">(rw *RWMutex)</span> <span class=\"title\">RLocker</span><span class=\"params\">()</span> <span class=\"title\">Locker</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">func</span> <span class=\"params\">(rw *RWMutex)</span> <span class=\"title\">RUnlock</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">func</span> <span class=\"params\">(rw *RWMutex)</span> <span class=\"title\">Unlock</span><span class=\"params\">()</span></span></span><br></pre></td></tr></table></figure></p>\n<p>对应的策略有：</p>\n<ul>\n<li><strong>允许存在多个读锁，但只能有一把写锁</strong>；<br></li>\n<li><strong>当写锁未被释放时或此时有正被等待的写锁，读锁不可用</strong>；<br></li>\n<li><strong>只有当全部读锁结束，写锁才可用</strong>；<br></li>\n</ul>\n<p><a name=\"RSEIF\"></a></p>\n<h2 id=\"sync-Once\"><a href=\"#sync-Once\" class=\"headerlink\" title=\"sync.Once\"></a>sync.Once</h2><p>sync.Once可以保证被调用的func，只调用一次。<br>Once数据结构为：</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">type</span> Once <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">\tm Mutex</span><br><span class=\"line\">\tdone <span class=\"keyword\">uint32</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(o *Once)</span> <span class=\"title\">Do</span><span class=\"params\">(f <span class=\"keyword\">func</span>()</span>)</span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> atomic.LoadUint32(&amp;o.done) == <span class=\"number\">1</span> &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span></span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"comment\">// Slow-path.</span></span><br><span class=\"line\">\to.m.Lock()</span><br><span class=\"line\">\t<span class=\"keyword\">defer</span> o.m.Unlock()</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> o.done == <span class=\"number\">0</span> &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">defer</span> atomic.StoreUint32(&amp;o.done, <span class=\"number\">1</span>)</span><br><span class=\"line\">\t\tf()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>由once.Do可以看出，当<em>once.Do(f)</em>被调用多次时，只有第一次会调用功能函数f。其核心思想是，使用原子计数记录被执行的次数。其中的锁机制，仍旧使用<strong>Mutex.</strong></p>\n<p>官方给出的一个示例，及对应的执行结果如下：<br><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//官方例子</span></span><br><span class=\"line\"><span class=\"keyword\">package</span> main</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> (</span><br><span class=\"line\">\t<span class=\"string\">\"fmt\"</span></span><br><span class=\"line\">\t<span class=\"string\">\"sync\"</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">var</span> once sync.Once</span><br><span class=\"line\">\tonceBody := <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t\tfmt.Println(<span class=\"string\">\"Only once\"</span>)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tdone := <span class=\"built_in\">make</span>(<span class=\"keyword\">chan</span> <span class=\"keyword\">bool</span>)</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i := <span class=\"number\">0</span>; i &lt; <span class=\"number\">10</span>; i++ &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">go</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t\t\tonce.Do(onceBody)</span><br><span class=\"line\">\t\t\tdone &lt;- <span class=\"literal\">true</span></span><br><span class=\"line\">\t\t&#125;()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i := <span class=\"number\">0</span>; i &lt; <span class=\"number\">10</span>; i++ &#123;</span><br><span class=\"line\">\t\t&lt;-done</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 打印输出为：</span></span><br><span class=\"line\">Only once</span><br></pre></td></tr></table></figure></p>\n<p><a name=\"bJsYV\"></a></p>\n<h2 id=\"sync-WaitGroup\"><a href=\"#sync-WaitGroup\" class=\"headerlink\" title=\"sync.WaitGroup\"></a>sync.WaitGroup</h2><blockquote>\n<p>A WaitGroup waits for a collection of goroutines to finish. The main goroutine calls Add to set the number of goroutines to wait for. Then each of the goroutines runs and calls Done when finished. At the same time, Wait can be used to block until all goroutines have finished.</p>\n</blockquote>\n<p>WaitGroup可以保证集合内所有goroutines协程完成后，主进程再执行其他动作。避免协程未执行完，主进程就退出或执行其他影响协程的动作。</p>\n<p><a name=\"aWZUt\"></a></p>\n<h3 id=\"WaitGroup操作方式\"><a href=\"#WaitGroup操作方式\" class=\"headerlink\" title=\"WaitGroup操作方式\"></a>WaitGroup操作方式</h3><p>执行协程前使用 func (<em>WaitGroup) Add 添加等待计数器。协程完成一次，执行func (</em>WaitGroup) Done，在waitgroup计数器中减少一个，直至计数器为零，释放锁。</p>\n<p><a name=\"6AL5C\"></a></p>\n<h3 id=\"使用举例\"><a href=\"#使用举例\" class=\"headerlink\" title=\"使用举例\"></a>使用举例</h3><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> main</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> (</span><br><span class=\"line\">\t<span class=\"string\">\"sync\"</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">type</span> httpPkg <span class=\"keyword\">struct</span>&#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(httpPkg)</span> <span class=\"title\">Get</span><span class=\"params\">(url <span class=\"keyword\">string</span>)</span></span> &#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> http httpPkg</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">var</span> wg sync.WaitGroup</span><br><span class=\"line\">\t<span class=\"keyword\">var</span> urls = []<span class=\"keyword\">string</span>&#123;</span><br><span class=\"line\">\t\t<span class=\"string\">\"http://www.golang.org/\"</span>,</span><br><span class=\"line\">\t\t<span class=\"string\">\"http://www.google.com/\"</span>,</span><br><span class=\"line\">\t\t<span class=\"string\">\"http://www.somestupidname.com/\"</span>,</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> _, url := <span class=\"keyword\">range</span> urls &#123;</span><br><span class=\"line\">\t\t<span class=\"comment\">// Increment the WaitGroup counter.</span></span><br><span class=\"line\">\t\twg.Add(<span class=\"number\">1</span>)</span><br><span class=\"line\">\t\t<span class=\"comment\">// Launch a goroutine to fetch the URL.</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">go</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">(url <span class=\"keyword\">string</span>)</span></span> &#123;</span><br><span class=\"line\">\t\t\t<span class=\"comment\">// Decrement the counter when the goroutine completes.</span></span><br><span class=\"line\">\t\t\t<span class=\"keyword\">defer</span> wg.Done()</span><br><span class=\"line\">\t\t\t<span class=\"comment\">// Fetch the URL.</span></span><br><span class=\"line\">\t\t\thttp.Get(url)</span><br><span class=\"line\">\t\t&#125;(url)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"comment\">// Wait for all HTTP fetches to complete.</span></span><br><span class=\"line\">\twg.Wait()</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n"},{"title":"Kafka - - 快速入门指南","date":"2019-02-01T10:41:49.000Z","_content":"<a name=\"e05dce83\"></a>\n## 简介\n\nKafka起源于2011年LikedIn的开源项目，并不断发展。如今它是一个完整的平台，允许您冗余地存储巨大的数据量，拥有一个具有巨大吞吐量（数百万/秒）的消息总线，同时可实现实时流处理。\n\nKafka具备的特性有：**分布式、水平扩展、高容错和日志管理**。接下来将逐个介绍特性。\n\n<a name=\"00ea564d\"></a>\n### 分布式\n\n分布式系统的显著特点是将任务分配到多个机器处理，即组成的集群对外暴露的形式仍为单一节点。Kafka的分布特性在于在不同节点（代理）存储、接收和发送消息。\n\n> 分布式系统的介绍可以参阅：[A Thorough Introduction to Distributed Systems](https://medium.freecodecamp.org/a-thorough-introduction-to-distributed-systems-3b91562c9b3c)\n\n\n分布式系统的优势主要体现在：高可扩展性、容错性。\n\n<a name=\"32a24e98\"></a>\n### 水平扩展\n\n首先解释、定义垂直扩展。例如，数据库服务器过载，最直接的解决办法是添加资源（CPU、RAM和SSD）。垂直扩展的两大缺点是：\n\n- 现有的硬件限制了扩展能力。例如不能无线提高CPU核数。\n- 通常需要停机时间。\n\n**水平扩展**通过投入更多的机器来解决上述问题。添加新机器不需要停机，也没有机器数量的限制。它的缺点是，并非所有系统支持水平弹性伸缩，因为在设计之初没有考虑工作在集群环境下，同时设计也更为复杂。<br />![](https://cdn.nlark.com/yuque/0/2019/jpeg/250680/1550673729515-587ccc54-647c-4f27-a36f-08848fd77da0.jpeg#align=left&display=inline&height=389&originHeight=389&originWidth=400&size=0&status=done&width=400)\n<a name=\"327fa254\"></a>\n### 高容错性\n非分布式系统的一大安全隐患是单点故障（single point of failure, SPOF）。例如单实例数据库宕机，会产生无法估量的损失。<br />分布式系统被设计为可配置的方式，来处理故障。例如，在5节点的Kafka集群中，即使其中两个节点关闭，系统仍然继续工作。需要注意的地方是，系统容错率与系统性能成反比，即容错率越高，性能越低。\n<a name=\"62b5133f\"></a>\n### 日志采集\n日志采集（事务日志）仅支持附加的持久有序数据结构，即无法修改或删除已有的记录。读取顺序从左向右如图所示。<br />![](https://cdn.nlark.com/yuque/0/2019/jpeg/250680/1550675101681-613e5d8c-b7f7-4800-8c6e-f0c7a41dae65.jpeg#align=left&display=inline&height=187&originHeight=187&originWidth=396&size=0&status=done&width=396)<br />在某种程度来讲，Kafka的数据结构就是如此简单。这也是Kafka的核心，因为它提供了有序数据，而有序的数据结构提供了确定性的处理方式。<br />Kafka实际上将所有消息存储在磁盘上，并且对他们进行排序，最大化利用硬盘顺序读取速度快的优势。\n\n- 读取和写入是整数级别O(1)（知道记录ID），与磁盘上的其他数据结构的操作复杂度为O(log N)相比，有巨大优势。\n- 读取和写入是分离的。写入时不会锁定读取，反之亦然（与平衡树相反）。\n\n这两点使得Kafka的性能有巨大优势，因为系统性能与数据量是分离的。Kafka无论处理100KB的数据量还是100TB的数据量，性能都是一样的。\n<a name=\"b3fbd195\"></a>\n## 工作原理\n向Kafka节点（broker）发送消息（记录）的称为程序（生产者），发送给其他程序处理消息的称为消费者。产生的消息存储在一个**topic**内，消费者订阅向topic订阅后，可以接收到对应topic的新消息。<br />![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1550761835264-486e6737-07e1-4bbb-aae7-4e09b7888f77.png#align=left&display=inline&height=178&name=image.png&originHeight=180&originWidth=258&size=8295&status=done&width=255)<br />随着topic变得越来越大，为保持性能和可伸缩性将topic拆分成更小的分区。（例如，需要存储用户的登录名，可以将用户名按照首字母进行拆分存储在不同的分区）<br />Kafka保证分区内的所有消息都按照它们进入的顺序排序。区分特定消息的方式是通过其**偏移量** ，可将其视为普通数组索引，在一个分区的序列号随着新消息进入而递增。<br />![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1550762596583-9e4702c2-cd98-410f-8587-2f2a17cbfaea.png#align=left&display=inline&height=182&name=image.png&originHeight=267&originWidth=416&size=19550&status=done&width=283)<br />Kafka遵循愚蠢的broker和聪明的消费者原则。意思是，Kafka不会跟踪哪一条记录已经被消费者读取并删除，而是将他们按照一定的时间（例如一天）或约定某个阈值大小来存储。消费者自身从Kafka的broker**主动拉取**新信息，并告知他们想要读取的片段。这意味着broker允许消费者按照自身的需要进行增加或减小偏移量，因此具有重新读取和重新处理信息的能力。<br />需要注意的是，消费者其实是消费者群组，包含一个或多个消费进程。为避免两个进程重复读取相同的信息，每个分区仅与每个组的一个消费者进程相关联。<br />![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1550763797220-d9a12e85-f1df-477c-adf7-ce92ddbeb9ac.png#align=left&display=inline&height=331&name=image.png&originHeight=661&originWidth=2000&size=238955&status=done&width=1000)\n<a name=\"efbcc1fb\"></a>\n## 数据持久化\nKafka将所有记录存储在磁盘，并且不会在RAM中保存任何记录。你可能会惊讶于以怎样高效的方式来做明智的选择。这背后有很多值得学习的优化知识：\n\n1. Kafka有将成组的消息合并的协议。允许网络请求将消息组合在一起减少网络开销，因此服务器一次性保留大量消息，消费者一次获取巨大的线性消息块。\n1. 磁盘顺序I/O读取速度很快。现代磁盘速度慢的原因是由于大量的磁盘寻道，但是在大型线性读写操作时不是问题。\n1. 线性操作由OS进一步优化，通过**预读取**（预读取多倍数据块）和**后写入**（将小的逻辑写入操作合并为组后再进行物理写入操作）技术。\n1. 现代OS利用RAM模拟磁盘缓存，这种技术成为pagecache。\n1. 由于kafka在整个流程（生产者--->代理--->消费者）中以未经修改的标准化二进制格式存储消息，因此它可以使用**零拷贝**（zero-copy）优化。操作系统将数据从pagecache直接复制到套接字，有效地完全绕过了Kafka代理应用程序。\n\n所有这些优化都使Kafka能够从接近网络的速度传输消息。\n<a name=\"8b75be39\"></a>\n## 数据分发和复制\n在这个章节，我们讨论Kafka如何实现容错以及它如何在节点之间分配数据。\n<a name=\"82a6c7de\"></a>\n### 数据复制\n分区数据在多个代理（broker）中复制，以便在其中一个代理挂掉时候，依然能够保存数据。<br />在任何时候，一个代理（broker）“拥有”其中一个分区，节点通过这个分区进行读写操作。因此，此分区被称为**分区领导者**（partition leader）。将接收到的数据复制给其他_**N**_个其他代理，称为**跟随者**（followers）。跟随者同样存储数据，并且随时准备着当leader挂掉时，取而代之。<br />这样的配置有助于保证任何成功发布的消息都不会丢失。通过更改复制因子，可以根据数据的重要性来交换性能以获得更强的持久性保证。<br />![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1551192978691-57bdf14e-90a0-47df-8aeb-60224ba6254c.png#align=left&display=inline&height=765&name=image.png&originHeight=1531&originWidth=2600&size=422840&status=done&width=1300)<br />在其中一个leader挂掉时，其他follower会竞选上岗，具体算法可以参考：<br />[_How does a producer/consumer know who the leader of a partition is?_](https://community.hortonworks.com/questions/149532/how-producer-and-consumer-identify-the-leader-in-k.html)<br />作为生产者/消费者，对一个分区进行读取时，首先需要知道对应分区的leader。这个信息需要存储在可以被访问到的地方，Kafka使用Zookeeper进行存储这些元数据。\n<a name=\"f52343ab\"></a>\n### 何为Zookeeper\nZookeeper是一个分布式键值存储结构。它针对读取进行了高度优化，但写入速度较慢。常应用于存储元数据和处理集群的核心机制（心跳包、分发更新配置等）。<br />它允许服务（Kafka的broker）的客户订阅通知，并且能在Zookeeper发生变动的时候发送给客户消息。这也是为什么brokers能够感知分区的leader发生变动。Zookeeper同时也具有成熟的容错性，或者说，Kafka很大程度上依赖Zookeeper的高容错性。<br />Zookeeper用于存储所有类型的元数据，包括但不限于：\n\n- 消费者群组中每个分区的偏移量（尽管现在的客户端在单独的Kafka主题Topic内存储偏移量）\n- ACL（访问控制列表），用于限制访问/授权\n- 生产者和消费者配额，包括每秒最大信息量\n- 存储分区leader和健康状态\n<a name=\"c577e2f9\"></a>\n### 如何区分分区的领导者\n在以往版本中，生产者和消费者经常直接连接并与Zookeeper交谈以获取此（和其他）信息。 目前Kafka已经弃用这种耦合，从0.8和0.9版本开始，客户端直接从Kafka的brokers那里获取元数据信息，他们自己与Zookeeper交谈。\n\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1551274509585-90480e7a-f43d-4959-9703-a908c3983f5f.png#align=left&display=inline&height=1076&name=image.png&originHeight=2152&originWidth=2000&size=462646&status=done&width=1000)\n<a name=\"3f4a00cf\"></a>\n## 流\n在Kafka中，流处理器是从输入的Topic中连续读取数据流，并对数据进行一些处理生成数据流以生成主题的任何（或外部服务、数据库、垃圾箱等）内容。<br />对于一些简单的消息，可能使用消费者或生产者的API接口直接处理即可，但是涉及到复杂的消息流（例如，多条数据流联合）处理的情况，Kafka提供一个集成的[Stream API](https://kafka.apache.org/documentation/streams/)库。<br />此API应用于自己的代码块中，而不是直接在代理（broker）上运行。它与消费者API类似，可以帮助你在多个应用（类似多个消费者）上扩展流处理工作。\n<a name=\"d34be05f\"></a>\n### 无状态处理\n流的无状态处理是确定性的，不需要依赖任何外部的处理方式。对于任何给定的数据，将始终生成与其他内容无关的相同输入。<br />![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1551280756166-0643b4f0-57aa-483b-b51f-ff4d42fc174e.png#align=left&display=inline&height=381&name=image.png&originHeight=762&originWidth=2600&size=233348&status=done&width=1300)\n<a name=\"6c8a2395\"></a>\n### 流式表的双重性\n首先要认识到流和表是相同的含义。流，可以解释为表，反之亦然。\n<a name=\"e3e24155\"></a>\n### 流作为表\n流可以看做对数据进行一系列的更新，因此最终结果作为表进行聚合。这种技术成为事件采集（Event sourcing）。<br />如果你了解如何实现同步数据库的复制，你会知道它是通过所谓的流复制（**Streaming replication**），每次表格中的变动都会发送到副本服务器。事件采集的另外一个例子是，区块链分类账，它也是进行一系列变化。<br />Kafka的数据流可以用相同的方式解释，即可以认为是积累到最终的状态的事件。此类流聚合保存在本地RocksDB中，称为**KTable**。<br />![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1551281577256-6c7efae0-3e86-4379-9b28-3a6870bb826a.png#align=left&display=inline&height=343&name=image.png&originHeight=686&originWidth=2000&size=219233&status=done&width=1000)\n<a name=\"d10a4cc4\"></a>\n### 表作为流\n可以将表视为流中每个键的最新值的快照。 以相同的方式，流记录可以生成表，表更新可以生成更改日志流。\n\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1551281769435-7f51d3f6-30f3-4ae8-9018-19d0ebfb11a9.png#align=left&display=inline&height=646&name=image.png&originHeight=1291&originWidth=1600&size=350243&status=done&width=800)\n<a name=\"096aebe0\"></a>\n### 有状态处理\n一些简单的操作，例如`map()`或者`filter()`都是无状态的，不需要额外保存有关处理的任何数据。但是，在现实生活中，大部分操作都是有状态的（例如`count()`），因此需要保存当前积累的值。<br />假如在流处理器上维护这些状态，流处理器可能会宕机，导致状态丢失。那么应当在哪里保存状态值才能容错呢？<br />一种最简单的方式是简单地将所有状态存储在远程数据库中，并通过网络连接到该数据库。这样做的问题是，没有数据的位置和产生大量的网络交互损耗，这两者都会显着减慢您的应用程序。 一个更微妙但重要的问题是您的流处理作业的正常运行时间将紧密耦合到远程数据库，并且作业将不会自包含_（数据库中的数据库与另一个团队的更改可能会破坏您的处理）_ 。<br />回忆下表和流的二元性。运行我们将流转化为与我们处理位于同一位置的表。它还能提供一种处理容错的机制，即在Kafka的Broker中存储流。<br />数据流处理器能够在本地表（即，RocksDB）存储状态，该表将从输入流（可能实在某些任意变换之后）更新。当进程失败时，可以通过重新请求流来恢复其数据。<br />你也可以使用一个远程数据库作为流的生产者，用于在本地重建表进行高效的广播更改日志。<br />\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1551282823033-1e7dcc9e-c2a2-4130-b972-b1c1776bd0f1.png#align=left&display=inline&height=729&name=image.png&originHeight=1458&originWidth=2000&size=234952&status=done&width=1000)\n<a name=\"KSQL\"></a>\n## KSQL\n通常，使用Kafka只能使用JVM语言编写刘处理，因为这是Kafka唯一的官方Streams API客户端。<br />\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1551799835544-909daa5c-d2ad-4f30-9060-496ba185feaf.png#align=left&display=inline&height=772&name=image.png&originHeight=1543&originWidth=1600&size=165449&status=done&width=800)<br />2018.04的Kafka发布**KSQL**，一种可以使用类SQL语言来编写简单流媒体工作的工具。<br />通过设置KSQL服务器，并且通过CLI方式进行交互以此来管理处理。它使用相同的抽象（KStream和KTable），保证了StreamS API的相同有点（可伸缩性、容错性）和更加简便的方式处理工作流。<br />这个特性虽然不被人经常提起，但经过实践对于测试更有用，甚至运行开发之外的人（例如，产品所有者）使用流处理。\n<a name=\"f525672f\"></a>\n### 流的可选择性\nKafka的流兼具了力量和简约的完美结合。可是说是市场上处理流工作的最佳工具，与其他流处理工具（Storm、Samza、Spark和Wallaroo）相比，Kafka更容易与其他工具结合。<br />大多数其他流处理的框架的问题在于它们运行和部署的复杂性。例如Spark这样的处理框架需要以下几点：\n\n1. 在一组计算机上控制大量的作业，并在集群上有效的分配。\n1. 为此，必须动态打包你的程序并将其部署在它需要执行的节点（以及配置、库等）。\n\n为此，要处理以上问题，使得框架尤为复杂。它们需要控制很多方面：部署、配置、监控和打包。<br />Kafka流能够允许你在你需要时，提出自己的部署策略，例如Kubernetes、Mesos、Nomad、Docker Swarm或者其他方式。<br />Kafka Streams的基本目的是使所有应用程序能够进行流处理，而无需运行和维护另一个操作复杂的集群。 唯一潜在的缺点是它与卡夫卡紧密结合，但在现代世界中，大多数（如果不是全部）实时处理由卡夫卡提供动力可能不是一个很大的劣势。\n<a name=\"c5329d3d\"></a>\n## 何时启用Kafka\n正如我们已经介绍的，Kafka允许通过集中式介质获取大量消息并且存储他们，并不担心性能或数据丢失等问题。<br />这意味着非常适合用在系统框架的核心，充当连接不同程序的中间媒介。Kafka能够成为事件驱动架构的中心部分，是您能够真正的将应用程序间解耦。\n\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1551888348371-8ade2e7b-bab2-4c43-9172-231a08b074c0.png#align=left&display=inline&height=337&name=image.png&originHeight=674&originWidth=900&size=432210&status=done&width=450)<br />Kafka能够非常轻松的分离不同（微）服务之间的通信。使用Streams API，现在可以更容易的编写业务逻辑，从而丰富Kafka主题数据以便提供服务。\n<a name=\"25f9c7fa\"></a>\n## 总结\nApache Kafka作为分布式流平台，每天可以处理数以万亿计的事件。Kafka提供低延迟、高吞吐量、高容错和订阅式流水线，同时能够流式处理事件。<br />我们回顾了它的基本语义（生产者、代理、消费者和Topic），了解了它的一些优化（page cache），通过复制数据了解了它的容错能力，并且介绍了它不断增长的强大流功能。\n\n\n","source":"_posts/yuque/Kafka - - 快速入门指南.md","raw":"\n---\ntitle: Kafka - - 快速入门指南\ndate: 2019-02-01 18:41:49 +0800\ntags: [珠峰翻译计划,Kafka]\ncategories: \n---\n<a name=\"e05dce83\"></a>\n## 简介\n\nKafka起源于2011年LikedIn的开源项目，并不断发展。如今它是一个完整的平台，允许您冗余地存储巨大的数据量，拥有一个具有巨大吞吐量（数百万/秒）的消息总线，同时可实现实时流处理。\n\nKafka具备的特性有：**分布式、水平扩展、高容错和日志管理**。接下来将逐个介绍特性。\n\n<a name=\"00ea564d\"></a>\n### 分布式\n\n分布式系统的显著特点是将任务分配到多个机器处理，即组成的集群对外暴露的形式仍为单一节点。Kafka的分布特性在于在不同节点（代理）存储、接收和发送消息。\n\n> 分布式系统的介绍可以参阅：[A Thorough Introduction to Distributed Systems](https://medium.freecodecamp.org/a-thorough-introduction-to-distributed-systems-3b91562c9b3c)\n\n\n分布式系统的优势主要体现在：高可扩展性、容错性。\n\n<a name=\"32a24e98\"></a>\n### 水平扩展\n\n首先解释、定义垂直扩展。例如，数据库服务器过载，最直接的解决办法是添加资源（CPU、RAM和SSD）。垂直扩展的两大缺点是：\n\n- 现有的硬件限制了扩展能力。例如不能无线提高CPU核数。\n- 通常需要停机时间。\n\n**水平扩展**通过投入更多的机器来解决上述问题。添加新机器不需要停机，也没有机器数量的限制。它的缺点是，并非所有系统支持水平弹性伸缩，因为在设计之初没有考虑工作在集群环境下，同时设计也更为复杂。<br />![](https://cdn.nlark.com/yuque/0/2019/jpeg/250680/1550673729515-587ccc54-647c-4f27-a36f-08848fd77da0.jpeg#align=left&display=inline&height=389&originHeight=389&originWidth=400&size=0&status=done&width=400)\n<a name=\"327fa254\"></a>\n### 高容错性\n非分布式系统的一大安全隐患是单点故障（single point of failure, SPOF）。例如单实例数据库宕机，会产生无法估量的损失。<br />分布式系统被设计为可配置的方式，来处理故障。例如，在5节点的Kafka集群中，即使其中两个节点关闭，系统仍然继续工作。需要注意的地方是，系统容错率与系统性能成反比，即容错率越高，性能越低。\n<a name=\"62b5133f\"></a>\n### 日志采集\n日志采集（事务日志）仅支持附加的持久有序数据结构，即无法修改或删除已有的记录。读取顺序从左向右如图所示。<br />![](https://cdn.nlark.com/yuque/0/2019/jpeg/250680/1550675101681-613e5d8c-b7f7-4800-8c6e-f0c7a41dae65.jpeg#align=left&display=inline&height=187&originHeight=187&originWidth=396&size=0&status=done&width=396)<br />在某种程度来讲，Kafka的数据结构就是如此简单。这也是Kafka的核心，因为它提供了有序数据，而有序的数据结构提供了确定性的处理方式。<br />Kafka实际上将所有消息存储在磁盘上，并且对他们进行排序，最大化利用硬盘顺序读取速度快的优势。\n\n- 读取和写入是整数级别O(1)（知道记录ID），与磁盘上的其他数据结构的操作复杂度为O(log N)相比，有巨大优势。\n- 读取和写入是分离的。写入时不会锁定读取，反之亦然（与平衡树相反）。\n\n这两点使得Kafka的性能有巨大优势，因为系统性能与数据量是分离的。Kafka无论处理100KB的数据量还是100TB的数据量，性能都是一样的。\n<a name=\"b3fbd195\"></a>\n## 工作原理\n向Kafka节点（broker）发送消息（记录）的称为程序（生产者），发送给其他程序处理消息的称为消费者。产生的消息存储在一个**topic**内，消费者订阅向topic订阅后，可以接收到对应topic的新消息。<br />![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1550761835264-486e6737-07e1-4bbb-aae7-4e09b7888f77.png#align=left&display=inline&height=178&name=image.png&originHeight=180&originWidth=258&size=8295&status=done&width=255)<br />随着topic变得越来越大，为保持性能和可伸缩性将topic拆分成更小的分区。（例如，需要存储用户的登录名，可以将用户名按照首字母进行拆分存储在不同的分区）<br />Kafka保证分区内的所有消息都按照它们进入的顺序排序。区分特定消息的方式是通过其**偏移量** ，可将其视为普通数组索引，在一个分区的序列号随着新消息进入而递增。<br />![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1550762596583-9e4702c2-cd98-410f-8587-2f2a17cbfaea.png#align=left&display=inline&height=182&name=image.png&originHeight=267&originWidth=416&size=19550&status=done&width=283)<br />Kafka遵循愚蠢的broker和聪明的消费者原则。意思是，Kafka不会跟踪哪一条记录已经被消费者读取并删除，而是将他们按照一定的时间（例如一天）或约定某个阈值大小来存储。消费者自身从Kafka的broker**主动拉取**新信息，并告知他们想要读取的片段。这意味着broker允许消费者按照自身的需要进行增加或减小偏移量，因此具有重新读取和重新处理信息的能力。<br />需要注意的是，消费者其实是消费者群组，包含一个或多个消费进程。为避免两个进程重复读取相同的信息，每个分区仅与每个组的一个消费者进程相关联。<br />![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1550763797220-d9a12e85-f1df-477c-adf7-ce92ddbeb9ac.png#align=left&display=inline&height=331&name=image.png&originHeight=661&originWidth=2000&size=238955&status=done&width=1000)\n<a name=\"efbcc1fb\"></a>\n## 数据持久化\nKafka将所有记录存储在磁盘，并且不会在RAM中保存任何记录。你可能会惊讶于以怎样高效的方式来做明智的选择。这背后有很多值得学习的优化知识：\n\n1. Kafka有将成组的消息合并的协议。允许网络请求将消息组合在一起减少网络开销，因此服务器一次性保留大量消息，消费者一次获取巨大的线性消息块。\n1. 磁盘顺序I/O读取速度很快。现代磁盘速度慢的原因是由于大量的磁盘寻道，但是在大型线性读写操作时不是问题。\n1. 线性操作由OS进一步优化，通过**预读取**（预读取多倍数据块）和**后写入**（将小的逻辑写入操作合并为组后再进行物理写入操作）技术。\n1. 现代OS利用RAM模拟磁盘缓存，这种技术成为pagecache。\n1. 由于kafka在整个流程（生产者--->代理--->消费者）中以未经修改的标准化二进制格式存储消息，因此它可以使用**零拷贝**（zero-copy）优化。操作系统将数据从pagecache直接复制到套接字，有效地完全绕过了Kafka代理应用程序。\n\n所有这些优化都使Kafka能够从接近网络的速度传输消息。\n<a name=\"8b75be39\"></a>\n## 数据分发和复制\n在这个章节，我们讨论Kafka如何实现容错以及它如何在节点之间分配数据。\n<a name=\"82a6c7de\"></a>\n### 数据复制\n分区数据在多个代理（broker）中复制，以便在其中一个代理挂掉时候，依然能够保存数据。<br />在任何时候，一个代理（broker）“拥有”其中一个分区，节点通过这个分区进行读写操作。因此，此分区被称为**分区领导者**（partition leader）。将接收到的数据复制给其他_**N**_个其他代理，称为**跟随者**（followers）。跟随者同样存储数据，并且随时准备着当leader挂掉时，取而代之。<br />这样的配置有助于保证任何成功发布的消息都不会丢失。通过更改复制因子，可以根据数据的重要性来交换性能以获得更强的持久性保证。<br />![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1551192978691-57bdf14e-90a0-47df-8aeb-60224ba6254c.png#align=left&display=inline&height=765&name=image.png&originHeight=1531&originWidth=2600&size=422840&status=done&width=1300)<br />在其中一个leader挂掉时，其他follower会竞选上岗，具体算法可以参考：<br />[_How does a producer/consumer know who the leader of a partition is?_](https://community.hortonworks.com/questions/149532/how-producer-and-consumer-identify-the-leader-in-k.html)<br />作为生产者/消费者，对一个分区进行读取时，首先需要知道对应分区的leader。这个信息需要存储在可以被访问到的地方，Kafka使用Zookeeper进行存储这些元数据。\n<a name=\"f52343ab\"></a>\n### 何为Zookeeper\nZookeeper是一个分布式键值存储结构。它针对读取进行了高度优化，但写入速度较慢。常应用于存储元数据和处理集群的核心机制（心跳包、分发更新配置等）。<br />它允许服务（Kafka的broker）的客户订阅通知，并且能在Zookeeper发生变动的时候发送给客户消息。这也是为什么brokers能够感知分区的leader发生变动。Zookeeper同时也具有成熟的容错性，或者说，Kafka很大程度上依赖Zookeeper的高容错性。<br />Zookeeper用于存储所有类型的元数据，包括但不限于：\n\n- 消费者群组中每个分区的偏移量（尽管现在的客户端在单独的Kafka主题Topic内存储偏移量）\n- ACL（访问控制列表），用于限制访问/授权\n- 生产者和消费者配额，包括每秒最大信息量\n- 存储分区leader和健康状态\n<a name=\"c577e2f9\"></a>\n### 如何区分分区的领导者\n在以往版本中，生产者和消费者经常直接连接并与Zookeeper交谈以获取此（和其他）信息。 目前Kafka已经弃用这种耦合，从0.8和0.9版本开始，客户端直接从Kafka的brokers那里获取元数据信息，他们自己与Zookeeper交谈。\n\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1551274509585-90480e7a-f43d-4959-9703-a908c3983f5f.png#align=left&display=inline&height=1076&name=image.png&originHeight=2152&originWidth=2000&size=462646&status=done&width=1000)\n<a name=\"3f4a00cf\"></a>\n## 流\n在Kafka中，流处理器是从输入的Topic中连续读取数据流，并对数据进行一些处理生成数据流以生成主题的任何（或外部服务、数据库、垃圾箱等）内容。<br />对于一些简单的消息，可能使用消费者或生产者的API接口直接处理即可，但是涉及到复杂的消息流（例如，多条数据流联合）处理的情况，Kafka提供一个集成的[Stream API](https://kafka.apache.org/documentation/streams/)库。<br />此API应用于自己的代码块中，而不是直接在代理（broker）上运行。它与消费者API类似，可以帮助你在多个应用（类似多个消费者）上扩展流处理工作。\n<a name=\"d34be05f\"></a>\n### 无状态处理\n流的无状态处理是确定性的，不需要依赖任何外部的处理方式。对于任何给定的数据，将始终生成与其他内容无关的相同输入。<br />![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1551280756166-0643b4f0-57aa-483b-b51f-ff4d42fc174e.png#align=left&display=inline&height=381&name=image.png&originHeight=762&originWidth=2600&size=233348&status=done&width=1300)\n<a name=\"6c8a2395\"></a>\n### 流式表的双重性\n首先要认识到流和表是相同的含义。流，可以解释为表，反之亦然。\n<a name=\"e3e24155\"></a>\n### 流作为表\n流可以看做对数据进行一系列的更新，因此最终结果作为表进行聚合。这种技术成为事件采集（Event sourcing）。<br />如果你了解如何实现同步数据库的复制，你会知道它是通过所谓的流复制（**Streaming replication**），每次表格中的变动都会发送到副本服务器。事件采集的另外一个例子是，区块链分类账，它也是进行一系列变化。<br />Kafka的数据流可以用相同的方式解释，即可以认为是积累到最终的状态的事件。此类流聚合保存在本地RocksDB中，称为**KTable**。<br />![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1551281577256-6c7efae0-3e86-4379-9b28-3a6870bb826a.png#align=left&display=inline&height=343&name=image.png&originHeight=686&originWidth=2000&size=219233&status=done&width=1000)\n<a name=\"d10a4cc4\"></a>\n### 表作为流\n可以将表视为流中每个键的最新值的快照。 以相同的方式，流记录可以生成表，表更新可以生成更改日志流。\n\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1551281769435-7f51d3f6-30f3-4ae8-9018-19d0ebfb11a9.png#align=left&display=inline&height=646&name=image.png&originHeight=1291&originWidth=1600&size=350243&status=done&width=800)\n<a name=\"096aebe0\"></a>\n### 有状态处理\n一些简单的操作，例如`map()`或者`filter()`都是无状态的，不需要额外保存有关处理的任何数据。但是，在现实生活中，大部分操作都是有状态的（例如`count()`），因此需要保存当前积累的值。<br />假如在流处理器上维护这些状态，流处理器可能会宕机，导致状态丢失。那么应当在哪里保存状态值才能容错呢？<br />一种最简单的方式是简单地将所有状态存储在远程数据库中，并通过网络连接到该数据库。这样做的问题是，没有数据的位置和产生大量的网络交互损耗，这两者都会显着减慢您的应用程序。 一个更微妙但重要的问题是您的流处理作业的正常运行时间将紧密耦合到远程数据库，并且作业将不会自包含_（数据库中的数据库与另一个团队的更改可能会破坏您的处理）_ 。<br />回忆下表和流的二元性。运行我们将流转化为与我们处理位于同一位置的表。它还能提供一种处理容错的机制，即在Kafka的Broker中存储流。<br />数据流处理器能够在本地表（即，RocksDB）存储状态，该表将从输入流（可能实在某些任意变换之后）更新。当进程失败时，可以通过重新请求流来恢复其数据。<br />你也可以使用一个远程数据库作为流的生产者，用于在本地重建表进行高效的广播更改日志。<br />\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1551282823033-1e7dcc9e-c2a2-4130-b972-b1c1776bd0f1.png#align=left&display=inline&height=729&name=image.png&originHeight=1458&originWidth=2000&size=234952&status=done&width=1000)\n<a name=\"KSQL\"></a>\n## KSQL\n通常，使用Kafka只能使用JVM语言编写刘处理，因为这是Kafka唯一的官方Streams API客户端。<br />\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1551799835544-909daa5c-d2ad-4f30-9060-496ba185feaf.png#align=left&display=inline&height=772&name=image.png&originHeight=1543&originWidth=1600&size=165449&status=done&width=800)<br />2018.04的Kafka发布**KSQL**，一种可以使用类SQL语言来编写简单流媒体工作的工具。<br />通过设置KSQL服务器，并且通过CLI方式进行交互以此来管理处理。它使用相同的抽象（KStream和KTable），保证了StreamS API的相同有点（可伸缩性、容错性）和更加简便的方式处理工作流。<br />这个特性虽然不被人经常提起，但经过实践对于测试更有用，甚至运行开发之外的人（例如，产品所有者）使用流处理。\n<a name=\"f525672f\"></a>\n### 流的可选择性\nKafka的流兼具了力量和简约的完美结合。可是说是市场上处理流工作的最佳工具，与其他流处理工具（Storm、Samza、Spark和Wallaroo）相比，Kafka更容易与其他工具结合。<br />大多数其他流处理的框架的问题在于它们运行和部署的复杂性。例如Spark这样的处理框架需要以下几点：\n\n1. 在一组计算机上控制大量的作业，并在集群上有效的分配。\n1. 为此，必须动态打包你的程序并将其部署在它需要执行的节点（以及配置、库等）。\n\n为此，要处理以上问题，使得框架尤为复杂。它们需要控制很多方面：部署、配置、监控和打包。<br />Kafka流能够允许你在你需要时，提出自己的部署策略，例如Kubernetes、Mesos、Nomad、Docker Swarm或者其他方式。<br />Kafka Streams的基本目的是使所有应用程序能够进行流处理，而无需运行和维护另一个操作复杂的集群。 唯一潜在的缺点是它与卡夫卡紧密结合，但在现代世界中，大多数（如果不是全部）实时处理由卡夫卡提供动力可能不是一个很大的劣势。\n<a name=\"c5329d3d\"></a>\n## 何时启用Kafka\n正如我们已经介绍的，Kafka允许通过集中式介质获取大量消息并且存储他们，并不担心性能或数据丢失等问题。<br />这意味着非常适合用在系统框架的核心，充当连接不同程序的中间媒介。Kafka能够成为事件驱动架构的中心部分，是您能够真正的将应用程序间解耦。\n\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/250680/1551888348371-8ade2e7b-bab2-4c43-9172-231a08b074c0.png#align=left&display=inline&height=337&name=image.png&originHeight=674&originWidth=900&size=432210&status=done&width=450)<br />Kafka能够非常轻松的分离不同（微）服务之间的通信。使用Streams API，现在可以更容易的编写业务逻辑，从而丰富Kafka主题数据以便提供服务。\n<a name=\"25f9c7fa\"></a>\n## 总结\nApache Kafka作为分布式流平台，每天可以处理数以万亿计的事件。Kafka提供低延迟、高吞吐量、高容错和订阅式流水线，同时能够流式处理事件。<br />我们回顾了它的基本语义（生产者、代理、消费者和Topic），了解了它的一些优化（page cache），通过复制数据了解了它的容错能力，并且介绍了它不断增长的强大流功能。\n\n\n","slug":"yuque/Kafka - - 快速入门指南","published":1,"updated":"2020-05-28T16:59:39.250Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckasagnj10013x396ftcmqybf","content":"<p><a name=\"e05dce83\"></a></p>\n<h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>Kafka起源于2011年LikedIn的开源项目，并不断发展。如今它是一个完整的平台，允许您冗余地存储巨大的数据量，拥有一个具有巨大吞吐量（数百万/秒）的消息总线，同时可实现实时流处理。</p>\n<p>Kafka具备的特性有：<strong>分布式、水平扩展、高容错和日志管理</strong>。接下来将逐个介绍特性。</p>\n<p><a name=\"00ea564d\"></a></p>\n<h3 id=\"分布式\"><a href=\"#分布式\" class=\"headerlink\" title=\"分布式\"></a>分布式</h3><p>分布式系统的显著特点是将任务分配到多个机器处理，即组成的集群对外暴露的形式仍为单一节点。Kafka的分布特性在于在不同节点（代理）存储、接收和发送消息。</p>\n<blockquote>\n<p>分布式系统的介绍可以参阅：<a href=\"https://medium.freecodecamp.org/a-thorough-introduction-to-distributed-systems-3b91562c9b3c\" target=\"_blank\" rel=\"noopener\">A Thorough Introduction to Distributed Systems</a></p>\n</blockquote>\n<p>分布式系统的优势主要体现在：高可扩展性、容错性。</p>\n<p><a name=\"32a24e98\"></a></p>\n<h3 id=\"水平扩展\"><a href=\"#水平扩展\" class=\"headerlink\" title=\"水平扩展\"></a>水平扩展</h3><p>首先解释、定义垂直扩展。例如，数据库服务器过载，最直接的解决办法是添加资源（CPU、RAM和SSD）。垂直扩展的两大缺点是：</p>\n<ul>\n<li>现有的硬件限制了扩展能力。例如不能无线提高CPU核数。</li>\n<li>通常需要停机时间。</li>\n</ul>\n<p><strong>水平扩展</strong>通过投入更多的机器来解决上述问题。添加新机器不需要停机，也没有机器数量的限制。它的缺点是，并非所有系统支持水平弹性伸缩，因为在设计之初没有考虑工作在集群环境下，同时设计也更为复杂。<br><img src=\"https://cdn.nlark.com/yuque/0/2019/jpeg/250680/1550673729515-587ccc54-647c-4f27-a36f-08848fd77da0.jpeg#align=left&amp;display=inline&amp;height=389&amp;originHeight=389&amp;originWidth=400&amp;size=0&amp;status=done&amp;width=400\" alt=\"\"><br><a name=\"327fa254\"></a></p>\n<h3 id=\"高容错性\"><a href=\"#高容错性\" class=\"headerlink\" title=\"高容错性\"></a>高容错性</h3><p>非分布式系统的一大安全隐患是单点故障（single point of failure, SPOF）。例如单实例数据库宕机，会产生无法估量的损失。<br>分布式系统被设计为可配置的方式，来处理故障。例如，在5节点的Kafka集群中，即使其中两个节点关闭，系统仍然继续工作。需要注意的地方是，系统容错率与系统性能成反比，即容错率越高，性能越低。<br><a name=\"62b5133f\"></a></p>\n<h3 id=\"日志采集\"><a href=\"#日志采集\" class=\"headerlink\" title=\"日志采集\"></a>日志采集</h3><p>日志采集（事务日志）仅支持附加的持久有序数据结构，即无法修改或删除已有的记录。读取顺序从左向右如图所示。<br><img src=\"https://cdn.nlark.com/yuque/0/2019/jpeg/250680/1550675101681-613e5d8c-b7f7-4800-8c6e-f0c7a41dae65.jpeg#align=left&amp;display=inline&amp;height=187&amp;originHeight=187&amp;originWidth=396&amp;size=0&amp;status=done&amp;width=396\" alt=\"\"><br>在某种程度来讲，Kafka的数据结构就是如此简单。这也是Kafka的核心，因为它提供了有序数据，而有序的数据结构提供了确定性的处理方式。<br>Kafka实际上将所有消息存储在磁盘上，并且对他们进行排序，最大化利用硬盘顺序读取速度快的优势。</p>\n<ul>\n<li>读取和写入是整数级别O(1)（知道记录ID），与磁盘上的其他数据结构的操作复杂度为O(log N)相比，有巨大优势。</li>\n<li>读取和写入是分离的。写入时不会锁定读取，反之亦然（与平衡树相反）。</li>\n</ul>\n<p>这两点使得Kafka的性能有巨大优势，因为系统性能与数据量是分离的。Kafka无论处理100KB的数据量还是100TB的数据量，性能都是一样的。<br><a name=\"b3fbd195\"></a></p>\n<h2 id=\"工作原理\"><a href=\"#工作原理\" class=\"headerlink\" title=\"工作原理\"></a>工作原理</h2><p>向Kafka节点（broker）发送消息（记录）的称为程序（生产者），发送给其他程序处理消息的称为消费者。产生的消息存储在一个<strong>topic</strong>内，消费者订阅向topic订阅后，可以接收到对应topic的新消息。<br><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1550761835264-486e6737-07e1-4bbb-aae7-4e09b7888f77.png#align=left&amp;display=inline&amp;height=178&amp;name=image.png&amp;originHeight=180&amp;originWidth=258&amp;size=8295&amp;status=done&amp;width=255\" alt=\"image.png\"><br>随着topic变得越来越大，为保持性能和可伸缩性将topic拆分成更小的分区。（例如，需要存储用户的登录名，可以将用户名按照首字母进行拆分存储在不同的分区）<br>Kafka保证分区内的所有消息都按照它们进入的顺序排序。区分特定消息的方式是通过其<strong>偏移量</strong> ，可将其视为普通数组索引，在一个分区的序列号随着新消息进入而递增。<br><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1550762596583-9e4702c2-cd98-410f-8587-2f2a17cbfaea.png#align=left&amp;display=inline&amp;height=182&amp;name=image.png&amp;originHeight=267&amp;originWidth=416&amp;size=19550&amp;status=done&amp;width=283\" alt=\"image.png\"><br>Kafka遵循愚蠢的broker和聪明的消费者原则。意思是，Kafka不会跟踪哪一条记录已经被消费者读取并删除，而是将他们按照一定的时间（例如一天）或约定某个阈值大小来存储。消费者自身从Kafka的broker<strong>主动拉取</strong>新信息，并告知他们想要读取的片段。这意味着broker允许消费者按照自身的需要进行增加或减小偏移量，因此具有重新读取和重新处理信息的能力。<br>需要注意的是，消费者其实是消费者群组，包含一个或多个消费进程。为避免两个进程重复读取相同的信息，每个分区仅与每个组的一个消费者进程相关联。<br><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1550763797220-d9a12e85-f1df-477c-adf7-ce92ddbeb9ac.png#align=left&amp;display=inline&amp;height=331&amp;name=image.png&amp;originHeight=661&amp;originWidth=2000&amp;size=238955&amp;status=done&amp;width=1000\" alt=\"image.png\"><br><a name=\"efbcc1fb\"></a></p>\n<h2 id=\"数据持久化\"><a href=\"#数据持久化\" class=\"headerlink\" title=\"数据持久化\"></a>数据持久化</h2><p>Kafka将所有记录存储在磁盘，并且不会在RAM中保存任何记录。你可能会惊讶于以怎样高效的方式来做明智的选择。这背后有很多值得学习的优化知识：</p>\n<ol>\n<li>Kafka有将成组的消息合并的协议。允许网络请求将消息组合在一起减少网络开销，因此服务器一次性保留大量消息，消费者一次获取巨大的线性消息块。</li>\n<li>磁盘顺序I/O读取速度很快。现代磁盘速度慢的原因是由于大量的磁盘寻道，但是在大型线性读写操作时不是问题。</li>\n<li>线性操作由OS进一步优化，通过<strong>预读取</strong>（预读取多倍数据块）和<strong>后写入</strong>（将小的逻辑写入操作合并为组后再进行物理写入操作）技术。</li>\n<li>现代OS利用RAM模拟磁盘缓存，这种技术成为pagecache。</li>\n<li>由于kafka在整个流程（生产者—&gt;代理—&gt;消费者）中以未经修改的标准化二进制格式存储消息，因此它可以使用<strong>零拷贝</strong>（zero-copy）优化。操作系统将数据从pagecache直接复制到套接字，有效地完全绕过了Kafka代理应用程序。</li>\n</ol>\n<p>所有这些优化都使Kafka能够从接近网络的速度传输消息。<br><a name=\"8b75be39\"></a></p>\n<h2 id=\"数据分发和复制\"><a href=\"#数据分发和复制\" class=\"headerlink\" title=\"数据分发和复制\"></a>数据分发和复制</h2><p>在这个章节，我们讨论Kafka如何实现容错以及它如何在节点之间分配数据。<br><a name=\"82a6c7de\"></a></p>\n<h3 id=\"数据复制\"><a href=\"#数据复制\" class=\"headerlink\" title=\"数据复制\"></a>数据复制</h3><p>分区数据在多个代理（broker）中复制，以便在其中一个代理挂掉时候，依然能够保存数据。<br>在任何时候，一个代理（broker）“拥有”其中一个分区，节点通过这个分区进行读写操作。因此，此分区被称为<strong>分区领导者</strong>（partition leader）。将接收到的数据复制给其他<em><strong>N</strong></em>个其他代理，称为<strong>跟随者</strong>（followers）。跟随者同样存储数据，并且随时准备着当leader挂掉时，取而代之。<br>这样的配置有助于保证任何成功发布的消息都不会丢失。通过更改复制因子，可以根据数据的重要性来交换性能以获得更强的持久性保证。<br><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1551192978691-57bdf14e-90a0-47df-8aeb-60224ba6254c.png#align=left&amp;display=inline&amp;height=765&amp;name=image.png&amp;originHeight=1531&amp;originWidth=2600&amp;size=422840&amp;status=done&amp;width=1300\" alt=\"image.png\"><br>在其中一个leader挂掉时，其他follower会竞选上岗，具体算法可以参考：<br><a href=\"https://community.hortonworks.com/questions/149532/how-producer-and-consumer-identify-the-leader-in-k.html\" target=\"_blank\" rel=\"noopener\"><em>How does a producer/consumer know who the leader of a partition is?</em></a><br>作为生产者/消费者，对一个分区进行读取时，首先需要知道对应分区的leader。这个信息需要存储在可以被访问到的地方，Kafka使用Zookeeper进行存储这些元数据。<br><a name=\"f52343ab\"></a></p>\n<h3 id=\"何为Zookeeper\"><a href=\"#何为Zookeeper\" class=\"headerlink\" title=\"何为Zookeeper\"></a>何为Zookeeper</h3><p>Zookeeper是一个分布式键值存储结构。它针对读取进行了高度优化，但写入速度较慢。常应用于存储元数据和处理集群的核心机制（心跳包、分发更新配置等）。<br>它允许服务（Kafka的broker）的客户订阅通知，并且能在Zookeeper发生变动的时候发送给客户消息。这也是为什么brokers能够感知分区的leader发生变动。Zookeeper同时也具有成熟的容错性，或者说，Kafka很大程度上依赖Zookeeper的高容错性。<br>Zookeeper用于存储所有类型的元数据，包括但不限于：</p>\n<ul>\n<li>消费者群组中每个分区的偏移量（尽管现在的客户端在单独的Kafka主题Topic内存储偏移量）</li>\n<li>ACL（访问控制列表），用于限制访问/授权</li>\n<li>生产者和消费者配额，包括每秒最大信息量</li>\n<li>存储分区leader和健康状态<br><a name=\"c577e2f9\"></a><h3 id=\"如何区分分区的领导者\"><a href=\"#如何区分分区的领导者\" class=\"headerlink\" title=\"如何区分分区的领导者\"></a>如何区分分区的领导者</h3>在以往版本中，生产者和消费者经常直接连接并与Zookeeper交谈以获取此（和其他）信息。 目前Kafka已经弃用这种耦合，从0.8和0.9版本开始，客户端直接从Kafka的brokers那里获取元数据信息，他们自己与Zookeeper交谈。</li>\n</ul>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1551274509585-90480e7a-f43d-4959-9703-a908c3983f5f.png#align=left&amp;display=inline&amp;height=1076&amp;name=image.png&amp;originHeight=2152&amp;originWidth=2000&amp;size=462646&amp;status=done&amp;width=1000\" alt=\"image.png\"><br><a name=\"3f4a00cf\"></a></p>\n<h2 id=\"流\"><a href=\"#流\" class=\"headerlink\" title=\"流\"></a>流</h2><p>在Kafka中，流处理器是从输入的Topic中连续读取数据流，并对数据进行一些处理生成数据流以生成主题的任何（或外部服务、数据库、垃圾箱等）内容。<br>对于一些简单的消息，可能使用消费者或生产者的API接口直接处理即可，但是涉及到复杂的消息流（例如，多条数据流联合）处理的情况，Kafka提供一个集成的<a href=\"https://kafka.apache.org/documentation/streams/\" target=\"_blank\" rel=\"noopener\">Stream API</a>库。<br>此API应用于自己的代码块中，而不是直接在代理（broker）上运行。它与消费者API类似，可以帮助你在多个应用（类似多个消费者）上扩展流处理工作。<br><a name=\"d34be05f\"></a></p>\n<h3 id=\"无状态处理\"><a href=\"#无状态处理\" class=\"headerlink\" title=\"无状态处理\"></a>无状态处理</h3><p>流的无状态处理是确定性的，不需要依赖任何外部的处理方式。对于任何给定的数据，将始终生成与其他内容无关的相同输入。<br><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1551280756166-0643b4f0-57aa-483b-b51f-ff4d42fc174e.png#align=left&amp;display=inline&amp;height=381&amp;name=image.png&amp;originHeight=762&amp;originWidth=2600&amp;size=233348&amp;status=done&amp;width=1300\" alt=\"image.png\"><br><a name=\"6c8a2395\"></a></p>\n<h3 id=\"流式表的双重性\"><a href=\"#流式表的双重性\" class=\"headerlink\" title=\"流式表的双重性\"></a>流式表的双重性</h3><p>首先要认识到流和表是相同的含义。流，可以解释为表，反之亦然。<br><a name=\"e3e24155\"></a></p>\n<h3 id=\"流作为表\"><a href=\"#流作为表\" class=\"headerlink\" title=\"流作为表\"></a>流作为表</h3><p>流可以看做对数据进行一系列的更新，因此最终结果作为表进行聚合。这种技术成为事件采集（Event sourcing）。<br>如果你了解如何实现同步数据库的复制，你会知道它是通过所谓的流复制（<strong>Streaming replication</strong>），每次表格中的变动都会发送到副本服务器。事件采集的另外一个例子是，区块链分类账，它也是进行一系列变化。<br>Kafka的数据流可以用相同的方式解释，即可以认为是积累到最终的状态的事件。此类流聚合保存在本地RocksDB中，称为<strong>KTable</strong>。<br><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1551281577256-6c7efae0-3e86-4379-9b28-3a6870bb826a.png#align=left&amp;display=inline&amp;height=343&amp;name=image.png&amp;originHeight=686&amp;originWidth=2000&amp;size=219233&amp;status=done&amp;width=1000\" alt=\"image.png\"><br><a name=\"d10a4cc4\"></a></p>\n<h3 id=\"表作为流\"><a href=\"#表作为流\" class=\"headerlink\" title=\"表作为流\"></a>表作为流</h3><p>可以将表视为流中每个键的最新值的快照。 以相同的方式，流记录可以生成表，表更新可以生成更改日志流。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1551281769435-7f51d3f6-30f3-4ae8-9018-19d0ebfb11a9.png#align=left&amp;display=inline&amp;height=646&amp;name=image.png&amp;originHeight=1291&amp;originWidth=1600&amp;size=350243&amp;status=done&amp;width=800\" alt=\"image.png\"><br><a name=\"096aebe0\"></a></p>\n<h3 id=\"有状态处理\"><a href=\"#有状态处理\" class=\"headerlink\" title=\"有状态处理\"></a>有状态处理</h3><p>一些简单的操作，例如<code>map()</code>或者<code>filter()</code>都是无状态的，不需要额外保存有关处理的任何数据。但是，在现实生活中，大部分操作都是有状态的（例如<code>count()</code>），因此需要保存当前积累的值。<br>假如在流处理器上维护这些状态，流处理器可能会宕机，导致状态丢失。那么应当在哪里保存状态值才能容错呢？<br>一种最简单的方式是简单地将所有状态存储在远程数据库中，并通过网络连接到该数据库。这样做的问题是，没有数据的位置和产生大量的网络交互损耗，这两者都会显着减慢您的应用程序。 一个更微妙但重要的问题是您的流处理作业的正常运行时间将紧密耦合到远程数据库，并且作业将不会自包含<em>（数据库中的数据库与另一个团队的更改可能会破坏您的处理）</em> 。<br>回忆下表和流的二元性。运行我们将流转化为与我们处理位于同一位置的表。它还能提供一种处理容错的机制，即在Kafka的Broker中存储流。<br>数据流处理器能够在本地表（即，RocksDB）存储状态，该表将从输入流（可能实在某些任意变换之后）更新。当进程失败时，可以通过重新请求流来恢复其数据。<br>你也可以使用一个远程数据库作为流的生产者，用于在本地重建表进行高效的广播更改日志。<br><br><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1551282823033-1e7dcc9e-c2a2-4130-b972-b1c1776bd0f1.png#align=left&amp;display=inline&amp;height=729&amp;name=image.png&amp;originHeight=1458&amp;originWidth=2000&amp;size=234952&amp;status=done&amp;width=1000\" alt=\"image.png\"><br><a name=\"KSQL\"></a></p>\n<h2 id=\"KSQL\"><a href=\"#KSQL\" class=\"headerlink\" title=\"KSQL\"></a>KSQL</h2><p>通常，使用Kafka只能使用JVM语言编写刘处理，因为这是Kafka唯一的官方Streams API客户端。<br><br><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1551799835544-909daa5c-d2ad-4f30-9060-496ba185feaf.png#align=left&amp;display=inline&amp;height=772&amp;name=image.png&amp;originHeight=1543&amp;originWidth=1600&amp;size=165449&amp;status=done&amp;width=800\" alt=\"image.png\"><br>2018.04的Kafka发布<strong>KSQL</strong>，一种可以使用类SQL语言来编写简单流媒体工作的工具。<br>通过设置KSQL服务器，并且通过CLI方式进行交互以此来管理处理。它使用相同的抽象（KStream和KTable），保证了StreamS API的相同有点（可伸缩性、容错性）和更加简便的方式处理工作流。<br>这个特性虽然不被人经常提起，但经过实践对于测试更有用，甚至运行开发之外的人（例如，产品所有者）使用流处理。<br><a name=\"f525672f\"></a></p>\n<h3 id=\"流的可选择性\"><a href=\"#流的可选择性\" class=\"headerlink\" title=\"流的可选择性\"></a>流的可选择性</h3><p>Kafka的流兼具了力量和简约的完美结合。可是说是市场上处理流工作的最佳工具，与其他流处理工具（Storm、Samza、Spark和Wallaroo）相比，Kafka更容易与其他工具结合。<br>大多数其他流处理的框架的问题在于它们运行和部署的复杂性。例如Spark这样的处理框架需要以下几点：</p>\n<ol>\n<li>在一组计算机上控制大量的作业，并在集群上有效的分配。</li>\n<li>为此，必须动态打包你的程序并将其部署在它需要执行的节点（以及配置、库等）。</li>\n</ol>\n<p>为此，要处理以上问题，使得框架尤为复杂。它们需要控制很多方面：部署、配置、监控和打包。<br>Kafka流能够允许你在你需要时，提出自己的部署策略，例如Kubernetes、Mesos、Nomad、Docker Swarm或者其他方式。<br>Kafka Streams的基本目的是使所有应用程序能够进行流处理，而无需运行和维护另一个操作复杂的集群。 唯一潜在的缺点是它与卡夫卡紧密结合，但在现代世界中，大多数（如果不是全部）实时处理由卡夫卡提供动力可能不是一个很大的劣势。<br><a name=\"c5329d3d\"></a></p>\n<h2 id=\"何时启用Kafka\"><a href=\"#何时启用Kafka\" class=\"headerlink\" title=\"何时启用Kafka\"></a>何时启用Kafka</h2><p>正如我们已经介绍的，Kafka允许通过集中式介质获取大量消息并且存储他们，并不担心性能或数据丢失等问题。<br>这意味着非常适合用在系统框架的核心，充当连接不同程序的中间媒介。Kafka能够成为事件驱动架构的中心部分，是您能够真正的将应用程序间解耦。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1551888348371-8ade2e7b-bab2-4c43-9172-231a08b074c0.png#align=left&amp;display=inline&amp;height=337&amp;name=image.png&amp;originHeight=674&amp;originWidth=900&amp;size=432210&amp;status=done&amp;width=450\" alt=\"image.png\"><br>Kafka能够非常轻松的分离不同（微）服务之间的通信。使用Streams API，现在可以更容易的编写业务逻辑，从而丰富Kafka主题数据以便提供服务。<br><a name=\"25f9c7fa\"></a></p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>Apache Kafka作为分布式流平台，每天可以处理数以万亿计的事件。Kafka提供低延迟、高吞吐量、高容错和订阅式流水线，同时能够流式处理事件。<br>我们回顾了它的基本语义（生产者、代理、消费者和Topic），了解了它的一些优化（page cache），通过复制数据了解了它的容错能力，并且介绍了它不断增长的强大流功能。</p>\n","site":{"data":{}},"excerpt":"","more":"<p><a name=\"e05dce83\"></a></p>\n<h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>Kafka起源于2011年LikedIn的开源项目，并不断发展。如今它是一个完整的平台，允许您冗余地存储巨大的数据量，拥有一个具有巨大吞吐量（数百万/秒）的消息总线，同时可实现实时流处理。</p>\n<p>Kafka具备的特性有：<strong>分布式、水平扩展、高容错和日志管理</strong>。接下来将逐个介绍特性。</p>\n<p><a name=\"00ea564d\"></a></p>\n<h3 id=\"分布式\"><a href=\"#分布式\" class=\"headerlink\" title=\"分布式\"></a>分布式</h3><p>分布式系统的显著特点是将任务分配到多个机器处理，即组成的集群对外暴露的形式仍为单一节点。Kafka的分布特性在于在不同节点（代理）存储、接收和发送消息。</p>\n<blockquote>\n<p>分布式系统的介绍可以参阅：<a href=\"https://medium.freecodecamp.org/a-thorough-introduction-to-distributed-systems-3b91562c9b3c\" target=\"_blank\" rel=\"noopener\">A Thorough Introduction to Distributed Systems</a></p>\n</blockquote>\n<p>分布式系统的优势主要体现在：高可扩展性、容错性。</p>\n<p><a name=\"32a24e98\"></a></p>\n<h3 id=\"水平扩展\"><a href=\"#水平扩展\" class=\"headerlink\" title=\"水平扩展\"></a>水平扩展</h3><p>首先解释、定义垂直扩展。例如，数据库服务器过载，最直接的解决办法是添加资源（CPU、RAM和SSD）。垂直扩展的两大缺点是：</p>\n<ul>\n<li>现有的硬件限制了扩展能力。例如不能无线提高CPU核数。</li>\n<li>通常需要停机时间。</li>\n</ul>\n<p><strong>水平扩展</strong>通过投入更多的机器来解决上述问题。添加新机器不需要停机，也没有机器数量的限制。它的缺点是，并非所有系统支持水平弹性伸缩，因为在设计之初没有考虑工作在集群环境下，同时设计也更为复杂。<br><img src=\"https://cdn.nlark.com/yuque/0/2019/jpeg/250680/1550673729515-587ccc54-647c-4f27-a36f-08848fd77da0.jpeg#align=left&amp;display=inline&amp;height=389&amp;originHeight=389&amp;originWidth=400&amp;size=0&amp;status=done&amp;width=400\" alt=\"\"><br><a name=\"327fa254\"></a></p>\n<h3 id=\"高容错性\"><a href=\"#高容错性\" class=\"headerlink\" title=\"高容错性\"></a>高容错性</h3><p>非分布式系统的一大安全隐患是单点故障（single point of failure, SPOF）。例如单实例数据库宕机，会产生无法估量的损失。<br>分布式系统被设计为可配置的方式，来处理故障。例如，在5节点的Kafka集群中，即使其中两个节点关闭，系统仍然继续工作。需要注意的地方是，系统容错率与系统性能成反比，即容错率越高，性能越低。<br><a name=\"62b5133f\"></a></p>\n<h3 id=\"日志采集\"><a href=\"#日志采集\" class=\"headerlink\" title=\"日志采集\"></a>日志采集</h3><p>日志采集（事务日志）仅支持附加的持久有序数据结构，即无法修改或删除已有的记录。读取顺序从左向右如图所示。<br><img src=\"https://cdn.nlark.com/yuque/0/2019/jpeg/250680/1550675101681-613e5d8c-b7f7-4800-8c6e-f0c7a41dae65.jpeg#align=left&amp;display=inline&amp;height=187&amp;originHeight=187&amp;originWidth=396&amp;size=0&amp;status=done&amp;width=396\" alt=\"\"><br>在某种程度来讲，Kafka的数据结构就是如此简单。这也是Kafka的核心，因为它提供了有序数据，而有序的数据结构提供了确定性的处理方式。<br>Kafka实际上将所有消息存储在磁盘上，并且对他们进行排序，最大化利用硬盘顺序读取速度快的优势。</p>\n<ul>\n<li>读取和写入是整数级别O(1)（知道记录ID），与磁盘上的其他数据结构的操作复杂度为O(log N)相比，有巨大优势。</li>\n<li>读取和写入是分离的。写入时不会锁定读取，反之亦然（与平衡树相反）。</li>\n</ul>\n<p>这两点使得Kafka的性能有巨大优势，因为系统性能与数据量是分离的。Kafka无论处理100KB的数据量还是100TB的数据量，性能都是一样的。<br><a name=\"b3fbd195\"></a></p>\n<h2 id=\"工作原理\"><a href=\"#工作原理\" class=\"headerlink\" title=\"工作原理\"></a>工作原理</h2><p>向Kafka节点（broker）发送消息（记录）的称为程序（生产者），发送给其他程序处理消息的称为消费者。产生的消息存储在一个<strong>topic</strong>内，消费者订阅向topic订阅后，可以接收到对应topic的新消息。<br><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1550761835264-486e6737-07e1-4bbb-aae7-4e09b7888f77.png#align=left&amp;display=inline&amp;height=178&amp;name=image.png&amp;originHeight=180&amp;originWidth=258&amp;size=8295&amp;status=done&amp;width=255\" alt=\"image.png\"><br>随着topic变得越来越大，为保持性能和可伸缩性将topic拆分成更小的分区。（例如，需要存储用户的登录名，可以将用户名按照首字母进行拆分存储在不同的分区）<br>Kafka保证分区内的所有消息都按照它们进入的顺序排序。区分特定消息的方式是通过其<strong>偏移量</strong> ，可将其视为普通数组索引，在一个分区的序列号随着新消息进入而递增。<br><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1550762596583-9e4702c2-cd98-410f-8587-2f2a17cbfaea.png#align=left&amp;display=inline&amp;height=182&amp;name=image.png&amp;originHeight=267&amp;originWidth=416&amp;size=19550&amp;status=done&amp;width=283\" alt=\"image.png\"><br>Kafka遵循愚蠢的broker和聪明的消费者原则。意思是，Kafka不会跟踪哪一条记录已经被消费者读取并删除，而是将他们按照一定的时间（例如一天）或约定某个阈值大小来存储。消费者自身从Kafka的broker<strong>主动拉取</strong>新信息，并告知他们想要读取的片段。这意味着broker允许消费者按照自身的需要进行增加或减小偏移量，因此具有重新读取和重新处理信息的能力。<br>需要注意的是，消费者其实是消费者群组，包含一个或多个消费进程。为避免两个进程重复读取相同的信息，每个分区仅与每个组的一个消费者进程相关联。<br><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1550763797220-d9a12e85-f1df-477c-adf7-ce92ddbeb9ac.png#align=left&amp;display=inline&amp;height=331&amp;name=image.png&amp;originHeight=661&amp;originWidth=2000&amp;size=238955&amp;status=done&amp;width=1000\" alt=\"image.png\"><br><a name=\"efbcc1fb\"></a></p>\n<h2 id=\"数据持久化\"><a href=\"#数据持久化\" class=\"headerlink\" title=\"数据持久化\"></a>数据持久化</h2><p>Kafka将所有记录存储在磁盘，并且不会在RAM中保存任何记录。你可能会惊讶于以怎样高效的方式来做明智的选择。这背后有很多值得学习的优化知识：</p>\n<ol>\n<li>Kafka有将成组的消息合并的协议。允许网络请求将消息组合在一起减少网络开销，因此服务器一次性保留大量消息，消费者一次获取巨大的线性消息块。</li>\n<li>磁盘顺序I/O读取速度很快。现代磁盘速度慢的原因是由于大量的磁盘寻道，但是在大型线性读写操作时不是问题。</li>\n<li>线性操作由OS进一步优化，通过<strong>预读取</strong>（预读取多倍数据块）和<strong>后写入</strong>（将小的逻辑写入操作合并为组后再进行物理写入操作）技术。</li>\n<li>现代OS利用RAM模拟磁盘缓存，这种技术成为pagecache。</li>\n<li>由于kafka在整个流程（生产者—&gt;代理—&gt;消费者）中以未经修改的标准化二进制格式存储消息，因此它可以使用<strong>零拷贝</strong>（zero-copy）优化。操作系统将数据从pagecache直接复制到套接字，有效地完全绕过了Kafka代理应用程序。</li>\n</ol>\n<p>所有这些优化都使Kafka能够从接近网络的速度传输消息。<br><a name=\"8b75be39\"></a></p>\n<h2 id=\"数据分发和复制\"><a href=\"#数据分发和复制\" class=\"headerlink\" title=\"数据分发和复制\"></a>数据分发和复制</h2><p>在这个章节，我们讨论Kafka如何实现容错以及它如何在节点之间分配数据。<br><a name=\"82a6c7de\"></a></p>\n<h3 id=\"数据复制\"><a href=\"#数据复制\" class=\"headerlink\" title=\"数据复制\"></a>数据复制</h3><p>分区数据在多个代理（broker）中复制，以便在其中一个代理挂掉时候，依然能够保存数据。<br>在任何时候，一个代理（broker）“拥有”其中一个分区，节点通过这个分区进行读写操作。因此，此分区被称为<strong>分区领导者</strong>（partition leader）。将接收到的数据复制给其他<em><strong>N</strong></em>个其他代理，称为<strong>跟随者</strong>（followers）。跟随者同样存储数据，并且随时准备着当leader挂掉时，取而代之。<br>这样的配置有助于保证任何成功发布的消息都不会丢失。通过更改复制因子，可以根据数据的重要性来交换性能以获得更强的持久性保证。<br><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1551192978691-57bdf14e-90a0-47df-8aeb-60224ba6254c.png#align=left&amp;display=inline&amp;height=765&amp;name=image.png&amp;originHeight=1531&amp;originWidth=2600&amp;size=422840&amp;status=done&amp;width=1300\" alt=\"image.png\"><br>在其中一个leader挂掉时，其他follower会竞选上岗，具体算法可以参考：<br><a href=\"https://community.hortonworks.com/questions/149532/how-producer-and-consumer-identify-the-leader-in-k.html\" target=\"_blank\" rel=\"noopener\"><em>How does a producer/consumer know who the leader of a partition is?</em></a><br>作为生产者/消费者，对一个分区进行读取时，首先需要知道对应分区的leader。这个信息需要存储在可以被访问到的地方，Kafka使用Zookeeper进行存储这些元数据。<br><a name=\"f52343ab\"></a></p>\n<h3 id=\"何为Zookeeper\"><a href=\"#何为Zookeeper\" class=\"headerlink\" title=\"何为Zookeeper\"></a>何为Zookeeper</h3><p>Zookeeper是一个分布式键值存储结构。它针对读取进行了高度优化，但写入速度较慢。常应用于存储元数据和处理集群的核心机制（心跳包、分发更新配置等）。<br>它允许服务（Kafka的broker）的客户订阅通知，并且能在Zookeeper发生变动的时候发送给客户消息。这也是为什么brokers能够感知分区的leader发生变动。Zookeeper同时也具有成熟的容错性，或者说，Kafka很大程度上依赖Zookeeper的高容错性。<br>Zookeeper用于存储所有类型的元数据，包括但不限于：</p>\n<ul>\n<li>消费者群组中每个分区的偏移量（尽管现在的客户端在单独的Kafka主题Topic内存储偏移量）</li>\n<li>ACL（访问控制列表），用于限制访问/授权</li>\n<li>生产者和消费者配额，包括每秒最大信息量</li>\n<li>存储分区leader和健康状态<br><a name=\"c577e2f9\"></a><h3 id=\"如何区分分区的领导者\"><a href=\"#如何区分分区的领导者\" class=\"headerlink\" title=\"如何区分分区的领导者\"></a>如何区分分区的领导者</h3>在以往版本中，生产者和消费者经常直接连接并与Zookeeper交谈以获取此（和其他）信息。 目前Kafka已经弃用这种耦合，从0.8和0.9版本开始，客户端直接从Kafka的brokers那里获取元数据信息，他们自己与Zookeeper交谈。</li>\n</ul>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1551274509585-90480e7a-f43d-4959-9703-a908c3983f5f.png#align=left&amp;display=inline&amp;height=1076&amp;name=image.png&amp;originHeight=2152&amp;originWidth=2000&amp;size=462646&amp;status=done&amp;width=1000\" alt=\"image.png\"><br><a name=\"3f4a00cf\"></a></p>\n<h2 id=\"流\"><a href=\"#流\" class=\"headerlink\" title=\"流\"></a>流</h2><p>在Kafka中，流处理器是从输入的Topic中连续读取数据流，并对数据进行一些处理生成数据流以生成主题的任何（或外部服务、数据库、垃圾箱等）内容。<br>对于一些简单的消息，可能使用消费者或生产者的API接口直接处理即可，但是涉及到复杂的消息流（例如，多条数据流联合）处理的情况，Kafka提供一个集成的<a href=\"https://kafka.apache.org/documentation/streams/\" target=\"_blank\" rel=\"noopener\">Stream API</a>库。<br>此API应用于自己的代码块中，而不是直接在代理（broker）上运行。它与消费者API类似，可以帮助你在多个应用（类似多个消费者）上扩展流处理工作。<br><a name=\"d34be05f\"></a></p>\n<h3 id=\"无状态处理\"><a href=\"#无状态处理\" class=\"headerlink\" title=\"无状态处理\"></a>无状态处理</h3><p>流的无状态处理是确定性的，不需要依赖任何外部的处理方式。对于任何给定的数据，将始终生成与其他内容无关的相同输入。<br><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1551280756166-0643b4f0-57aa-483b-b51f-ff4d42fc174e.png#align=left&amp;display=inline&amp;height=381&amp;name=image.png&amp;originHeight=762&amp;originWidth=2600&amp;size=233348&amp;status=done&amp;width=1300\" alt=\"image.png\"><br><a name=\"6c8a2395\"></a></p>\n<h3 id=\"流式表的双重性\"><a href=\"#流式表的双重性\" class=\"headerlink\" title=\"流式表的双重性\"></a>流式表的双重性</h3><p>首先要认识到流和表是相同的含义。流，可以解释为表，反之亦然。<br><a name=\"e3e24155\"></a></p>\n<h3 id=\"流作为表\"><a href=\"#流作为表\" class=\"headerlink\" title=\"流作为表\"></a>流作为表</h3><p>流可以看做对数据进行一系列的更新，因此最终结果作为表进行聚合。这种技术成为事件采集（Event sourcing）。<br>如果你了解如何实现同步数据库的复制，你会知道它是通过所谓的流复制（<strong>Streaming replication</strong>），每次表格中的变动都会发送到副本服务器。事件采集的另外一个例子是，区块链分类账，它也是进行一系列变化。<br>Kafka的数据流可以用相同的方式解释，即可以认为是积累到最终的状态的事件。此类流聚合保存在本地RocksDB中，称为<strong>KTable</strong>。<br><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1551281577256-6c7efae0-3e86-4379-9b28-3a6870bb826a.png#align=left&amp;display=inline&amp;height=343&amp;name=image.png&amp;originHeight=686&amp;originWidth=2000&amp;size=219233&amp;status=done&amp;width=1000\" alt=\"image.png\"><br><a name=\"d10a4cc4\"></a></p>\n<h3 id=\"表作为流\"><a href=\"#表作为流\" class=\"headerlink\" title=\"表作为流\"></a>表作为流</h3><p>可以将表视为流中每个键的最新值的快照。 以相同的方式，流记录可以生成表，表更新可以生成更改日志流。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1551281769435-7f51d3f6-30f3-4ae8-9018-19d0ebfb11a9.png#align=left&amp;display=inline&amp;height=646&amp;name=image.png&amp;originHeight=1291&amp;originWidth=1600&amp;size=350243&amp;status=done&amp;width=800\" alt=\"image.png\"><br><a name=\"096aebe0\"></a></p>\n<h3 id=\"有状态处理\"><a href=\"#有状态处理\" class=\"headerlink\" title=\"有状态处理\"></a>有状态处理</h3><p>一些简单的操作，例如<code>map()</code>或者<code>filter()</code>都是无状态的，不需要额外保存有关处理的任何数据。但是，在现实生活中，大部分操作都是有状态的（例如<code>count()</code>），因此需要保存当前积累的值。<br>假如在流处理器上维护这些状态，流处理器可能会宕机，导致状态丢失。那么应当在哪里保存状态值才能容错呢？<br>一种最简单的方式是简单地将所有状态存储在远程数据库中，并通过网络连接到该数据库。这样做的问题是，没有数据的位置和产生大量的网络交互损耗，这两者都会显着减慢您的应用程序。 一个更微妙但重要的问题是您的流处理作业的正常运行时间将紧密耦合到远程数据库，并且作业将不会自包含<em>（数据库中的数据库与另一个团队的更改可能会破坏您的处理）</em> 。<br>回忆下表和流的二元性。运行我们将流转化为与我们处理位于同一位置的表。它还能提供一种处理容错的机制，即在Kafka的Broker中存储流。<br>数据流处理器能够在本地表（即，RocksDB）存储状态，该表将从输入流（可能实在某些任意变换之后）更新。当进程失败时，可以通过重新请求流来恢复其数据。<br>你也可以使用一个远程数据库作为流的生产者，用于在本地重建表进行高效的广播更改日志。<br><br><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1551282823033-1e7dcc9e-c2a2-4130-b972-b1c1776bd0f1.png#align=left&amp;display=inline&amp;height=729&amp;name=image.png&amp;originHeight=1458&amp;originWidth=2000&amp;size=234952&amp;status=done&amp;width=1000\" alt=\"image.png\"><br><a name=\"KSQL\"></a></p>\n<h2 id=\"KSQL\"><a href=\"#KSQL\" class=\"headerlink\" title=\"KSQL\"></a>KSQL</h2><p>通常，使用Kafka只能使用JVM语言编写刘处理，因为这是Kafka唯一的官方Streams API客户端。<br><br><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1551799835544-909daa5c-d2ad-4f30-9060-496ba185feaf.png#align=left&amp;display=inline&amp;height=772&amp;name=image.png&amp;originHeight=1543&amp;originWidth=1600&amp;size=165449&amp;status=done&amp;width=800\" alt=\"image.png\"><br>2018.04的Kafka发布<strong>KSQL</strong>，一种可以使用类SQL语言来编写简单流媒体工作的工具。<br>通过设置KSQL服务器，并且通过CLI方式进行交互以此来管理处理。它使用相同的抽象（KStream和KTable），保证了StreamS API的相同有点（可伸缩性、容错性）和更加简便的方式处理工作流。<br>这个特性虽然不被人经常提起，但经过实践对于测试更有用，甚至运行开发之外的人（例如，产品所有者）使用流处理。<br><a name=\"f525672f\"></a></p>\n<h3 id=\"流的可选择性\"><a href=\"#流的可选择性\" class=\"headerlink\" title=\"流的可选择性\"></a>流的可选择性</h3><p>Kafka的流兼具了力量和简约的完美结合。可是说是市场上处理流工作的最佳工具，与其他流处理工具（Storm、Samza、Spark和Wallaroo）相比，Kafka更容易与其他工具结合。<br>大多数其他流处理的框架的问题在于它们运行和部署的复杂性。例如Spark这样的处理框架需要以下几点：</p>\n<ol>\n<li>在一组计算机上控制大量的作业，并在集群上有效的分配。</li>\n<li>为此，必须动态打包你的程序并将其部署在它需要执行的节点（以及配置、库等）。</li>\n</ol>\n<p>为此，要处理以上问题，使得框架尤为复杂。它们需要控制很多方面：部署、配置、监控和打包。<br>Kafka流能够允许你在你需要时，提出自己的部署策略，例如Kubernetes、Mesos、Nomad、Docker Swarm或者其他方式。<br>Kafka Streams的基本目的是使所有应用程序能够进行流处理，而无需运行和维护另一个操作复杂的集群。 唯一潜在的缺点是它与卡夫卡紧密结合，但在现代世界中，大多数（如果不是全部）实时处理由卡夫卡提供动力可能不是一个很大的劣势。<br><a name=\"c5329d3d\"></a></p>\n<h2 id=\"何时启用Kafka\"><a href=\"#何时启用Kafka\" class=\"headerlink\" title=\"何时启用Kafka\"></a>何时启用Kafka</h2><p>正如我们已经介绍的，Kafka允许通过集中式介质获取大量消息并且存储他们，并不担心性能或数据丢失等问题。<br>这意味着非常适合用在系统框架的核心，充当连接不同程序的中间媒介。Kafka能够成为事件驱动架构的中心部分，是您能够真正的将应用程序间解耦。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2019/png/250680/1551888348371-8ade2e7b-bab2-4c43-9172-231a08b074c0.png#align=left&amp;display=inline&amp;height=337&amp;name=image.png&amp;originHeight=674&amp;originWidth=900&amp;size=432210&amp;status=done&amp;width=450\" alt=\"image.png\"><br>Kafka能够非常轻松的分离不同（微）服务之间的通信。使用Streams API，现在可以更容易的编写业务逻辑，从而丰富Kafka主题数据以便提供服务。<br><a name=\"25f9c7fa\"></a></p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>Apache Kafka作为分布式流平台，每天可以处理数以万亿计的事件。Kafka提供低延迟、高吞吐量、高容错和订阅式流水线，同时能够流式处理事件。<br>我们回顾了它的基本语义（生产者、代理、消费者和Topic），了解了它的一些优化（page cache），通过复制数据了解了它的容错能力，并且介绍了它不断增长的强大流功能。</p>\n"},{"title":"usb接口键盘转PS2接口","date":"2019-03-03T15:09:24.000Z","_content":"<a name=\"9c5d49bd\"></a>\n## 用途\n\n公司或者主机设备没有usb接口，只能使用PS/2接口键盘。此程序完成USB HID keyboard协议向PS/2的scan code set 2转换。\n\n<a name=\"43424246\"></a>\n## 需要的硬件设备\n\n1. arduino uno R3\n2. USB Host Shield\n\n<a name=\"9e1bb02b\"></a>\n## 使用说明\n\n1. 默认PS/2接口的的四条数据线中，数据段和时钟段连接在Arduino的（4，2）。\n2. 使用IDE刷入usb2ps2.ino即可\n\n<a name=\"35649185\"></a>\n## 源代码地址\n\n[https://github.com/limao693/usb2ps2](https://github.com/limao693/usb2ps2)\n\n<a name=\"7cfd3686\"></a>\n## 参考文件\n\n1. [USB HID to PS/2 Scan Code Translation Table](https://download.microsoft.com/download/1/6/1/161ba512-40e2-4cc9-843a-923143f3456c/translate.pdf)\n2. [PS2键盘接口说明](http://www.burtonsys.com/ps2_chapweske.htm)\n3. [模拟PS/2键盘](https://www.arduino.cn/thread-77766-1-1.html)\n\n<a name=\"8867abb4\"></a>\n## Application scenario\n\nThe company or host device does not have a usb interface and can only use the PS/2 interface keyboard. This program completes the conversion of the USB HID keyboard protocol to the PS/2 scan code set 2.\n\n<a name=\"a57c2952\"></a>\n## Required hardware devices\n\n1. Arduino uno R3\n2. USB Host Shield\n\n<a name=\"a3258974\"></a>\n## Instructions for use\n\n1. Among the four data lines of the default PS/2 interface, the data segment and the clock segment are connected to the Arduino (4, 2).\n2. Use the IDE to brush usb2ps2.ino\n\n<a name=\"a98df735\"></a>\n## Source code\n\n[https://github.com/limao693/usb2ps2](https://github.com/limao693/usb2ps2)\n\n<a name=\"225e6fed\"></a>\n## reference document\n\n1. [USB HID to PS/2 Scan Code Translation Table](https://download.microsoft.com/download/1/6/1/161ba512-40e2-4cc9-843a-923143f3456c/translate.pdf)\n2. [PS2 Keyboard Interface Description](http://www.burtonsys.com/ps2_chapweske.htm)\n3. [Analog PS/2 Keyboard](https://www.arduino.cn/thread-77766-1-1.html)\n\n\n","source":"_posts/yuque/usb接口键盘转PS2接口.md","raw":"\n---\ntitle: usb接口键盘转PS2接口\ndate: 2019-03-03 23:09:24 +0800\ntags: [Arduino,硬件]\ncategories: \n---\n<a name=\"9c5d49bd\"></a>\n## 用途\n\n公司或者主机设备没有usb接口，只能使用PS/2接口键盘。此程序完成USB HID keyboard协议向PS/2的scan code set 2转换。\n\n<a name=\"43424246\"></a>\n## 需要的硬件设备\n\n1. arduino uno R3\n2. USB Host Shield\n\n<a name=\"9e1bb02b\"></a>\n## 使用说明\n\n1. 默认PS/2接口的的四条数据线中，数据段和时钟段连接在Arduino的（4，2）。\n2. 使用IDE刷入usb2ps2.ino即可\n\n<a name=\"35649185\"></a>\n## 源代码地址\n\n[https://github.com/limao693/usb2ps2](https://github.com/limao693/usb2ps2)\n\n<a name=\"7cfd3686\"></a>\n## 参考文件\n\n1. [USB HID to PS/2 Scan Code Translation Table](https://download.microsoft.com/download/1/6/1/161ba512-40e2-4cc9-843a-923143f3456c/translate.pdf)\n2. [PS2键盘接口说明](http://www.burtonsys.com/ps2_chapweske.htm)\n3. [模拟PS/2键盘](https://www.arduino.cn/thread-77766-1-1.html)\n\n<a name=\"8867abb4\"></a>\n## Application scenario\n\nThe company or host device does not have a usb interface and can only use the PS/2 interface keyboard. This program completes the conversion of the USB HID keyboard protocol to the PS/2 scan code set 2.\n\n<a name=\"a57c2952\"></a>\n## Required hardware devices\n\n1. Arduino uno R3\n2. USB Host Shield\n\n<a name=\"a3258974\"></a>\n## Instructions for use\n\n1. Among the four data lines of the default PS/2 interface, the data segment and the clock segment are connected to the Arduino (4, 2).\n2. Use the IDE to brush usb2ps2.ino\n\n<a name=\"a98df735\"></a>\n## Source code\n\n[https://github.com/limao693/usb2ps2](https://github.com/limao693/usb2ps2)\n\n<a name=\"225e6fed\"></a>\n## reference document\n\n1. [USB HID to PS/2 Scan Code Translation Table](https://download.microsoft.com/download/1/6/1/161ba512-40e2-4cc9-843a-923143f3456c/translate.pdf)\n2. [PS2 Keyboard Interface Description](http://www.burtonsys.com/ps2_chapweske.htm)\n3. [Analog PS/2 Keyboard](https://www.arduino.cn/thread-77766-1-1.html)\n\n\n","slug":"yuque/usb接口键盘转PS2接口","published":1,"updated":"2020-05-28T16:59:39.251Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckasagnj40015x396yy10e818","content":"<p><a name=\"9c5d49bd\"></a></p>\n<h2 id=\"用途\"><a href=\"#用途\" class=\"headerlink\" title=\"用途\"></a>用途</h2><p>公司或者主机设备没有usb接口，只能使用PS/2接口键盘。此程序完成USB HID keyboard协议向PS/2的scan code set 2转换。</p>\n<p><a name=\"43424246\"></a></p>\n<h2 id=\"需要的硬件设备\"><a href=\"#需要的硬件设备\" class=\"headerlink\" title=\"需要的硬件设备\"></a>需要的硬件设备</h2><ol>\n<li>arduino uno R3</li>\n<li>USB Host Shield</li>\n</ol>\n<p><a name=\"9e1bb02b\"></a></p>\n<h2 id=\"使用说明\"><a href=\"#使用说明\" class=\"headerlink\" title=\"使用说明\"></a>使用说明</h2><ol>\n<li>默认PS/2接口的的四条数据线中，数据段和时钟段连接在Arduino的（4，2）。</li>\n<li>使用IDE刷入usb2ps2.ino即可</li>\n</ol>\n<p><a name=\"35649185\"></a></p>\n<h2 id=\"源代码地址\"><a href=\"#源代码地址\" class=\"headerlink\" title=\"源代码地址\"></a>源代码地址</h2><p><a href=\"https://github.com/limao693/usb2ps2\" target=\"_blank\" rel=\"noopener\">https://github.com/limao693/usb2ps2</a></p>\n<p><a name=\"7cfd3686\"></a></p>\n<h2 id=\"参考文件\"><a href=\"#参考文件\" class=\"headerlink\" title=\"参考文件\"></a>参考文件</h2><ol>\n<li><a href=\"https://download.microsoft.com/download/1/6/1/161ba512-40e2-4cc9-843a-923143f3456c/translate.pdf\" target=\"_blank\" rel=\"noopener\">USB HID to PS/2 Scan Code Translation Table</a></li>\n<li><a href=\"http://www.burtonsys.com/ps2_chapweske.htm\" target=\"_blank\" rel=\"noopener\">PS2键盘接口说明</a></li>\n<li><a href=\"https://www.arduino.cn/thread-77766-1-1.html\" target=\"_blank\" rel=\"noopener\">模拟PS/2键盘</a></li>\n</ol>\n<p><a name=\"8867abb4\"></a></p>\n<h2 id=\"Application-scenario\"><a href=\"#Application-scenario\" class=\"headerlink\" title=\"Application scenario\"></a>Application scenario</h2><p>The company or host device does not have a usb interface and can only use the PS/2 interface keyboard. This program completes the conversion of the USB HID keyboard protocol to the PS/2 scan code set 2.</p>\n<p><a name=\"a57c2952\"></a></p>\n<h2 id=\"Required-hardware-devices\"><a href=\"#Required-hardware-devices\" class=\"headerlink\" title=\"Required hardware devices\"></a>Required hardware devices</h2><ol>\n<li>Arduino uno R3</li>\n<li>USB Host Shield</li>\n</ol>\n<p><a name=\"a3258974\"></a></p>\n<h2 id=\"Instructions-for-use\"><a href=\"#Instructions-for-use\" class=\"headerlink\" title=\"Instructions for use\"></a>Instructions for use</h2><ol>\n<li>Among the four data lines of the default PS/2 interface, the data segment and the clock segment are connected to the Arduino (4, 2).</li>\n<li>Use the IDE to brush usb2ps2.ino</li>\n</ol>\n<p><a name=\"a98df735\"></a></p>\n<h2 id=\"Source-code\"><a href=\"#Source-code\" class=\"headerlink\" title=\"Source code\"></a>Source code</h2><p><a href=\"https://github.com/limao693/usb2ps2\" target=\"_blank\" rel=\"noopener\">https://github.com/limao693/usb2ps2</a></p>\n<p><a name=\"225e6fed\"></a></p>\n<h2 id=\"reference-document\"><a href=\"#reference-document\" class=\"headerlink\" title=\"reference document\"></a>reference document</h2><ol>\n<li><a href=\"https://download.microsoft.com/download/1/6/1/161ba512-40e2-4cc9-843a-923143f3456c/translate.pdf\" target=\"_blank\" rel=\"noopener\">USB HID to PS/2 Scan Code Translation Table</a></li>\n<li><a href=\"http://www.burtonsys.com/ps2_chapweske.htm\" target=\"_blank\" rel=\"noopener\">PS2 Keyboard Interface Description</a></li>\n<li><a href=\"https://www.arduino.cn/thread-77766-1-1.html\" target=\"_blank\" rel=\"noopener\">Analog PS/2 Keyboard</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<p><a name=\"9c5d49bd\"></a></p>\n<h2 id=\"用途\"><a href=\"#用途\" class=\"headerlink\" title=\"用途\"></a>用途</h2><p>公司或者主机设备没有usb接口，只能使用PS/2接口键盘。此程序完成USB HID keyboard协议向PS/2的scan code set 2转换。</p>\n<p><a name=\"43424246\"></a></p>\n<h2 id=\"需要的硬件设备\"><a href=\"#需要的硬件设备\" class=\"headerlink\" title=\"需要的硬件设备\"></a>需要的硬件设备</h2><ol>\n<li>arduino uno R3</li>\n<li>USB Host Shield</li>\n</ol>\n<p><a name=\"9e1bb02b\"></a></p>\n<h2 id=\"使用说明\"><a href=\"#使用说明\" class=\"headerlink\" title=\"使用说明\"></a>使用说明</h2><ol>\n<li>默认PS/2接口的的四条数据线中，数据段和时钟段连接在Arduino的（4，2）。</li>\n<li>使用IDE刷入usb2ps2.ino即可</li>\n</ol>\n<p><a name=\"35649185\"></a></p>\n<h2 id=\"源代码地址\"><a href=\"#源代码地址\" class=\"headerlink\" title=\"源代码地址\"></a>源代码地址</h2><p><a href=\"https://github.com/limao693/usb2ps2\" target=\"_blank\" rel=\"noopener\">https://github.com/limao693/usb2ps2</a></p>\n<p><a name=\"7cfd3686\"></a></p>\n<h2 id=\"参考文件\"><a href=\"#参考文件\" class=\"headerlink\" title=\"参考文件\"></a>参考文件</h2><ol>\n<li><a href=\"https://download.microsoft.com/download/1/6/1/161ba512-40e2-4cc9-843a-923143f3456c/translate.pdf\" target=\"_blank\" rel=\"noopener\">USB HID to PS/2 Scan Code Translation Table</a></li>\n<li><a href=\"http://www.burtonsys.com/ps2_chapweske.htm\" target=\"_blank\" rel=\"noopener\">PS2键盘接口说明</a></li>\n<li><a href=\"https://www.arduino.cn/thread-77766-1-1.html\" target=\"_blank\" rel=\"noopener\">模拟PS/2键盘</a></li>\n</ol>\n<p><a name=\"8867abb4\"></a></p>\n<h2 id=\"Application-scenario\"><a href=\"#Application-scenario\" class=\"headerlink\" title=\"Application scenario\"></a>Application scenario</h2><p>The company or host device does not have a usb interface and can only use the PS/2 interface keyboard. This program completes the conversion of the USB HID keyboard protocol to the PS/2 scan code set 2.</p>\n<p><a name=\"a57c2952\"></a></p>\n<h2 id=\"Required-hardware-devices\"><a href=\"#Required-hardware-devices\" class=\"headerlink\" title=\"Required hardware devices\"></a>Required hardware devices</h2><ol>\n<li>Arduino uno R3</li>\n<li>USB Host Shield</li>\n</ol>\n<p><a name=\"a3258974\"></a></p>\n<h2 id=\"Instructions-for-use\"><a href=\"#Instructions-for-use\" class=\"headerlink\" title=\"Instructions for use\"></a>Instructions for use</h2><ol>\n<li>Among the four data lines of the default PS/2 interface, the data segment and the clock segment are connected to the Arduino (4, 2).</li>\n<li>Use the IDE to brush usb2ps2.ino</li>\n</ol>\n<p><a name=\"a98df735\"></a></p>\n<h2 id=\"Source-code\"><a href=\"#Source-code\" class=\"headerlink\" title=\"Source code\"></a>Source code</h2><p><a href=\"https://github.com/limao693/usb2ps2\" target=\"_blank\" rel=\"noopener\">https://github.com/limao693/usb2ps2</a></p>\n<p><a name=\"225e6fed\"></a></p>\n<h2 id=\"reference-document\"><a href=\"#reference-document\" class=\"headerlink\" title=\"reference document\"></a>reference document</h2><ol>\n<li><a href=\"https://download.microsoft.com/download/1/6/1/161ba512-40e2-4cc9-843a-923143f3456c/translate.pdf\" target=\"_blank\" rel=\"noopener\">USB HID to PS/2 Scan Code Translation Table</a></li>\n<li><a href=\"http://www.burtonsys.com/ps2_chapweske.htm\" target=\"_blank\" rel=\"noopener\">PS2 Keyboard Interface Description</a></li>\n<li><a href=\"https://www.arduino.cn/thread-77766-1-1.html\" target=\"_blank\" rel=\"noopener\">Analog PS/2 Keyboard</a></li>\n</ol>\n"},{"title":"RPC调用","date":"2019-06-03T03:41:05.000Z","_content":"<a name=\"hZZFF\"></a>\n### 知识点\n<a name=\"6NwQ3\"></a>\n#### Target\nan RPC Server's target:<br />       topic and server is required; exchange is optional<br />an RPC endpoint's target:<br />       namespace and version is optional<br />an RPC client sending a message:<br />       topic is required, all other attributes optional<br />a Notification Server's target:<br />       topic is required, exchange is optional; all other attributes ignored<br />a Notifier's target:<br />       topic is required, exchange is optional; all other attributes ignored\n\n","source":"_posts/yuque/RPC调用.md","raw":"\n---\ntitle: RPC调用\ndate: 2019-06-03 11:41:05 +0800\ntags: [rpc,HTTP]\ncategories: \n---\n<a name=\"hZZFF\"></a>\n### 知识点\n<a name=\"6NwQ3\"></a>\n#### Target\nan RPC Server's target:<br />       topic and server is required; exchange is optional<br />an RPC endpoint's target:<br />       namespace and version is optional<br />an RPC client sending a message:<br />       topic is required, all other attributes optional<br />a Notification Server's target:<br />       topic is required, exchange is optional; all other attributes ignored<br />a Notifier's target:<br />       topic is required, exchange is optional; all other attributes ignored\n\n","slug":"yuque/RPC调用","published":1,"updated":"2020-05-28T16:59:39.250Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckasagnj80017x3965efnyvrh","content":"<p><a name=\"hZZFF\"></a></p>\n<h3 id=\"知识点\"><a href=\"#知识点\" class=\"headerlink\" title=\"知识点\"></a>知识点</h3><p><a name=\"6NwQ3\"></a></p>\n<h4 id=\"Target\"><a href=\"#Target\" class=\"headerlink\" title=\"Target\"></a>Target</h4><p>an RPC Server’s target:<br>       topic and server is required; exchange is optional<br>an RPC endpoint’s target:<br>       namespace and version is optional<br>an RPC client sending a message:<br>       topic is required, all other attributes optional<br>a Notification Server’s target:<br>       topic is required, exchange is optional; all other attributes ignored<br>a Notifier’s target:<br>       topic is required, exchange is optional; all other attributes ignored</p>\n","site":{"data":{}},"excerpt":"","more":"<p><a name=\"hZZFF\"></a></p>\n<h3 id=\"知识点\"><a href=\"#知识点\" class=\"headerlink\" title=\"知识点\"></a>知识点</h3><p><a name=\"6NwQ3\"></a></p>\n<h4 id=\"Target\"><a href=\"#Target\" class=\"headerlink\" title=\"Target\"></a>Target</h4><p>an RPC Server’s target:<br>       topic and server is required; exchange is optional<br>an RPC endpoint’s target:<br>       namespace and version is optional<br>an RPC client sending a message:<br>       topic is required, all other attributes optional<br>a Notification Server’s target:<br>       topic is required, exchange is optional; all other attributes ignored<br>a Notifier’s target:<br>       topic is required, exchange is optional; all other attributes ignored</p>\n"},{"title":"测试语雀-Travis-Hexo","date":"2019-01-28T16:16:15.000Z","_content":"<a name=\"211a7729\"></a>\n## 信息来源\n本次语雀到Travis的配置，来源于：<br />[https://segmentfault.com/a/1190000017797561#articleHeader1](https://segmentfault.com/a/1190000017797561#articleHeader1)\n\n仅分享搭建历程，及代码分析。\n<a name=\"ed23dee5\"></a>\n## TEST步骤\n第一次，init测试。检测是否同步信息，有效期5分钟。过期删除<br />第二次测试，时间5分钟<br />第三次测试，时间3分钟<br />第四次测试，时间3分钟，仅测试 POSTMan触发请求，查看语雀是否会同步至github。失败<br />第五次测试，测试yuque-hexo组件clean/sync命令的先后顺序。<br />第六次测试，测试yuque-hexo组件，先clean后执行sync命令。<br />第七次测试，测试POSTMan触发请求。<br />第八次测试，测试serverless函数的正确性。<br />第九次测试，测试serverless函数的正确性。<br />第十次测试，测试serverless函数的正确性,参数进行硬编码。<br />第十一次测试，测试serverless函数的正确性.<br />第十二次测试，测试serverless函数的正确性.<br />第十二次测试，测试serverless函数的正确性,测试返回值。<br />第十三次测试，测试Travis pull queest的设置是否阻止的触发。<br />第十四次测试，测试serverless函数的正确性,移除触发body体的message。<br />第十五次测试，更改上次body体的错误，错误传输<‘hexo’>，加了单引号，未识别。<br />成功了，哈哈。。。<br />2019.1.30\n\n","source":"_posts/yuque/测试语雀-Travis-Hexo.md","raw":"\n---\ntitle: 测试语雀-Travis-Hexo\ndate: 2019-01-29 00:16:15 +0800\ntags: []\ncategories: \n---\n<a name=\"211a7729\"></a>\n## 信息来源\n本次语雀到Travis的配置，来源于：<br />[https://segmentfault.com/a/1190000017797561#articleHeader1](https://segmentfault.com/a/1190000017797561#articleHeader1)\n\n仅分享搭建历程，及代码分析。\n<a name=\"ed23dee5\"></a>\n## TEST步骤\n第一次，init测试。检测是否同步信息，有效期5分钟。过期删除<br />第二次测试，时间5分钟<br />第三次测试，时间3分钟<br />第四次测试，时间3分钟，仅测试 POSTMan触发请求，查看语雀是否会同步至github。失败<br />第五次测试，测试yuque-hexo组件clean/sync命令的先后顺序。<br />第六次测试，测试yuque-hexo组件，先clean后执行sync命令。<br />第七次测试，测试POSTMan触发请求。<br />第八次测试，测试serverless函数的正确性。<br />第九次测试，测试serverless函数的正确性。<br />第十次测试，测试serverless函数的正确性,参数进行硬编码。<br />第十一次测试，测试serverless函数的正确性.<br />第十二次测试，测试serverless函数的正确性.<br />第十二次测试，测试serverless函数的正确性,测试返回值。<br />第十三次测试，测试Travis pull queest的设置是否阻止的触发。<br />第十四次测试，测试serverless函数的正确性,移除触发body体的message。<br />第十五次测试，更改上次body体的错误，错误传输<‘hexo’>，加了单引号，未识别。<br />成功了，哈哈。。。<br />2019.1.30\n\n","slug":"yuque/测试语雀-Travis-Hexo","published":1,"updated":"2020-05-28T16:59:39.251Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckasagnj90019x396wuh8zs6l","content":"<p><a name=\"211a7729\"></a></p>\n<h2 id=\"信息来源\"><a href=\"#信息来源\" class=\"headerlink\" title=\"信息来源\"></a>信息来源</h2><p>本次语雀到Travis的配置，来源于：<br><a href=\"https://segmentfault.com/a/1190000017797561#articleHeader1\" target=\"_blank\" rel=\"noopener\">https://segmentfault.com/a/1190000017797561#articleHeader1</a></p>\n<p>仅分享搭建历程，及代码分析。<br><a name=\"ed23dee5\"></a></p>\n<h2 id=\"TEST步骤\"><a href=\"#TEST步骤\" class=\"headerlink\" title=\"TEST步骤\"></a>TEST步骤</h2><p>第一次，init测试。检测是否同步信息，有效期5分钟。过期删除<br>第二次测试，时间5分钟<br>第三次测试，时间3分钟<br>第四次测试，时间3分钟，仅测试 POSTMan触发请求，查看语雀是否会同步至github。失败<br>第五次测试，测试yuque-hexo组件clean/sync命令的先后顺序。<br>第六次测试，测试yuque-hexo组件，先clean后执行sync命令。<br>第七次测试，测试POSTMan触发请求。<br>第八次测试，测试serverless函数的正确性。<br>第九次测试，测试serverless函数的正确性。<br>第十次测试，测试serverless函数的正确性,参数进行硬编码。<br>第十一次测试，测试serverless函数的正确性.<br>第十二次测试，测试serverless函数的正确性.<br>第十二次测试，测试serverless函数的正确性,测试返回值。<br>第十三次测试，测试Travis pull queest的设置是否阻止的触发。<br>第十四次测试，测试serverless函数的正确性,移除触发body体的message。<br>第十五次测试，更改上次body体的错误，错误传输&lt;‘hexo’&gt;，加了单引号，未识别。<br>成功了，哈哈。。。<br>2019.1.30</p>\n","site":{"data":{}},"excerpt":"","more":"<p><a name=\"211a7729\"></a></p>\n<h2 id=\"信息来源\"><a href=\"#信息来源\" class=\"headerlink\" title=\"信息来源\"></a>信息来源</h2><p>本次语雀到Travis的配置，来源于：<br><a href=\"https://segmentfault.com/a/1190000017797561#articleHeader1\" target=\"_blank\" rel=\"noopener\">https://segmentfault.com/a/1190000017797561#articleHeader1</a></p>\n<p>仅分享搭建历程，及代码分析。<br><a name=\"ed23dee5\"></a></p>\n<h2 id=\"TEST步骤\"><a href=\"#TEST步骤\" class=\"headerlink\" title=\"TEST步骤\"></a>TEST步骤</h2><p>第一次，init测试。检测是否同步信息，有效期5分钟。过期删除<br>第二次测试，时间5分钟<br>第三次测试，时间3分钟<br>第四次测试，时间3分钟，仅测试 POSTMan触发请求，查看语雀是否会同步至github。失败<br>第五次测试，测试yuque-hexo组件clean/sync命令的先后顺序。<br>第六次测试，测试yuque-hexo组件，先clean后执行sync命令。<br>第七次测试，测试POSTMan触发请求。<br>第八次测试，测试serverless函数的正确性。<br>第九次测试，测试serverless函数的正确性。<br>第十次测试，测试serverless函数的正确性,参数进行硬编码。<br>第十一次测试，测试serverless函数的正确性.<br>第十二次测试，测试serverless函数的正确性.<br>第十二次测试，测试serverless函数的正确性,测试返回值。<br>第十三次测试，测试Travis pull queest的设置是否阻止的触发。<br>第十四次测试，测试serverless函数的正确性,移除触发body体的message。<br>第十五次测试，更改上次body体的错误，错误传输&lt;‘hexo’&gt;，加了单引号，未识别。<br>成功了，哈哈。。。<br>2019.1.30</p>\n"}],"PostAsset":[],"PostCategory":[],"PostTag":[{"post_id":"ckasagnhk0003x396ywp46e4f","tag_id":"ckasagnhp0006x396q0jouy0v","_id":"ckasagni5000fx396lhmrzmu3"},{"post_id":"ckasagnhk0003x396ywp46e4f","tag_id":"ckasagnhy000ax396dadphzy8","_id":"ckasagni6000hx396qiv4igz0"},{"post_id":"ckasagnhn0005x3963ahl1dt6","tag_id":"ckasagnhp0006x396q0jouy0v","_id":"ckasagni9000lx396ecjnufxl"},{"post_id":"ckasagnhn0005x3963ahl1dt6","tag_id":"ckasagni7000ix396hfxq1u1m","_id":"ckasagni9000mx396ize3zsjt"},{"post_id":"ckasagnht0008x396o3hx3qts","tag_id":"ckasagni9000kx396iblqy0bo","_id":"ckasagnia000px396yv9a96nz"},{"post_id":"ckasagnht0008x396o3hx3qts","tag_id":"ckasagni9000nx396ajsargbg","_id":"ckasagnia000qx396hxabsp25"},{"post_id":"ckasagnhv0009x396w0dcyw65","tag_id":"ckasagnia000ox396r3317f1z","_id":"ckasagnib000tx39629e2pkd7"},{"post_id":"ckasagnhv0009x396w0dcyw65","tag_id":"ckasagnia000rx396wy8l0vhr","_id":"ckasagnib000ux396958qiam3"},{"post_id":"ckasagni1000cx396np0ahzfn","tag_id":"ckasagnia000sx396hcl44g6o","_id":"ckasagnib000wx396p5ddju07"},{"post_id":"ckasagni1000cx396np0ahzfn","tag_id":"ckasagnib000vx396zxk6ooa6","_id":"ckasagnic000xx3968w02xcjj"},{"post_id":"ckasagnix000yx396jrt5o9rx","tag_id":"ckasagnhp0006x396q0jouy0v","_id":"ckasagnj00010x396cz7bupjw"},{"post_id":"ckasagnix000yx396jrt5o9rx","tag_id":"ckasagnhy000ax396dadphzy8","_id":"ckasagnj10012x396rlmu8xz7"},{"post_id":"ckasagniy000zx3964j84f1sh","tag_id":"ckasagnhp0006x396q0jouy0v","_id":"ckasagnj40014x396cdeys39m"},{"post_id":"ckasagniy000zx3964j84f1sh","tag_id":"ckasagni7000ix396hfxq1u1m","_id":"ckasagnj70016x396pgdzqql7"},{"post_id":"ckasagnj10013x396ftcmqybf","tag_id":"ckasagnia000sx396hcl44g6o","_id":"ckasagnj90018x3961f538yoo"},{"post_id":"ckasagnj10013x396ftcmqybf","tag_id":"ckasagnib000vx396zxk6ooa6","_id":"ckasagnjb001ax3966rtey9m4"},{"post_id":"ckasagnj40015x396yy10e818","tag_id":"ckasagni9000kx396iblqy0bo","_id":"ckasagnjb001bx396vuzb4zpd"},{"post_id":"ckasagnj40015x396yy10e818","tag_id":"ckasagni9000nx396ajsargbg","_id":"ckasagnjb001cx396s8tby32c"},{"post_id":"ckasagnj80017x3965efnyvrh","tag_id":"ckasagnia000ox396r3317f1z","_id":"ckasagnjb001dx39606v1ele2"},{"post_id":"ckasagnj80017x3965efnyvrh","tag_id":"ckasagnia000rx396wy8l0vhr","_id":"ckasagnjc001ex3965mdgpvd0"}],"Tag":[{"name":"docker","_id":"ckasagnhp0006x396q0jouy0v"},{"name":"Cgroup","_id":"ckasagnhy000ax396dadphzy8"},{"name":"namespace","_id":"ckasagni7000ix396hfxq1u1m"},{"name":"Arduino","_id":"ckasagni9000kx396iblqy0bo"},{"name":"硬件","_id":"ckasagni9000nx396ajsargbg"},{"name":"rpc","_id":"ckasagnia000ox396r3317f1z"},{"name":"HTTP","_id":"ckasagnia000rx396wy8l0vhr"},{"name":"珠峰翻译计划","_id":"ckasagnia000sx396hcl44g6o"},{"name":"Kafka","_id":"ckasagnib000vx396zxk6ooa6"}]}}